---
title: 02. 听觉注意解码准确性对助听器降噪系统的影响
icon: boke
date: 2025-11-27 01:44:44
author: Ran
category:
    - reading
    - literature
isOriginal: true
sticky: false
star: false
article: true
timeline: true
image: false
navbar: true
sidebarIcon: true
comment: true
lastUpdated: true
editLink: true
backToTop: true
toc: true
---

 **Impact of auditory attention decoding accuracy on noise reduction systems  for hearing aids (2026)**

![题目及作者](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251127015134844.png)

## 摘要

Hearing aid users often struggle to focus on a specific target speaker in multi-talker environments. Auditory attention decoding (AAD) algorithms, which extract attentional cues from electroencephalogram (EEG) signals, offer a potential solution. This study evaluates **how AAD accuracy and decision window length affect the performance of a multichannel Wiener filter noise reduction system in a speaker and story-independent scenario**. Simulations in two-speaker anechoic conditions show that, for decision windows of 1 s or less, AAD accuracies approximately above 81 % are required to meet minimum conversational speech quality (PESQ = 2.0), while accuracies approximately above 64 % suffice for intelligibility (STOI = 0.62). These results define quantitative performance targets for integrating AAD-based noise reduction into hearing aids and highlight the trade-off between decision latency, decoding accuracy, and perceptual benefit under idealized beamforming/VAD and anechoic conditions with high-density EEG.

助听器使用者在多说话者环境中常常难以专注于特定的目标说话者。听觉注意解码（AAD）算法可以从脑电图（EEG）信号中提取注意线索，提供一个潜在的解决方案。本研究评估了**AAD准确率和决策窗口长度如何影响多通道维纳滤波噪声抑制系统在说话者和故事独立场景中的性能**。双说话者无回声条件下的仿真表明，对于1秒或更短的决策窗口，AAD准确率需要大约超过81%才能达到最低的会话语音质量（PESQ = 2.0），而大约超过64%的准确率就足以满足可懂度要求（STOI = 0.62）。这些结果为将基于AAD的噪声抑制集成到助听器中设定了量化的性能目标，并突出了在理想的波束形成/VAD和无回声条件下、高密度EEG环境中决策延迟、解码准确率与感知收益之间的权衡。



## 1. Introduction

### 1.1 研究背景

1. **问题背景：**

    听力损失用户在多说话人（“鸡尾酒会”）环境中难以聚焦于目标说话人，现有助听器在此方面存在不足。

2. **现有解决方案与局限：**

    **传统方法**：依赖音量、视线方向等启发式规则，在目标源不具备这些特征时效果不佳。

    **新兴技术**：基于脑电图（EEG）的**听觉注意力解码（AAD）** 技术，可直接从大脑信号中解码用户注意力。

    *   **两大技术路径**：
        
        * **神经引导的语音提取**：使用EEG信号直接引导深度学习模型从混合语音中提取目标语音。但存在模型复杂、泛化能力差（如依赖特定说话人）等问题，不适用于现实助听器。
        
        * **分离后分类**：先分离各说话人信号（提供多个备选），再用AAD选择目标。这种方法**更易于在助听器上实现**，是本文采用的技术路径。
        
            > ### **为何“更易于在助听器上实现”？**
            >
            > 与第一种“端到端”方法相比，这种模块化设计有两大优势：
            >
            > 1. **计算负载分离与降低**：
            >     - **语音分离模块**和**EEG解码模块**可以独立优化。语音分离可以使用经典的、计算效率高的信号处理算法（如MWF）。
            >     - EEG解码虽然仍需神经网络，但它的任务被简化为一个相对简单的**分类问题**（左/右），而不是复杂的语音波形重构问题。这大大降低了模型的复杂度和计算需求。
            > 2. **系统更鲁棒、更易调试**：
            >     - 每个模块的功能明确，可以单独测试和评估。如果效果不好，可以定位问题是出在“分离不准”还是“选择不对”。
            >     - 更容易集成现有的、成熟的助听器技术（如波束成形器）。

3. **核心矛盾**：AAD的**准确率**与**决策窗口长度（延迟）** 之间存在权衡。短窗口（低延迟）是实用性的关键，但会导致准确率下降。先前研究使用了**长达30秒的决策窗口**，这在现实中**完全不实用**。

4. **前人研究局限：**

    - `[12-14]`：**MWF + AAD**（与本文系统架构几乎一致）。
    - `[15]`：**双耳波束成形 + 认知驱动**（核心思想一致，技术实现不同）。
    - `[16]`：**AAD与自适应波束成形的联合模型**（更先进的集成思路）。

    **这表明：** 将神经科学与音频处理结合以增强目标语音的**核心思想并非本文首创**。

    这些研究证明了“神经导向”在**技术原理上可行**，但它们为了达到足够高的解码精度（比如90%以上），普遍依赖于**长达30秒的决策窗口**。

5. **参考的核心文献局限**

    **贡献**：它提出了一种直接用EEG对听觉注意方位（左/右）进行分类的CNN方法，并且**关键地**，它在**约1秒的决策窗口**下，达到了与以往长窗口研究相似的准确率。

    **局限：**

    - 只评估了AAD本身的分类性能，**未集成到噪声抑制系统中**评估最终语音效果。
    - 依赖需要先验知识的**伪迹去除算法** （实用中无法预先知道并标记EEG中的伪迹，如眨眼、肌肉活动）。
    - 存在**数据泄露**问题（未严格说话人独立），导致性能评估虚高。

5. **其他局限：**

    大多数研究只报告AAD分类准确率，但助听器的适用性最终取决于**语音可懂度与质量**。

### 1.2 本文贡献

**🎯 研究目标**

1. **量化影响**：研究 **AAD算法的分类准确率** 和 **决策窗口长度** 这两个关键参数，如何影响噪声抑制系统的最终性能。
2. **确定最低要求**：找到为了达到**足够的语音可懂度（intelligibility）和质量（quality）**，所需要的**AAD准确率和决策窗口长度的最低门槛**。
3. **提供设计起点**：为未来神经导向助听器的工程设计提供**量化的性能基准和起始点**，而不仅仅是理论概念。

---

**贡献一：系统集成与在严格场景下的评估**

**做了什么**：将基于多通道维纳滤波器的噪声抑制系统与基于EEG的注意力检测算法相**结合**，并在一个**说话者和故事都独立**的场景下进行评估。

- **“结合”** 验证了完整系统链路的可行性。
- **“独立”** 意味着模型在训练时**从未见过**测试时所用的说话人和故事内容。这保证了评估结果的**严谨性和泛化能力**，证明了系统能应对真实世界中未知的说话人和对话，而不是在“作弊”。

------

**贡献二：AAD模型的个性化改进**

**做了什么**：改进了文献`[17]`中的CNN模型，提出了**三级个性化微调策略**，探索了利用助听器验配过程中收集的用户特定EEG数据来提升性能。

- 证明了**少量用户数据**（在标准验配过程中可获取）能**显著提升**AAD性能。
- 为未来产品提供了一个极具操作性的性能提升路径：**“预训练通用模型 + 验配时快速微调”**。

------

**贡献三：基于客观感知指标的系统性能分析**

**做了什么**：使用**PESQ**和**STOI**这两个客观指标来分析系统输出。

- 这代表了评估范式的转变。不再只看中间的“算法准确率”，而是关注最终的“**用户体验**”。
- **PESQ**评价语音听起来是否舒适、自然（**质量**）。
- **STOI**评价语音是否能被听懂（**可懂度**）。这两个才是助听器成功的终极标准。

------

**贡献四：建立定量的性能基准**

**做了什么**：首次定量地建立了AAD准确率、决策窗口与可接受语音质量/可懂度之间的对应关系，明确了最低性能要求。

- 这是全文的**最高价值总结**。它将前三点贡献的发现，凝结成可供工程界直接使用的“设计规格书”。
- 例如，它给出了明确答案：*“如果想让助听器在1秒内反应，并且语音质量达标，那么你的AAD算法准确率必须达到81%以上。”*
- 这为整个领域设定了清晰、量化的研发目标，让后续研究不再是盲目追求“更高的准确率”，而是有针对性地攻关“在指定延迟下达到所需准确率”。

## 2. Acoustic scenario description

### 2.1 物理场景设定

这一部分描述了一个**理想化的双说话人混响场景**：

- **设备配置（假设）**：
    - 助听器佩戴在**左耳**。
    - 左耳助听器上有 **`M/2` 个麦克风**，呈线性阵列排列。
    - 右耳有一个耳模，上面也有 **`M/2` 个麦克风**。
    - 左右耳的麦克风信号通过**无线传输**同步，共同构成一个完整的 **`M` 麦克风阵列系统**。
- **麦克风捕捉到的声源与噪声**：
    - 有 **`N` 个不同的说话人**。
    - 存在**环境噪声**，包括：
        - **环境扩散声场**（如房间混响、空调声）。
        - **电路噪声**。
- **关键假设（详情见2.2）：**
    - 语音源和噪声是**遍历的**，即语音源和噪声**完全均匀混合**，而且短时内是**平稳的**，其统计特性可以在短时窗口内估计。
    - 语音与噪声之间是**不相关的**。

**目的**：这个设定模拟了未来**双耳协同**的助听器，能利用头部两侧的麦克风获取空间信息，这是实现波束成形和声源定位的基础。



### 2.2 核心数学假设（公式推导的前提）

为了能用数学工具处理这个复杂场景，论文引入了三个关键假设，这是整个理论模型的基石：

- **假设一：线性混合**

    > “The M microphones capture a **linear mixture** of speech signals...”

    - **含义**：每个麦克风接收到的信号，是各个声源信号经过其传播路径（可能衰减、延迟）后，**简单相加**的结果。忽略回声、非线性失真等复杂效应。

    - **为什么重要**：只有线性混合，才能用公式 $$y = \sum_{i=1}^N a_i s_i + n $$  来表示，这是后续所有矩阵运算和滤波器设计（如MWF）的**根本前提**。

        > **公式详解：**
        >
        > **步骤1：单个麦克风收到什么？**
        > 对于第 `m` 个麦克风，在时频点 `(λ, k)` 上：
        >
        > $$y_m=x_{m_1}+x_{m_2}+...+x_{m_N}+n_m$$
        >
        > - $y_m$：麦克风 `m` 最终录到的**总信号**。
        > - $x_{m_i}$：第 `i` 个说话人的声音传到麦克风 `m` 这里的部分。
        > - $n_m$：环境噪声和电路噪声在麦克风 `m` 处的部分。
        >
        > **步骤2：每个说话人的声音怎么来的？**
        >
        > $$x_{m_i}=a_{m_i}∗s_i$$
        >
        > - $s_i$：第 `i` 个说话人发出的**原始、纯净的语音信号**（声源处）。
        > - $a_{m_i}$：**声学传递函数**。它描述了声音从第 `i` 个说话人的嘴巴，传播到第 `m` 个麦克风的**整个过程**所发生的变化。
        > - $x_{m_i}$：最终抵达麦克风 `m` 的第 `i` 个说话人的声音。
        >
        > **步骤3：合并成向量形式**
        > 把所有 `M` 个麦克风的信号堆叠成向量，得到更简洁的表达：
        >
        > $$\vec{y}=\vec{a_1}s_1+\vec{a_2}s_2+...+\vec{a_N}s_N+\vec{n}$$ 

- **假设二：短时遍历性**

    > “It is assumed that both source activity and noise statistics are **ergodic and estimable over short-term windows**.”

    - **含义**：语音和噪声的统计特性（如均值、方差、相关性）在短时间内（例如20-40毫秒的帧内）是**平稳且可估计的**。虽然语音整体变化剧烈，但在极短的片段内，其特性相对稳定。
    - **为什么重要**：这是所有**短时傅里叶变换**和**在线估计算法**的灵魂。它允许我们将非平稳的信号切成小段，在每一段内用统计方法处理，并相信这些估计是有效的。

- **假设三：信号不相关**

    > “Furthermore, the speech sources and noise are assumed to be **uncorrelated**.”

    - **含义**：任意两个不同的声源（例如目标说话人和干扰说话人）之间，以及任何声源与背景噪声之间，它们的信号是**统计上不相关**的。一个信号的变化无法用来预测另一个信号的变化。
    - **为什么重要**：这是**多通道维纳滤波器能够奏效的最关键假设**。MWF的核心思想是利用信号与噪声在空间特性上的差异来分离它们。如果目标语音和干扰语音高度相关（比如是同一个人说的不同句子），MWF将极难分离它们。这个假设在现实中很难完全满足，但它是理论推导和获得清晰解的**必要条件**。

### 2.2 公式解读

![](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251127032915033.png)

**1. 声源与角色定义**

- **`s₁(t)`**：**目标语音信号**
    - 这是听者**主动注意并想听清**的说话人。
    - 在本文的后续心理声学实验中，听者被要求始终跟随 `s₁(t)` 的内容。
- **`s₂(t)`**：**干扰语音信号**
    - 这是听者**需要忽略**的说话人。
    - 在系统中，`s₂(t)` 被视为需要被抑制的“噪声”之一。

**重要性**：这明确了系统任务的二元性——不是抑制一般的环境噪音，而是要在**两个非常相似的人类语音**中做出选择并抑制其中一个。这是“鸡尾酒会问题”的核心挑战。

---

 **2. 空间位置设定**

- **方位角**：两个声源分别位于听者左右两侧的 **±90°** 方位。
    - 例如，`s₁(t)` 在 **+90°**（听者左侧），`s₂(t)` 在 **-90°**（听者右侧）。
- **为何选择 ±90°？**
    1. **最大化空间分离**：这是双耳听觉中**空间线索最显著**的位置。左右耳的时间差和强度差最大，最有利于基于空间位置的分离算法（如波束成形）。
    2. **简化问题**：将声源置于极端两侧，避免了正前方或后方带来的空间模糊性，使研究可以专注于评估AAD和噪声抑制本身的性能，而不受声源定位模糊的干扰。
    3. **符合典型场景**：模拟了常见的对话场景，例如在餐桌两旁与人交谈。

---

**公式 (1): 单个麦克风接收到的全部信号**

![公式1](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251127030012189.png)

- **`yₘ(λ, k)`**：在第 `m` 个麦克风的 **时频点 `(λ, k)`** 上接收到的总信号。（`λ` 是时间帧索引，`k` 是频率点索引）
- **`Σ xₘᵢ(λ, k)`**：所有 `N` 个说话人的语音信号在第 `m` 个麦克风处叠加的结果。
- **`nₘ(λ, k)`**：在第 `m` 个麦克风处收到的环境噪声和电路噪声。

> **通俗理解**：这个公式就是说，**每个麦克风听到的声音 = 所有说话人声音的混合 + 背景噪音**。对应线性混合假设。



 **公式 (2): 单个麦克风接收到的单个说话人的语音信号**

公式(2) 是公式(1) 的一部分

![公式2](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251127030905913.png)

- **`sᵢ(λ, k)`**：第 `i` 个说话人发出的**纯净语音信号**。
- **`aₘᵢ(λ, k)`**：**声学传递函数**，它模拟了第 `i` 个声源发出的声音传播到第 `m` 个麦克风这个过程所发生的变化（如衰减、延迟）。
- **`xₘᵢ(λ, k)`**：最终，第 `i` 个说话人的声音被第 `m` 个麦克风捕捉到的版本。

> **通俗理解**：一个说话人的声音从嘴里发出，经过空气传播，再到被麦克风录下，这个过程会发生改变。`aₘᵢ` 就是描述这个“改变”的函数。所以，**麦克风收到的某个说话人的声音 = 他发出的原始声音 × 传播路径的影响**。



 **公式 (3): 所有麦克风信号的向量表示**

![公式3](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251127031337699.png)

这只是把公式(1)和(2)结合起来，并用**向量形式**表示所有 `M` 个麦克风的信息，这样更简洁，也便于后续的矩阵运算。

- **`y(λ, k)`**：一个向量，包含了所有 `M` 个麦克风在时频点 `(λ, k)` 上接收到的信号 `[y₁, y₂, ..., y_M]ᵀ`。
- **`aᵢ(λ, k)`**：一个向量，包含了第 `i` 个说话人到所有 `M` 个麦克风的声学传递函数 `[a₁ᵢ, a₂ᵢ, ..., a_Mᵢ]ᵀ`。它定义了该说话人的**空间位置信息**。
- **`n(λ, k)`**：一个向量，包含了所有 `M` 个麦克风处的噪声 `[n₁, n₂, ..., n_M]ᵀ`。



 **公式 (4) & (5): 定义“期望信号”与“噪声+干扰”信号**

这里对总信号 `y(λ, k)` 进行拆分，将其明确分为“我们想要的”和“我们不想要的”两部分。

- **期望信号向量 `x(λ, k)`**：

    ![](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251127031911653.png)

    假设第一个说话人 `s₁` 是听者关注的目标。那么，所有麦克风收到的、来自 `s₁` 的信号就是期望信号。

- **干扰噪声向量 `r(λ, k)`**：

    ![公式4](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251127031932922.png)

    这个向量包含了**所有干扰说话人（`i=2` 到 `N`）的声音**加上**环境噪声**。在本文的双说话人场景中，`i=2` 就是那个干扰说话人。

- **总信号的最终简化形式**：

    ![公式5](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251127031954973.png)

    这个公式至关重要，它将复杂的声学场景**简化为一个清晰的加法模型**：**总信号 = 期望信号 + (干扰 + 噪声)**。



**公式(6)**

![公式6](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251127032631166.png)

这个公式的意思是：**系统对目标语音的最终估计值 `x̂`，等于将所有麦克风的混合信号 `y`，通过一个精心设计的多通道滤波器 `w` 进行加权组合后得到的结果。**是**多通道维纳滤波器**的核心输出公式。给出了解决方案的第一步：如何利用 `w` 从 `y` 中提取 `x̂`

- **`x̂(λ, k)`**: 这是在时频点 `(λ, k)` 上，对**参考麦克风**处**目标语音** `x₁(λ, k)` 的**估计值**。也就是我们最终想得到的、增强后的信号。它的质量（PESQ/STOI）是本文评判系统成败的唯一标准。
- **`y(λ, k)`**: 这是我们熟悉的公式(3)中定义的向量，包含了所有 `M` 个麦克风在此时频点上接收到的信号 `[y₁, y₂, ..., y_M]ᵀ`。它是算法的**输入**。
- **`w(λ, k)`**: 这是**多通道维纳滤波器**在时频点 `(λ, k)` 上的**复值权重向量** `[w₁, w₂, ..., w_M]ᵀ`。每个元素 `w_m` 对应一个麦克风。这个权重向量是算法的核心，它包含了如何整合所有麦克风信息以突出目标、抑制噪声和干扰的“知识”。
- **`(·)^H`**: 表示**埃尔米特转置**（即共轭转置）。因为我们在处理**复值**的频域信号，所以需要共轭转置。
- **物理意义**：`w` 的每个复数权重 `w_m` 对第 `m` 个麦克风的信号执行两项操作：
    1. **幅度缩放**：放大或减小该麦克风信号的贡献。
    2. **相位旋转**：对该麦克风信号进行微小的延迟或提前。
        **这样做的终极目的**是：让所有麦克风中**来自目标方向**的信号成分**同相叠加**（建设性干涉），而让来自干扰和噪声方向的信号成分**异相抵消**（破坏性干涉）。



💡 直观理解：

您可以把这个公式想象成一个**智能的、随时空变化的“音量调节旋钮”组合**：

- **目标**：从一堆混乱的麦克风信号 `y` 中，提取出目标说话人在参考麦克风处的干净声音 `x̂`。

- **方法**：滤波器 `w` 会对每一个麦克风的信号进行一项复杂的操作：
    - **调整幅度（缩放）**
    - **调整相位（延迟）**
    
- **最终效果**：所有经过这样精心调整后的麦克风信号被加在一起。在这个过程中，**目标说话人的声音因为其特定的空间位置（由向量 `a₁` 定义）而被同相叠加、增强**；而**噪声和干扰说话人的声音则因为来自不同方向而被异相抵消、削弱**。

    

`w` 的最终目的，是**与目标声源的空间特征向量 `a₁` 匹配**。

回忆公式(2)-(3)：目标语音在各麦克风上的接收信号是：

![](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251202202809989.png)

理想情况下，如果我们知道 `a₁`，最优权重就是：`w ∝ a` ，意思就是：最优滤波器权重 `w` 应该与目标声源的空间特征 `a` 成比例。

---

### 2.3 问题

#### Q1：公式1的时频点 (λ, k)

**1. 什么是“时频点” `(λ, k)`？**

想象一下你在看一部电影的频谱图：

- **横轴 `λ`**：代表**时间**。比如 `λ=1` 代表电影开始的第10毫秒（取决于窗口长度和重叠），`λ=2` 代表第20毫秒，以此类推。它把连续的时间切成了一帧一帧的短片段。
- **纵轴 `k`**：代表**频率**。比如 `k=1` 代表0-100Hz，`k=2` 代表100-200Hz，以此类推。它表示在这一帧时间里，声音是由哪些频率成分构成的。
- **时频点 `(λ, k)`**：就是这张图上的一个**像素点**。它精确地表示在**某个特定的短暂时间片段（λ）** 内，**某个特定频率段（k）** 上的信号**强度（或能量）**。

**所以，公式 `yₘ(λ, k)` 读作：在第 `m` 个麦克风，第 `λ` 个时间帧，第 `k` 个频率 bin 上，接收到的总信号强度。**

**2. 为什么需要时频点？（核心原因）**

**① 利用“稀疏性”假设**
如上图所示，这是最根本的原因。在任意一个**非常短的时间窗口**（例如32ms）内，**多个说话人极少会在完全相同的时间、发出完全相同的频率**。这意味着，在大多数时频点 `(λ, k)` 上，其能量主要只由**一个**占主导地位的声源（目标说话人或干扰者）贡献，其他声源在该点的能量很弱甚至为零。

**② 简化处理，允许线性滤波**
在时频域中，卷积混合（在时间域是复杂的）在窄带假设下可以近似为**瞬时混合**。这就使得公式(3)中的混合模型成立，并且可以使用像**多通道维纳滤波器（MWF）** 这样的**线性滤波器** `w(λ, k)` 来进行处理。在时间域直接进行类似的线性过滤要困难得多。

**③ 契合语音和非平稳信号的特性**
语音和噪声都是**非平稳信号**，它们的统计特性随时间变化。在时频域中，我们可以针对**每一帧（λ）** 来估计和更新信号的统计信息（如协方差矩阵 `Φ_y(λ,k)`），这让算法能够自适应地跟踪声音环境的变化。

**3. 一个生动的比喻**

把整个一段语音信号想象成一幅**完整的油画**，画上是两个人物重叠在一起。

- **在时间域分离**：就像让你不借助任何工具，直接把画上的两个人完美地剥离开，这几乎是不可能的。
- **在时频域分离**：就像用一个**高倍放大镜**，逐个像素 `(λ, k)` 地去观察这幅画。你会发现，在大多数像素点上，其实只显示了一个人物的颜色。你只需要在每个像素点上做一个简单的决定：“这个像素点更可能属于人物A还是人物B？”。
- **MWF的作用**：就是这个“决策过程”。它根据麦克风阵列收到的信息，在每个时频点上计算一个最优的权重，来提取目标信号并抑制干扰。

**总结：使用“时频点” `(λ, k)` 是一种“分而治之”的策略。它将一个全局性的、高度复杂的非线性分离问题，分解成了大量局部的、相对简单的线性估计问题，从而使得实时的、高效的噪声抑制和语音增强成为可能。**

---

#### Q2：公式6的复数权重向量

**一、为什么要引入复数？—— 一个根本问题**

**问题**：如何用一个数字 **同时** 表示一个声音的：

1. **响度**（幅度/振幅）
2. **时机**（相位/时间点）

**传统实数**：`3.0` 只能表示响度，无法表示时机。
**解决方案**：使用**复数**！一个复数可以同时打包这两个信息。

------

**二、复数的直观理解：旋转箭头**

把声音想象成一个**在转盘上旋转的箭头**：

| 概念           | 在“旋转箭头”模型中的对应                   |
| :------------- | :----------------------------------------- |
| **复数的长度** | **箭头的长度** → 代表声音的**幅度/响度**   |
| **复数的角度** | **箭头的指向** → 代表声音的**相位/时间点** |
| **复平面**     | **整个转盘**                               |



```
                   复平面（想象成一个钟面）
                         ^ 虚轴 (Imaginary)
                         |
                         |  箭头 (复数 Z)
                         |   /
                         |  / 
                         | /  长度 = 幅度
                         |/ ) 角度 = 相位
        ----------+-----------> 实轴 (Real)
                         |
                         |
```



------

 **三、复数的两种表示法**

**1. 直角坐标形式：`a + jb`**

- **`a`**：实部，表示箭头在“东西方向”的投影长度
- **`b`**：虚部，表示箭头在“南北方向”的投影长度
- **`j`**：虚数单位，`j = √(-1)`，表示“旋转90度”的操作

**例如**：`3 + 4j` 表示箭头向东3单位，向北4单位。

**2. 极坐标形式：`R \* e^(jθ)`**

- **`R`**：幅度（长度），`R = √(a² + b²)`
- **`θ`**：相位（角度），`θ = arctan(b/a)`
- **`e^(jθ)`**：表示“旋转θ角度”的数学操作

**例如**：`5 * e^(j0.93)` 表示长度为5，角度为0.93弧度（约53°）的箭头。

------

**四、在声音/信号处理中的具体含义**

当我们在时频域看到一个复数 `Z = R * e^(jθ)` 时：

**物理意义：**

- **`R`**：在这个特定频率上，声音的**强度/能量**有多大。
- **`θ`**：在这个特定时间点上，该频率分量的声波处于**振动周期的哪个位置**。

**关键理解：相位是相对的时间信息**

假设有两个麦克风收到同一个声音：

```
麦克风1：信号1 = R * e^(j*θ₁)
麦克风2：信号2 = R * e^(j*θ₂)  # 同样的幅度，但相位不同
```



**相位差 `Δθ = θ₂ - θ₁` 直接告诉你声音到达两个麦克风的**时间差！

- `Δθ = 0`：同时到达
- `Δθ > 0`：麦克风2比麦克风1晚到
- `Δθ < 0`：麦克风2比麦克风1早到

------

**五、复数的运算如何对应物理操作**

**1. 复数乘法：缩放 + 旋转**

```
Z₁ * Z₂ = (R₁ * e^(jθ₁)) * (R₂ * e^(jθ₂)) = (R₁R₂) * e^(j(θ₁+θ₂))
```

**物理意义**：

- **`R₁R₂`**：幅度被缩放（调音量）
- **`θ₁+θ₂`**：相位被旋转（调时间）

**这正是权重 `w_m` 对信号 `y_m` 的作用！**

```
w_m * y_m = (幅度_w * e^(j*相位_w)) * (幅度_y * e^(j*相位_y))
          = (幅度_w * 幅度_y) * e^(j*(相位_w + 相位_y))
```



 **2. 复数加法：矢量叠加**

```
Z₁ + Z₂ = (a₁ + jb₁) + (a₂ + jb₂) = (a₁+a₂) + j(b₁+b₂)
```

**物理意义**：两个声波在空气中相遇时，它们的压力和速度就是这样**矢量相加**的。



**3. 复数共轭：`Z\* = a - jb` 或 `R \* e^(-jθ)`**

**物理意义**：**时间反转**或**相位取反**。在公式 `w^H y` 中的 `w^H`（埃尔米特转置）就包含共轭操作，这相当于对权重进行相位反向调整来对齐信号。

------

**六、为什么权重是复数向量？**

每个复数权重对应调整一个麦克风信号，几个麦克风信号同时调整，**复数权重 `w_m` 对第 m 个麦克风信号做两件事：**

```bash
w_m = A_m * e^(j*θ_m)
      ↑           ↑
  幅度缩放因子    相位旋转因子
```

- **`A_m`**（实数部分）：控制**放大或衰减**多少，调节该麦克风信号的“音量”
- **`θ_m`**（相位角）：控制**延迟或提前**多少时间，它与其他麦克风的信号在时间上对齐

**而“向量” `w` 则是：**

![](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251202202337174.png)

- 一个包含 `M` 个复数的列表
- 每个复数对应一个麦克风，针对性调整
- 整个向量编码了**如何利用所有麦克风的空间分布信息**来提取目标声音





## 3. AAD-based noise reduction system

相关文献[12]关注说话人分离这个步骤：

```bash
麦克风信号 → 盲源分离系统 → 分离出的两个语音流
           (ICA或DNN)       (目标语音近似 + 干扰语音近似)
```

**两种实现技术**

 **① 独立成分分析 （ICA）**

- **原理**：一种经典的统计方法。假设各个源信号在统计上**相互独立**，通过寻找一个变换矩阵，使得输出信号的独立性最大化。
- **优点**：数学理论清晰，无需训练数据。
- **缺点**：对假设敏感（现实中语音信号不完全独立，两个同时说话的人的语音信号在统计上并不完全独立，分离效果可能不理想），计算复杂，分离质量有限。

 **② 深度神经网络（DNN）**

- **原理**：使用大量带标签的混合-纯净语音数据对，训练一个神经网络直接学习从混合信号到分离信号的映射。
- **优点**：分离质量通常比ICA高，能学习复杂的声学模式。
- **缺点**：需要大量训练数据，模型复杂，可能过拟合，泛化能力存疑，可能不适合助听器上的实时处理。

---

**基于解码-相关性”的传统AAD方法**

该方法分三步走：

- **解码重建**：从所有EEG通道中，重建出用户正在关注的**目标说话人的语音包络**（声音的强度轮廓）。
- **计算相关**：将重建出的包络，分别与**两个已知的说话人**各自的语音包络计算**皮尔逊相关系数**。
- **选择目标**：**相关系数更高**的那个说话人，即被判定为用户注意的目标。

- **局限**：性能**极度依赖决策窗口长度**。

    **原因**：从EEG重建的包络**信噪比极低**，在短时间窗口下估计的相关系数**非常不稳定、噪声大**。

---

由于文献 [17] 中，通过卷积神经网络利用EEG信号检测听觉注意力的焦点，而不使用干净语音包络信息，使用大约1秒的决策窗口，也达到了相同范围的准确率。本文提出一种将多通道波束形成（MWF）与基于脑电图（EEG）的算法结合，用于检测听觉注意力位置的降噪系统。

两个信号分别位于左右两侧，一个为目标信号，一个为干扰信号。

![](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251127033944881.png)



### 3.1 噪声抑制滤波器

对应图中红框部分。

 **一、 目标：我们想做什么？**

回顾公式(5)：`y = x + r`

- `y`：麦克风收到的**混合信号**（向量）
- `x`：我们想要的**目标语音**在麦克风上的信号（向量）
- `r`：我们想消除的**干扰+噪声**（向量）

**我们的终极目标**：设计一个“魔法过滤器” `w`，把它作用在混合信号 `y` 上，能最大程度地保留 `x`，同时滤除 `r`。
用数学表示，就是找到一个滤波器 `w`，使得输出：

![](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251202230646430.png)

尽可能接近我们想要的 `x₁`（即目标语音在**参考麦克风**处的信号）。

**二、 核心思想：如何设计最优过滤器？—— MMSE准则**

我们如何判断一个过滤器 `w` 是好是坏？需要一个**优化准则**。

论文采用工程中最经典、最直观的准则：**最小均方误差**。

> **思想**：让过滤器估计出的语音 `x̂`，与真实的干净语音 `x₁` 之间的**平均平方误差**最小。

**数学表达（公式7）**：

![公式7](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251202230951519.png)

**解读**：

- `𝔼{·}`：求期望（长期平均），表示我们关心的是**统计平均性能**，而不是某一次的偶然。
- `|·|²`：取模的平方，用来度量误差的大小。
- `x₁ - w^H y`：就是**估计误差**。
- `arg min`：寻找能使这个平均平方误差最小的那个权重向量 `w`。

 **左边：`w(λ,k)`**

- 这是我们要求解的、**未知的滤波器权重向量**。
- 它本身就是我们想要的结果。

**右边：`arg min_w { ... }`**

- 这是一个**算子**，它作用于一个**函数**（大括号里的均方误差函数）。
- **`min_w`** 的意思是：找到这个函数的**最小值**。
- **`arg`** 的意思是：找到使得函数达到这个**最小值的那个参数（即 w 的值）**。

**所以，整个右边 `arg min_w { ... }` 的运算结果，就是一个特定的 w 值**。

**三、 理论推导：最优解是怎么来的？（公式8）**

公式7中，省略(λ,k)便于清晰推导：

- `x₁`：标量，参考麦克风处的**目标语音**（我们想估计的信号）
- `y`：`M×1` 向量，所有麦克风的**接收信号**
- `w`：`M×1` 向量，滤波器权重（待求）
- `𝔼{·}`：统计期望（均值）

**注意**：我们推导的是**复数信号**的最优化，需要用到**复梯度**。

**步骤1：展开目标函数**

定义目标函数（代价函数）：

> 代价函数是**针对整个训练集** 的误差，是所有样本损失的平均或总和，用来优化参数。损失函数针对单个样本。

![](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251203000103241.png)

展开平方项：

![](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251203000203081.png)

::: info 

因为信号是复数，复数的模平方等于它和它的共轭相乘，即

 ![](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251203001057798.png)

所以这里的复数是：

![](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251203001311294.png)

那么：

![](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251203001403181.png)

使用复共轭的性质：

1. **和差的共轭**：$(a-b)^* = a^* - b^*$
2. **共轭转置的共轭**：$(\mathbf{w}^H\mathbf{y})^* = \mathbf{y}^H \mathbf{w}$ （矩阵/向量的共轭转置规则）

因此：
$$
(x_1 - \mathbf{w}^H\mathbf{y})^* 
= x_1^* - (\mathbf{w}^H\mathbf{y})^*
= x_1^* - \mathbf{y}^H\mathbf{w}
$$
于是右边就变成：
$$
(x_1 - \mathbf{w}^H \mathbf{y})(x_1^{*} - \mathbf{y}^H \mathbf{w})
$$
:::

继续展开：

![](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251203002015915.png)

带入期望：

![](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251203002401452.png)

::: info

期望 = 随机变量在概率意义下的平均值，不是简单的算术平均，而是带有权重的平均——权重是该取值发生的概率。

在机器学习中，**期望（Expectation）** 的最重要应用之一就是 **风险最小化（Risk Minimization）**。

:::

**步骤2：引入协方差矩阵**

通过观察上述展开的公式，发现：

$\mathbb{E}[y y^H]$

$\mathbb{E}[x_1 y^H]$

这些东西正好就是：
$$
\Phi_{yy} = \mathbb{E}[yy^H]
$$

$$
\Phi_{xy} = \mathbb{E}[x_1y^H]
$$

::: info

$\Phi_{yy}$ 是输入向量 y 的协方差 / 自相关矩阵.

假设你的麦克风阵列有 $M$ 个通道，那么：
$$
y = 
\begin{bmatrix}
y_1 \\ y_2 \\ \vdots \\ y_M
\end{bmatrix}
$$


是 **多通道观测信号**（带噪声的）。

于是：
$$
y y^H =
\begin{bmatrix}
y_1 y_1^* & y_1 y_2^* & \dots \\
y_2 y_1^* & y_2 y_2^* & \dots \\
\vdots & & \ddots
\end{bmatrix}
$$
对每个元素取期望：
$$
\Phi_{yy}[i,j] = \mathbb{E}[\, y_i\, y_j^* \,]
$$
这就是：

👉 **通道 $i$ 和通道 $j$ 之间的相关性（或协方差）**

整矩阵表示：
 **“y 的能量 + y 通道之间的相关关系”**

这就是所谓的“噪声+语音的协方差矩阵”。













:::

这个模块负责**并行地生成两个备选的“干净”语音流**。

- **实现方式**：使用两个独立的**多通道维纳滤波器**。
    - **MWF-L**: 旨在增强来自**左侧**的说话人，并抑制右侧说话人和噪声。
    - **MWF-R**: 旨在增强来自**右侧**的说话人，并抑制左侧说话人和噪声。
- **关键点**：在此阶段，系统**并不知道**用户正在关注哪一侧。它只是“尽职”地准备好两个可能的选择，等待最终的指令。这对应于流程图中的模块 **(a)**。









好的，我们把 **3.1、3.2 和 3.3** 节放在一起，用一个完整且统一的比喻来讲解，让您彻底理解这三个核心模块是如何协同工作的。

想象一个 **“智能秘书”** 在嘈杂的会议室里帮你只听清你想听的那个人说话。这个系统的工作方式如下：

---

 🎯 **3.1 噪声抑制滤波器：两位专业的“速记员”**

*   **【他们的职责】**
    这两位速记员，一位专门负责记录**左边**的发言人（MWF-L），另一位专门负责记录**右边**的发言人（MWF-R）。他们的任务是**实时地、并行地**尽可能清晰地记录下各自负责的目标的讲话，并过滤掉对方的声音和房间里的其他杂音。

*   **【他们如何工作】**
    他们使用的工具是一个复杂的“公式”（**多通道维纳滤波器 MWF**）。这个公式能教他们如何综合所有麦克风的信息，像调整一堆旋钮一样，**放大目标方向的声音，抵消干扰方向的声音**。
    *   **核心公式**：`x̂ = w^H * y`
    *   **通俗解释**：`w` 是这套“旋钮”的最佳设置方案。它是由 `Φ_xx`（目标语音的特征）和 `Φ_rr`（噪声的特征）计算出来的。速记员的工作就是根据这些特征，应用这个最佳方案，产出初步净化的记录稿。

*   **【小结】**
    这两位速记员非常专业，但他们有个**局限**：他们只管记录自己负责的目标，**并不知道你此刻真正想听的是左边这位还是右边这位**。所以他们俩都在不停地工作，产出两份记录稿。

---

### 3.2 🔬 **相干矩阵估计器：资深的“人物特征分析师”**

*   **【他的职责】**
    这位分析师不直接参与记录，他的任务是**为上面的两位速记员提供“人物档案”**。他需要分析出：
    1.  **目标人物的声学特征**（`Φ_xx`）：左边的人声音有什么特点？右边的人声音有什么特点？
    2.  **干扰与噪声的特征**（`Φ_rr`）：房间里的空调声、另一个人的声音，有什么特点？

*   **【他如何工作】（三步法）**
    1.  **定向收音**：他使用两个**定向麦克风**（**固定波束成形器**），一个主要收左边的音，一个主要收右边的音。
    2.  **判断状态**：他雇了两个**助理**（**语音活动检测器 VAD**），分别监听这两个定向麦克风。左边的助理会在左边的人说话时举手，右边的同理。
    3.  **建立档案**：
        *   当**左边助理**举手时，分析师就知道：此刻左边定向麦克风里主要是**目标语音（左边）**，右边定向麦克风里主要是**干扰噪声（右边+环境）**。他立刻用此时的信号更新左边速记员（MWF-L）需要的“人物档案”。
        *   当**右边助理**举手时，他就为右边速记员（MWF-R）更新档案。

*   **【小结】**
    这位分析师通过“定向监听”和“状态判断”，间接地获取了纯净的目标和干扰特征，让两位速记员手中的“旋钮方案”(`w`)始终保持最佳状态。**本文假设这位分析师和他的助理是“理想的”，永不犯错**，以便集中考察最关键的部分。

---

### 3.3 🧠 **听觉注意力解码器：洞察你内心的“决策主管”**

*   **【他的职责】**
    这位主管是最终的**决策者**。他的任务非常简单：**看你一眼，就知道你此刻心里想听左边还是右边的人说话**。然后，他命令系统将对应速记员的记录稿递给你。

*   **【他如何工作】**
    *   他通过一个特殊的“读心术头盔”（**EEG设备**）来实时感知你的大脑活动。
    *   他不是一个冲动的人，他需要**观察你一小段时间**（比如**1秒钟**），收集足够的脑电数据，才会做出一个稳妥的决定（**决策窗口**）。
    *   他使用一个训练好的“直觉模型”（**CNN神经网络**）来分析这些脑电数据，最终输出指令：**“左”** 或 **“右”**。

*   **【核心挑战与权衡】**
    *   如果他观察你的时间太短（**决策窗口短**，如0.5秒），他很容易**判断失误**（准确率低），可能会把错误的记录稿递给你。
    *   如果他观察你的时间太长（**决策窗口长**，如4秒），他的决策虽然很准，但**反应太慢**（延迟高），等你拿到记录稿时，话题可能已经过去了。
    *   **因此，他的“反应速度”和“判断准确率”之间的权衡，是本文研究的绝对核心。**

---

### 3.4 💎 整体协作流程总结

现在，我们把这三个角色串联起来，看看这个“智能秘书系统”是如何工作的：

1.  **并行准备**：
    *   **人物特征分析师（3.2）** 不断为**两位速记员（3.1）** 提供最新的“人物档案”。
    *   两位速记员根据档案，并行地、高质量地记录着各自目标的讲话，产出两份初步净化的记录稿。

2.  **最终决策**：
    *   **决策主管（3.3）** 通过“读心术”判断出你当前想听谁。
    *   他发出一个简单的切换指令。

3.  **交付结果**：
    *   系统根据指令，选择对应速记员的记录稿，作为最终的语音输出给你听。

**总而言之，3.1是干活的，3.2是给干活的人提供技术支持的，3.3是做最终决定的。论文的目的，就是研究这个“做最终决定”的决策主管（3.3），他的反应速度（决策窗口）和业务能力（准确率）要达到什么水平，才能保证你最终听到的东西（语音质量和可懂度）是满意的。**

### 3.5 问题

#### Q2：噪声抑制滤波器和相干矩阵估计器的区别

🎨 核心比喻：**厨师 vs. 食材处理员**

想象一个高级餐厅的厨房，要为客人准备两道主菜（左声道和右声道）。

---

👨‍🍳 **3.1 噪声抑制滤波器 - 主厨**

*   **角色**：**两位主厨**
    *   **主厨-左**：专门烹饪左声道这道菜。
    *   **主厨-右**：专门烹饪右声道这道菜。
*   **职责**：**负责“烹饪”出最终端给客人的菜肴**。他们拿到处理好的食材，运用他们高超的厨艺（**MWF算法**），做出一道美味、干净、没有异味的菜。
*   **工作内容**：他们遵循一个固定的、最优的食谱（**公式 w^opt = Φ_yy⁻¹ Φ_xx q**）。这个食谱告诉他们如何精确地调配各种原料（麦克风信号），才能最好地突出主料（目标语音），掩盖或去除不好的味道（噪声和干扰）。
*   **关键**：他们是**最终产品的产出者**。系统最终的语音质量（PESQ）和可懂度（STOI）直接由他们的“厨艺”决定。

---

🥬 **3.2 相干矩阵估计器 - 食材处理员**

*   **角色**：**一位资深的食材处理员**
*   **职责**：**负责为主厨准备最核心的、处理好的食材**，而不是直接做菜。他的任务是：
    1.  分辨出什么是“上等主肉”（纯净的 **`Φ_xx`** - 目标语音的统计特征）。
    2.  分辨出什么是“需要剔除的筋膜和边角料”（纯净的 **`Φ_rr`** - 噪声和干扰的统计特征）。
*   **工作内容**：
    *   他使用特殊的工具（**固定波束成形器**）来对混合在一起的原始食材进行**粗分离**。
    *   他依靠经验（**语音活动检测器 VAD**）来判断什么时候拿到的是纯主肉，什么时候拿到的是纯边角料。
    *   他将这些分析好的、代表食材特征的“样品”（`Φ_xx` 和 `Φ_rr`）交给两位主厨。
*   **关键**：他是**服务和支持者**。他工作的**准确性**直接决定了主厨拿到的食谱（公式里的 `Φ_xx` 和 `Φ_rr`）是否靠谱，进而影响菜肴的最终品质。**如果他提供的食材特征有误，主厨厨艺再高也做不出好菜。**

---

💡 总结与类比

| 特性               | **3.1 噪声抑制滤波器 (主厨)**              | **3.2 相干矩阵估计器 (食材处理员)**                          |
| :----------------- | :----------------------------------------- | :----------------------------------------------------------- |
| **核心任务**       | **产出**最终增强后的语音信号。             | **估计和提供**计算所需的**统计特征**（协方差矩阵）。         |
| **在公式中的位置** | 执行公式 **`x̂ = w^H y`**，是**最终输出**。 | 计算公式 **`w^opt = Φ_yy⁻¹ Φ_xx q`** 中的 **`Φ_xx` 和 `Φ_rr`**，是**中间输入**。 |
| **依赖关系**       | 依赖于3.2提供的准确统计信息。              | 依赖于原始的麦克风信号和VAD/波束成形的性能。                 |
| **比喻**           | **烹饪**                                   | **准备食材**                                                 |

**所以，它们的根本区别是：**
*   **3.2 是“信息提供者”**，它回答“**是什么？**”（What is the target? What is the noise?）
*   **3.1 是“命令执行者”**，它回答“**怎么做？**”（How to extract the target and suppress the noise?）

在本文的实验中，作者假设 **“食材处理员”是完美的**（理想波束成形和VAD），这样就能确保如果最终“菜肴”不好吃，那问题一定不是出在食材上，而很可能是出在**决定上哪道菜的“大堂经理”（3.3 AAD）** 身上，或者“主厨”的算法本身。这就隔离了变量，让作者能专注于研究AAD的性能影响。







