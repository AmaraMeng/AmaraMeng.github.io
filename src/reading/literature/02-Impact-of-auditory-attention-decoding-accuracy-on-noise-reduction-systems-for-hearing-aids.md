---
title: 02. 听觉注意解码准确性对助听器降噪系统的影响
icon: boke
date: 2025-11-27 01:44:44
author: Ran
category:
    - reading
    - literature
isOriginal: true
sticky: false
star: false
article: true
timeline: true
image: false
navbar: true
sidebarIcon: true
comment: true
lastUpdated: true
editLink: true
backToTop: true
toc: true
---

 **Impact of auditory attention decoding accuracy on noise reduction systems  for hearing aids (2026)**

![题目及作者](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251127015134844.png)

## 摘要

Hearing aid users often struggle to focus on a specific target speaker in multi-talker environments. Auditory attention decoding (AAD) algorithms, which extract attentional cues from electroencephalogram (EEG) signals, offer a potential solution. This study evaluates **how AAD accuracy and decision window length affect the performance of a multichannel Wiener filter noise reduction system in a speaker and story-independent scenario**. Simulations in two-speaker anechoic conditions show that, for decision windows of 1 s or less, AAD accuracies approximately above 81 % are required to meet minimum conversational speech quality (PESQ = 2.0), while accuracies approximately above 64 % suffice for intelligibility (STOI = 0.62). These results define quantitative performance targets for integrating AAD-based noise reduction into hearing aids and highlight the trade-off between decision latency, decoding accuracy, and perceptual benefit under idealized beamforming/VAD and anechoic conditions with high-density EEG.

助听器使用者在多说话者环境中常常难以专注于特定的目标说话者。听觉注意解码（AAD）算法可以从脑电图（EEG）信号中提取注意线索，提供一个潜在的解决方案。本研究评估了**AAD准确率和决策窗口长度如何影响多通道维纳滤波噪声抑制系统在说话者和故事独立场景中的性能**。双说话者无回声条件下的仿真表明，对于1秒或更短的决策窗口，AAD准确率需要大约超过81%才能达到最低的会话语音质量（PESQ = 2.0），而大约超过64%的准确率就足以满足可懂度要求（STOI = 0.62）。这些结果为将基于AAD的噪声抑制集成到助听器中设定了量化的性能目标，并突出了在理想的波束形成/VAD和无回声条件下、高密度EEG环境中决策延迟、解码准确率与感知收益之间的权衡。



## 1. Introduction

### 1.1 研究背景

1. **问题背景：**

    听力损失用户在多说话人（“鸡尾酒会”）环境中难以聚焦于目标说话人，现有助听器在此方面存在不足。

2. **现有解决方案与局限：**

    **传统方法**：依赖音量、视线方向等启发式规则，在目标源不具备这些特征时效果不佳。

    **新兴技术**：基于脑电图（EEG）的**听觉注意力解码（AAD）** 技术，可直接从大脑信号中解码用户注意力。

    *   **两大技术路径**：
        
        * **神经引导的语音提取**：使用EEG信号直接引导深度学习模型从混合语音中提取目标语音。但存在模型复杂、泛化能力差（如依赖特定说话人）等问题，不适用于现实助听器。
        
        * **分离后分类**：先分离各说话人信号（提供多个备选），再用AAD选择目标。这种方法**更易于在助听器上实现**，是本文采用的技术路径。
        
            > ### **为何“更易于在助听器上实现”？**
            >
            > 与第一种“端到端”方法相比，这种模块化设计有两大优势：
            >
            > 1. **计算负载分离与降低**：
            >     - **语音分离模块**和**EEG解码模块**可以独立优化。语音分离可以使用经典的、计算效率高的信号处理算法（如MWF）。
            >     - EEG解码虽然仍需神经网络，但它的任务被简化为一个相对简单的**分类问题**（左/右），而不是复杂的语音波形重构问题。这大大降低了模型的复杂度和计算需求。
            > 2. **系统更鲁棒、更易调试**：
            >     - 每个模块的功能明确，可以单独测试和评估。如果效果不好，可以定位问题是出在“分离不准”还是“选择不对”。
            >     - 更容易集成现有的、成熟的助听器技术（如波束成形器）。

3. **核心矛盾**：AAD的**准确率**与**决策窗口长度（延迟）** 之间存在权衡。短窗口（低延迟）是实用性的关键，但会导致准确率下降。先前研究使用了**长达30秒的决策窗口**，这在现实中**完全不实用**。

4. **前人研究局限：**

    - `[12-14]`：**MWF + AAD**（与本文系统架构几乎一致）。
    - `[15]`：**双耳波束成形 + 认知驱动**（核心思想一致，技术实现不同）。
    - `[16]`：**AAD与自适应波束成形的联合模型**（更先进的集成思路）。

    **这表明：** 将神经科学与音频处理结合以增强目标语音的**核心思想并非本文首创**。

    这些研究证明了“神经导向”在**技术原理上可行**，但它们为了达到足够高的解码精度（比如90%以上），普遍依赖于**长达30秒的决策窗口**。

5. **参考的核心文献局限**

    **贡献**：它提出了一种直接用EEG对听觉注意方位（左/右）进行分类的CNN方法，并且**关键地**，它在**约1秒的决策窗口**下，达到了与以往长窗口研究相似的准确率。

    **局限：**

    - 只评估了AAD本身的分类性能，**未集成到噪声抑制系统中**评估最终语音效果。
    - 依赖需要先验知识的**伪迹去除算法** （实用中无法预先知道并标记EEG中的伪迹，如眨眼、肌肉活动）。
    - 存在**数据泄露**问题（未严格说话人独立），导致性能评估虚高。

5. **其他局限：**

    大多数研究只报告AAD分类准确率，但助听器的适用性最终取决于**语音可懂度与质量**。

### 1.2 本文贡献

**🎯 研究目标**

1. **量化影响**：研究 **AAD算法的分类准确率** 和 **决策窗口长度** 这两个关键参数，如何影响噪声抑制系统的最终性能。
2. **确定最低要求**：找到为了达到**足够的语音可懂度（intelligibility）和质量（quality）**，所需要的**AAD准确率和决策窗口长度的最低门槛**。
3. **提供设计起点**：为未来神经导向助听器的工程设计提供**量化的性能基准和起始点**，而不仅仅是理论概念。

---

**贡献一：系统集成与在严格场景下的评估**

**做了什么**：将基于多通道维纳滤波器的噪声抑制系统与基于EEG的注意力检测算法相**结合**，并在一个**说话者和故事都独立**的场景下进行评估。

- **“结合”** 验证了完整系统链路的可行性。
- **“独立”** 意味着模型在训练时**从未见过**测试时所用的说话人和故事内容。这保证了评估结果的**严谨性和泛化能力**，证明了系统能应对真实世界中未知的说话人和对话，而不是在“作弊”。

------

**贡献二：AAD模型的个性化改进**

**做了什么**：改进了文献`[17]`中的CNN模型，提出了**三级个性化微调策略**，探索了利用助听器验配过程中收集的用户特定EEG数据来提升性能。

- 证明了**少量用户数据**（在标准验配过程中可获取）能**显著提升**AAD性能。
- 为未来产品提供了一个极具操作性的性能提升路径：**“预训练通用模型 + 验配时快速微调”**。

------

**贡献三：基于客观感知指标的系统性能分析**

**做了什么**：使用**PESQ**和**STOI**这两个客观指标来分析系统输出。

- 这代表了评估范式的转变。不再只看中间的“算法准确率”，而是关注最终的“**用户体验**”。
- **PESQ**评价语音听起来是否舒适、自然（**质量**）。
- **STOI**评价语音是否能被听懂（**可懂度**）。这两个才是助听器成功的终极标准。

------

**贡献四：建立定量的性能基准**

**做了什么**：首次定量地建立了AAD准确率、决策窗口与可接受语音质量/可懂度之间的对应关系，明确了最低性能要求。

- 这是全文的**最高价值总结**。它将前三点贡献的发现，凝结成可供工程界直接使用的“设计规格书”。
- 例如，它给出了明确答案：*“如果想让助听器在1秒内反应，并且语音质量达标，那么你的AAD算法准确率必须达到81%以上。”*
- 这为整个领域设定了清晰、量化的研发目标，让后续研究不再是盲目追求“更高的准确率”，而是有针对性地攻关“在指定延迟下达到所需准确率”。

## 2. Acoustic scenario description

### 2.1 物理场景设定

这一部分描述了一个**理想化的双说话人混响场景**：

- **设备配置（假设）**：
    - 助听器佩戴在**左耳**。
    - 左耳助听器上有 **`M/2` 个麦克风**，呈线性阵列排列。
    - 右耳有一个耳模，上面也有 **`M/2` 个麦克风**。
    - 左右耳的麦克风信号通过**无线传输**同步，共同构成一个完整的 **`M` 麦克风阵列系统**。
- **麦克风捕捉到的声源与噪声**：
    - 有 **`N` 个不同的说话人**。
    - 存在**环境噪声**，包括：
        - **环境扩散声场**（如房间混响、空调声）。
        - **电路噪声**。
- **关键假设（详情见2.2）：**
    - 语音源和噪声是**遍历的**，即语音源和噪声**完全均匀混合**，而且短时内是**平稳的**，其统计特性可以在短时窗口内估计。
    - 语音与噪声之间是**不相关的**。

**目的**：这个设定模拟了未来**双耳协同**的助听器，能利用头部两侧的麦克风获取空间信息，这是实现波束成形和声源定位的基础。



### 2.2 核心数学假设（公式推导的前提）

为了能用数学工具处理这个复杂场景，论文引入了三个关键假设，这是整个理论模型的基石：

- **假设一：线性混合**

    > “The M microphones capture a **linear mixture** of speech signals...”

    - **含义**：每个麦克风接收到的信号，是各个声源信号经过其传播路径（可能衰减、延迟）后，**简单相加**的结果。忽略回声、非线性失真等复杂效应。

    - **为什么重要**：只有线性混合，才能用公式 $$y = \sum_{i=1}^N a_i s_i + n $$  来表示，这是后续所有矩阵运算和滤波器设计（如MWF）的**根本前提**。

        > **公式详解：**
        >
        > **步骤1：单个麦克风收到什么？**
        > 对于第 `m` 个麦克风，在时频点 `(λ, k)` 上：
        >
        > $$y_m=x_{m_1}+x_{m_2}+...+x_{m_N}+n_m$$
        >
        > - $y_m$：麦克风 `m` 最终录到的**总信号**。
        > - $x_{m_i}$：第 `i` 个说话人的声音传到麦克风 `m` 这里的部分。
        > - $n_m$：环境噪声和电路噪声在麦克风 `m` 处的部分。
        >
        > **步骤2：每个说话人的声音怎么来的？**
        >
        > $$x_{m_i}=a_{m_i}∗s_i$$
        >
        > - $s_i$：第 `i` 个说话人发出的**原始、纯净的语音信号**（声源处）。
        > - $a_{m_i}$：**声学传递函数**。它描述了声音从第 `i` 个说话人的嘴巴，传播到第 `m` 个麦克风的**整个过程**所发生的变化。
        > - $x_{m_i}$：最终抵达麦克风 `m` 的第 `i` 个说话人的声音。
        >
        > **步骤3：合并成向量形式**
        > 把所有 `M` 个麦克风的信号堆叠成向量，得到更简洁的表达：
        >
        > $$\vec{y}=\vec{a_1}s_1+\vec{a_2}s_2+...+\vec{a_N}s_N+\vec{n}$$ 

- **假设二：短时遍历性**

    > “It is assumed that both source activity and noise statistics are **ergodic and estimable over short-term windows**.”

    - **含义**：语音和噪声的统计特性（如均值、方差、相关性）在短时间内（例如20-40毫秒的帧内）是**平稳且可估计的**。虽然语音整体变化剧烈，但在极短的片段内，其特性相对稳定。
    - **为什么重要**：这是所有**短时傅里叶变换**和**在线估计算法**的灵魂。它允许我们将非平稳的信号切成小段，在每一段内用统计方法处理，并相信这些估计是有效的。

- **假设三：信号不相关**

    > “Furthermore, the speech sources and noise are assumed to be **uncorrelated**.”

    - **含义**：任意两个不同的声源（例如目标说话人和干扰说话人）之间，以及任何声源与背景噪声之间，它们的信号是**统计上不相关**的。一个信号的变化无法用来预测另一个信号的变化。
    - **为什么重要**：这是**多通道维纳滤波器能够奏效的最关键假设**。MWF的核心思想是利用信号与噪声在空间特性上的差异来分离它们。如果目标语音和干扰语音高度相关（比如是同一个人说的不同句子），MWF将极难分离它们。这个假设在现实中很难完全满足，但它是理论推导和获得清晰解的**必要条件**。

### 2.2 公式解读

![](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251127032915033.png)

**1. 声源与角色定义**

- **`s₁(t)`**：**目标语音信号**
    - 这是听者**主动注意并想听清**的说话人。
    - 在本文的后续心理声学实验中，听者被要求始终跟随 `s₁(t)` 的内容。
- **`s₂(t)`**：**干扰语音信号**
    - 这是听者**需要忽略**的说话人。
    - 在系统中，`s₂(t)` 被视为需要被抑制的“噪声”之一。

**重要性**：这明确了系统任务的二元性——不是抑制一般的环境噪音，而是要在**两个非常相似的人类语音**中做出选择并抑制其中一个。这是“鸡尾酒会问题”的核心挑战。

---

 **2. 空间位置设定**

- **方位角**：两个声源分别位于听者左右两侧的 **±90°** 方位。
    - 例如，`s₁(t)` 在 **+90°**（听者左侧），`s₂(t)` 在 **-90°**（听者右侧）。
- **为何选择 ±90°？**
    1. **最大化空间分离**：这是双耳听觉中**空间线索最显著**的位置。左右耳的时间差和强度差最大，最有利于基于空间位置的分离算法（如波束成形）。
    2. **简化问题**：将声源置于极端两侧，避免了正前方或后方带来的空间模糊性，使研究可以专注于评估AAD和噪声抑制本身的性能，而不受声源定位模糊的干扰。
    3. **符合典型场景**：模拟了常见的对话场景，例如在餐桌两旁与人交谈。

---

**公式 (1): 单个麦克风接收到的全部信号**

![公式1](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251127030012189.png)

- **`yₘ(λ, k)`**：在第 `m` 个麦克风的 **时频点 `(λ, k)`** 上接收到的总信号。（`λ` 是时间帧索引，`k` 是频率点索引）
- **`Σ xₘᵢ(λ, k)`**：所有 `N` 个说话人的语音信号在第 `m` 个麦克风处叠加的结果。
- **`nₘ(λ, k)`**：在第 `m` 个麦克风处收到的环境噪声和电路噪声。

> **通俗理解**：这个公式就是说，**每个麦克风听到的声音 = 所有说话人声音的混合 + 背景噪音**。对应线性混合假设。



 **公式 (2): 单个麦克风接收到的单个说话人的语音信号**

公式(2) 是公式(1) 的一部分

![公式2](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251127030905913.png)

- **`sᵢ(λ, k)`**：第 `i` 个说话人发出的**纯净语音信号**。
- **`aₘᵢ(λ, k)`**：**声学传递函数**，它模拟了第 `i` 个声源发出的声音传播到第 `m` 个麦克风这个过程所发生的变化（如衰减、延迟）。
- **`xₘᵢ(λ, k)`**：最终，第 `i` 个说话人的声音被第 `m` 个麦克风捕捉到的版本。

> **通俗理解**：一个说话人的声音从嘴里发出，经过空气传播，再到被麦克风录下，这个过程会发生改变。`aₘᵢ` 就是描述这个“改变”的函数。所以，**麦克风收到的某个说话人的声音 = 他发出的原始声音 × 传播路径的影响**。



 **公式 (3): 所有麦克风信号的向量表示**

![公式3](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251127031337699.png)

这只是把公式(1)和(2)结合起来，并用**向量形式**表示所有 `M` 个麦克风的信息，这样更简洁，也便于后续的矩阵运算。

- **`y(λ, k)`**：一个向量，包含了所有 `M` 个麦克风在时频点 `(λ, k)` 上接收到的信号 `[y₁, y₂, ..., y_M]ᵀ`。
- **`aᵢ(λ, k)`**：一个向量，包含了第 `i` 个说话人到所有 `M` 个麦克风的声学传递函数 `[a₁ᵢ, a₂ᵢ, ..., a_Mᵢ]ᵀ`。它定义了该说话人的**空间位置信息**。
- **`n(λ, k)`**：一个向量，包含了所有 `M` 个麦克风处的噪声 `[n₁, n₂, ..., n_M]ᵀ`。



 **公式 (4) & (5): 定义“期望信号”与“噪声+干扰”信号**

这里对总信号 `y(λ, k)` 进行拆分，将其明确分为“我们想要的”和“我们不想要的”两部分。

- **期望信号向量 `x(λ, k)`**：

    ![](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251127031911653.png)

    假设第一个说话人 `s₁` 是听者关注的目标。那么，所有麦克风收到的、来自 `s₁` 的信号就是期望信号。

- **干扰噪声向量 `r(λ, k)`**：

    ![公式4](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251127031932922.png)

    这个向量包含了**所有干扰说话人（`i=2` 到 `N`）的声音**加上**环境噪声**。在本文的双说话人场景中，`i=2` 就是那个干扰说话人。

- **总信号的最终简化形式**：

    ![公式5](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251127031954973.png)

    这个公式至关重要，它将复杂的声学场景**简化为一个清晰的加法模型**：**总信号 = 期望信号 + (干扰 + 噪声)**。



**公式(6)**

![公式6](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251127032631166.png)

这个公式的意思是：**系统对目标语音的最终估计值 `x̂`，等于将所有麦克风的混合信号 `y`，通过一个精心设计的多通道滤波器 `w` 进行加权组合后得到的结果。**是**多通道维纳滤波器**的核心输出公式。给出了解决方案的第一步：如何利用 `w` 从 `y` 中提取 `x̂`

- **`x̂(λ, k)`**: 这是在时频点 `(λ, k)` 上，对**参考麦克风**处**目标语音** `x₁(λ, k)` 的**估计值**。也就是我们最终想得到的、增强后的信号。它的质量（PESQ/STOI）是本文评判系统成败的唯一标准。
- **`y(λ, k)`**: 这是我们熟悉的公式(3)中定义的向量，包含了所有 `M` 个麦克风在此时频点上接收到的信号 `[y₁, y₂, ..., y_M]ᵀ`。它是算法的**输入**。
- **`w(λ, k)`**: 这是**多通道维纳滤波器**在时频点 `(λ, k)` 上的**复值权重向量** `[w₁, w₂, ..., w_M]ᵀ`。每个元素 `w_m` 对应一个麦克风。这个权重向量是算法的核心，它包含了如何整合所有麦克风信息以突出目标、抑制噪声和干扰的“知识”。
- **`(·)^H`**: 表示**埃尔米特转置**（即共轭转置）。 表示把原矩阵中每个元素求共轭再转置。因为我们在处理**复值**的频域信号，所以需要共轭转置。
- **物理意义**：`w` 的每个复数权重 `w_m` 对第 `m` 个麦克风的信号执行两项操作：
    1. **幅度缩放**：放大或减小该麦克风信号的贡献。
    2. **相位旋转**：对该麦克风信号进行微小的延迟或提前。
        **这样做的终极目的**是：让所有麦克风中**来自目标方向**的信号成分**同相叠加**（建设性干涉），而让来自干扰和噪声方向的信号成分**异相抵消**（破坏性干涉）。



💡 直观理解：

您可以把这个公式想象成一个**智能的、随时空变化的“音量调节旋钮”组合**：

- **目标**：从一堆混乱的麦克风信号 `y` 中，提取出目标说话人在参考麦克风处的干净声音 `x̂`。

- **方法**：滤波器 `w` 会对每一个麦克风的信号进行一项复杂的操作：
    - **调整幅度（缩放）**
    - **调整相位（延迟）**
    
- **最终效果**：所有经过这样精心调整后的麦克风信号被加在一起。在这个过程中，**目标说话人的声音因为其特定的空间位置（由向量 `a₁` 定义）而被同相叠加、增强**；而**噪声和干扰说话人的声音则因为来自不同方向而被异相抵消、削弱**。

    

`w` 的最终目的，是**与目标声源的空间特征向量 `a₁` 匹配**。

回忆公式(2)-(3)：目标语音在各麦克风上的接收信号是：

![](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251202202809989.png)

理想情况下，如果我们知道 `a₁`，最优权重就是：`w ∝ a` ，意思就是：最优滤波器权重 `w` 应该与目标声源的空间特征 `a` 成比例。

---

### 2.3 问题

#### Q1：公式1的时频点 (λ, k)

**1. 什么是“时频点” `(λ, k)`？**

想象一下你在看一部电影的频谱图：

- **横轴 `λ`**：代表**时间**。比如 `λ=1` 代表电影开始的第10毫秒（取决于窗口长度和重叠），`λ=2` 代表第20毫秒，以此类推。它把连续的时间切成了一帧一帧的短片段。
- **纵轴 `k`**：代表**频率**。比如 `k=1` 代表0-100Hz，`k=2` 代表100-200Hz，以此类推。它表示在这一帧时间里，声音是由哪些频率成分构成的。
- **时频点 `(λ, k)`**：就是这张图上的一个**像素点**。它精确地表示在**某个特定的短暂时间片段（λ）** 内，**某个特定频率段（k）** 上的信号**强度（或能量）**。

**所以，公式 `yₘ(λ, k)` 读作：在第 `m` 个麦克风，第 `λ` 个时间帧，第 `k` 个频率 bin 上，接收到的总信号强度。**

**2. 为什么需要时频点？（核心原因）**

**① 利用“稀疏性”假设**
如上图所示，这是最根本的原因。在任意一个**非常短的时间窗口**（例如32ms）内，**多个说话人极少会在完全相同的时间、发出完全相同的频率**。这意味着，在大多数时频点 `(λ, k)` 上，其能量主要只由**一个**占主导地位的声源（目标说话人或干扰者）贡献，其他声源在该点的能量很弱甚至为零。

**② 简化处理，允许线性滤波**
在时频域中，卷积混合（在时间域是复杂的）在窄带假设下可以近似为**瞬时混合**。这就使得公式(3)中的混合模型成立，并且可以使用像**多通道维纳滤波器（MWF）** 这样的**线性滤波器** `w(λ, k)` 来进行处理。在时间域直接进行类似的线性过滤要困难得多。

**③ 契合语音和非平稳信号的特性**
语音和噪声都是**非平稳信号**，它们的统计特性随时间变化。在时频域中，我们可以针对**每一帧（λ）** 来估计和更新信号的统计信息（如协方差矩阵 `Φ_y(λ,k)`），这让算法能够自适应地跟踪声音环境的变化。

**3. 一个生动的比喻**

把整个一段语音信号想象成一幅**完整的油画**，画上是两个人物重叠在一起。

- **在时间域分离**：就像让你不借助任何工具，直接把画上的两个人完美地剥离开，这几乎是不可能的。
- **在时频域分离**：就像用一个**高倍放大镜**，逐个像素 `(λ, k)` 地去观察这幅画。你会发现，在大多数像素点上，其实只显示了一个人物的颜色。你只需要在每个像素点上做一个简单的决定：“这个像素点更可能属于人物A还是人物B？”。
- **MWF的作用**：就是这个“决策过程”。它根据麦克风阵列收到的信息，在每个时频点上计算一个最优的权重，来提取目标信号并抑制干扰。

**总结：使用“时频点” `(λ, k)` 是一种“分而治之”的策略。它将一个全局性的、高度复杂的非线性分离问题，分解成了大量局部的、相对简单的线性估计问题，从而使得实时的、高效的噪声抑制和语音增强成为可能。**

---

#### Q2：公式6的复数权重向量

**一、为什么要引入复数？—— 一个根本问题**

**问题**：如何用一个数字 **同时** 表示一个声音的：

1. **响度**（幅度/振幅）
2. **时机**（相位/时间点）

**传统实数**：`3.0` 只能表示响度，无法表示时机。
**解决方案**：使用**复数**！一个复数可以同时打包这两个信息。

------

**二、复数的直观理解：旋转箭头**

把声音想象成一个**在转盘上旋转的箭头**：

| 概念           | 在“旋转箭头”模型中的对应                   |
| :------------- | :----------------------------------------- |
| **复数的长度** | **箭头的长度** → 代表声音的**幅度/响度**   |
| **复数的角度** | **箭头的指向** → 代表声音的**相位/时间点** |
| **复平面**     | **整个转盘**                               |



```
                   复平面（想象成一个钟面）
                         ^ 虚轴 (Imaginary)
                         |
                         |  箭头 (复数 Z)
                         |   /
                         |  / 
                         | /  长度 = 幅度
                         |/ ) 角度 = 相位
        ----------+-----------> 实轴 (Real)
                         |
                         |
```



------

 **三、复数的两种表示法**

**1. 直角坐标形式：`a + jb`**

- **`a`**：实部，表示箭头在“东西方向”的投影长度
- **`b`**：虚部，表示箭头在“南北方向”的投影长度
- **`j`**：虚数单位，`j = √(-1)`，表示“旋转90度”的操作

**例如**：`3 + 4j` 表示箭头向东3单位，向北4单位。

**2. 极坐标形式：`R \* e^(jθ)`**

- **`R`**：幅度（长度），`R = √(a² + b²)`
- **`θ`**：相位（角度），`θ = arctan(b/a)`
- **`e^(jθ)`**：表示“旋转θ角度”的数学操作

**例如**：`5 * e^(j0.93)` 表示长度为5，角度为0.93弧度（约53°）的箭头。

------

**四、在声音/信号处理中的具体含义**

当我们在时频域看到一个复数 `Z = R * e^(jθ)` 时：

**物理意义：**

- **`R`**：在这个特定频率上，声音的**强度/能量**有多大。
- **`θ`**：在这个特定时间点上，该频率分量的声波处于**振动周期的哪个位置**。

**关键理解：相位是相对的时间信息**

假设有两个麦克风收到同一个声音：

```
麦克风1：信号1 = R * e^(j*θ₁)
麦克风2：信号2 = R * e^(j*θ₂)  # 同样的幅度，但相位不同
```



**相位差 `Δθ = θ₂ - θ₁` 直接告诉你声音到达两个麦克风的**时间差！

- `Δθ = 0`：同时到达
- `Δθ > 0`：麦克风2比麦克风1晚到
- `Δθ < 0`：麦克风2比麦克风1早到

------

**五、复数的运算如何对应物理操作**

**1. 复数乘法：缩放 + 旋转**

```
Z₁ * Z₂ = (R₁ * e^(jθ₁)) * (R₂ * e^(jθ₂)) = (R₁R₂) * e^(j(θ₁+θ₂))
```

**物理意义**：

- **`R₁R₂`**：幅度被缩放（调音量）
- **`θ₁+θ₂`**：相位被旋转（调时间）

**这正是权重 `w_m` 对信号 `y_m` 的作用！**

```
w_m * y_m = (幅度_w * e^(j*相位_w)) * (幅度_y * e^(j*相位_y))
          = (幅度_w * 幅度_y) * e^(j*(相位_w + 相位_y))
```



 **2. 复数加法：矢量叠加**

```
Z₁ + Z₂ = (a₁ + jb₁) + (a₂ + jb₂) = (a₁+a₂) + j(b₁+b₂)
```

**物理意义**：两个声波在空气中相遇时，它们的压力和速度就是这样**矢量相加**的。



**3. 复数共轭：`Z\* = a - jb` 或 `R \* e^(-jθ)`**

**物理意义**：**时间反转**或**相位取反**。在公式 `w^H y` 中的 `w^H`（埃尔米特转置）就包含共轭操作，这相当于对权重进行相位反向调整来对齐信号。

------

**六、为什么权重是复数向量？**

每个复数权重对应调整一个麦克风信号，几个麦克风信号同时调整，**复数权重 `w_m` 对第 m 个麦克风信号做两件事：**

```bash
w_m = A_m * e^(j*θ_m)
      ↑           ↑
  幅度缩放因子    相位旋转因子
```

- **`A_m`**（实数部分）：控制**放大或衰减**多少，调节该麦克风信号的“音量”
- **`θ_m`**（相位角）：控制**延迟或提前**多少时间，它与其他麦克风的信号在时间上对齐

**而“向量” `w` 则是：**

![](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251202202337174.png)

- 一个包含 `M` 个复数的列表
- 每个复数对应一个麦克风，针对性调整
- 整个向量编码了**如何利用所有麦克风的空间分布信息**来提取目标声音





## 3. AAD-based noise reduction system

相关文献[12]关注说话人分离这个步骤：

```bash
麦克风信号 → 盲源分离系统 → 分离出的两个语音流
           (ICA或DNN)       (目标语音近似 + 干扰语音近似)
```

**两种实现技术**

 **① 独立成分分析 （ICA）**

- **原理**：一种经典的统计方法。假设各个源信号在统计上**相互独立**，通过寻找一个变换矩阵，使得输出信号的独立性最大化。
- **优点**：数学理论清晰，无需训练数据。
- **缺点**：对假设敏感（现实中语音信号不完全独立，两个同时说话的人的语音信号在统计上并不完全独立，分离效果可能不理想），计算复杂，分离质量有限。

 **② 深度神经网络（DNN）**

- **原理**：使用大量带标签的混合-纯净语音数据对，训练一个神经网络直接学习从混合信号到分离信号的映射。
- **优点**：分离质量通常比ICA高，能学习复杂的声学模式。
- **缺点**：需要大量训练数据，模型复杂，可能过拟合，泛化能力存疑，可能不适合助听器上的实时处理。

---

**基于解码-相关性”的传统AAD方法**

该方法分三步走：

- **解码重建**：从所有EEG通道中，重建出用户正在关注的**目标说话人的语音包络**（声音的强度轮廓）。
- **计算相关**：将重建出的包络，分别与**两个已知的说话人**各自的语音包络计算**皮尔逊相关系数**。
- **选择目标**：**相关系数更高**的那个说话人，即被判定为用户注意的目标。

- **局限**：性能**极度依赖决策窗口长度**。

    **原因**：从EEG重建的包络**信噪比极低**，在短时间窗口下估计的相关系数**非常不稳定、噪声大**。

---

由于文献 [17] 中，通过卷积神经网络利用EEG信号检测听觉注意力的焦点，而不使用干净语音包络信息，使用大约1秒的决策窗口，也达到了相同范围的准确率。本文提出一种将多通道波束形成（MWF）与基于脑电图（EEG）的算法结合，用于检测听觉注意力位置的降噪系统。

两个信号分别位于左右两侧，一个为目标信号，一个为干扰信号。

![](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251127033944881.png)



### 3.1 噪声抑制滤波器

对应图中红框部分。

这个模块负责**并行地生成两个备选的“干净”语音流**。

- **实现方式**：使用两个独立的**多通道维纳滤波器**。
    - **MWF-L**: 旨在增强来自**左侧**的说话人，并抑制右侧说话人和噪声。
    - **MWF-R**: 旨在增强来自**右侧**的说话人，并抑制左侧说话人和噪声。
- **关键点**：在此阶段，系统**并不知道**用户正在关注哪一侧。它只是“尽职”地准备好两个可能的选择，等待最终的指令。这对应于流程图中的模块 **(a)**。



 **一、 目标：我们想做什么？**

回顾公式(5)：`y = x + r`

- `y`：麦克风收到的**混合信号**（向量）
- `x`：我们想要的**目标语音**在麦克风上的信号（向量）
- `r`：我们想消除的**干扰+噪声**（向量）

**我们的终极目标**：设计一个“魔法过滤器” `w`，把它作用在混合信号 `y` 上，能最大程度地保留 `x`，同时滤除 `r`。
用数学表示，就是找到一个滤波器 `w`，使得输出：

![](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251202230646430.png)

尽可能接近我们想要的 `x₁`（即目标语音在**参考麦克风**处的信号）。

---

**二、 核心思想：如何设计最优过滤器？—— MMSE准则**

我们如何判断一个过滤器 `w` 是好是坏？需要一个**优化准则**。

论文采用工程中最经典、最直观的准则：**最小均方误差**。

> **思想**：让过滤器估计出的语音 `x̂`，与真实的干净语音 `x₁` 之间的**平均平方误差**最小。

**数学表达（公式7）**：

![公式7](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251202230951519.png)

**解读**：

- `𝔼{·}`：求期望（长期平均），表示我们关心的是**统计平均性能**，而不是某一次的偶然。
- `|·|²`：取模的平方，用来度量误差的大小。
- `x₁ - w^H y`：就是**估计误差**。
- `arg min`：寻找能使这个平均平方误差最小的那个权重向量 `w`。

 **左边：`w(λ,k)`**

- 这是我们要求解的、**未知的滤波器权重向量**。
- 它本身就是我们想要的结果。

**右边：`arg min_w { ... }`**

- 这是一个**算子**，它作用于一个**函数**（大括号里的均方误差函数）。
- **`min_w`** 的意思是：找到这个函数的**最小值**。
- **`arg`** 的意思是：找到使得函数达到这个**最小值的那个参数（即 w 的值）**。

**所以，整个右边 `arg min_w { ... }` 的运算结果，就是一个特定的 w 值**。

---

**三、 理论推导：最优解是怎么来的？（公式8）**

公式7中，省略(λ,k)便于清晰推导：

- `x₁`：标量，参考麦克风处的**目标语音**（我们想估计的信号）
- `y`：`M×1` 向量，所有麦克风的**接收信号**
- `w`：`M×1` 向量，滤波器权重（待求）
- `𝔼{·}`：统计期望（均值），不能最小化**一次具体实验的误差**，而要最小化**长期的、平均的误差**。这就是引入 **`𝔼{·}`（期望/均值）** 的根本原因。



- **步骤1：展开目标函数**

定义目标函数（代价函数）：

> 代价函数是**针对整个训练集** 的误差，是所有样本损失的平均或总和，用来优化参数。损失函数针对单个样本。

![](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251203000103241.png)

展开平方项：

![](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251203000203081.png)

::: info 

因为信号是复数，复数的模平方等于它和它的共轭相乘，即

 ![](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251203001057798.png)

所以这里的复数是：

![](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251203001311294.png)

那么：

![](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251203001403181.png)

使用复共轭的性质：

1. **和差的共轭**：$(a-b)^* = a^* - b^*$
2. **共轭转置的共轭**：$(\mathbf{w}^H\mathbf{y})^* = \mathbf{y}^H \mathbf{w}$ （矩阵/向量的共轭转置规则）

因此：
$$
(x_1 - \mathbf{w}^H\mathbf{y})^* 
= x_1^* - (\mathbf{w}^H\mathbf{y})^*
= x_1^* - \mathbf{y}^H\mathbf{w}
$$
于是右边就变成：
$$
(x_1 - \mathbf{w}^H \mathbf{y})(x_1^{*} - \mathbf{y}^H \mathbf{w})
$$
:::



继续展开：

![](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251203002015915.png)

带入期望：

![](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251203002401452.png)



::: info

在信号处理的许多问题中（特别是线性滤波问题），**二阶统计量（相关函数、协方差）包含了我们需要的全部信息**。这是因为：

- 对于**高斯过程**，二阶统计量完全决定了其分布
- 即使对于非高斯信号（如语音），在**最小均方误差（MMSE）准则下的最优线性滤波器**也**只依赖于二阶统计量**

**二阶统计量**指的就是各种 **“相关”** 和 **“协方差”**：

上述公式拆分出 4 项：

- $\mathbb{E}[x_1 x_1^*]$：目标语音信号自身的平均功率，物理意义是**原始目标语音有多响**（平均而言）。

- $\mathbb{E}[x_1 y^H]w$：$\mathbb{E}[x_1 y^H]$ 是一个 **`1×M` 的行向量**。它的第 `m` 个元素是 $\mathbb{E}[x_1 y_m^*]$ ，表示**原始目标语音信号** `x₁` 与**第 m 个麦克风接收到的信号** $y_m$ 的**互相关**（零延迟时），总体是两个信号之间的平均相关性。

    ![](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251203125052791.png)

    

- $w^H\mathbb{E}[y x_1^*]$：正是第二项的共轭转置。（原理：$(a^H b)^H = b^H a$ ）

- $w^H\mathbb{E}[y y^H]w$ ：$\mathbb{E}[y y^H]$ 是一个 **`M×M` 的矩阵**。它的 `(m,n)` 元素是  $\mathbb{E}[y_m y_n^H]$ ，表示**第 m 个麦克风信号**与**第 n 个麦克风信号**的**互相关**。这个矩阵编码了**所有麦克风信号之间的空间相关结构**。

:::



**带入期望将问题从“随机变量”转化为“确定参数”**

原始问题中，`x₁` 和 `y` 是**随机变量**（每次实验都不同）。经过取期望 `𝔼{·}` 后：

- 不再是随机变量，而是**确定的数值/矩阵**（假设我们知道真实的统计量）。
- 这意味着 `J(w)` 现在只是 **`w` 的确定函数**，我们可以用标准的微积分方法求其最小值。

> **类比**：如果我们说“最小化学生的考试成绩”，这是模糊的（每个学生不同）。但如果说“最小化全班的平均成绩”，这就是一个明确的数学问题。



::: info

期望 = 随机变量在概率意义下的平均值，不是简单的算术平均，而是带有权重的平均——权重是该取值发生的概率。

在机器学习中，**期望（Expectation）** 的最重要应用之一就是 **风险最小化（Risk Minimization）**。

:::



**步骤2：引入协方差矩阵**

通过观察上述展开的公式，发现：

第一项跟 $\mathbf w$ 无关，是常数 C。

为了简洁，作者给这几个期望起名字：

$\mathbf\Phi_{yy} = \mathbb E\{\mathbf y\mathbf y^H\}$  —— 含噪声的相干矩阵（所有麦克风收到的声音，y 是向量）

$\mathbf\Phi_{xx} = \mathbb E\{\mathbf x\mathbf x^H\}$  —— 纯语音（无噪声）的相干矩阵（所有麦克风收到的目标声音，x 是向量）

还会用到 $\mathbf\Phi_{yx} = \mathbb E\{\mathbf y\mathbf x^H\}$ 等。

同时定义
$$
x_1 = \mathbf q^H\mathbf x,\quad \mathbf q=[1,0,0,\dots]^T
$$
也就是“从 $\mathbf x$ 这堆麦克风信号里，挑第 1 个出来”。

::: info

因为在双耳情况下：

- 左耳重建用左耳第一个麦克风作为 reference
- 右耳重建用右耳第一个麦克风作为 reference

为什么选第 1 个通道？
 因为那是“耳道入口最接近真实自然听感的位置”。

:::

有了 $\mathbf q$ 之后，其中两项可以写成矩阵形式（可以先当作“换个写法”）：

- 第 2 项中 $\mathbb E\{x_1\mathbf y^H\}    =\mathbf q^H\mathbb E\{\mathbf x\mathbf y^H\}    =\mathbf q^H\mathbf\Phi_{xy}$

- 第 3 项中 $\mathbb E\{\mathbf y x_1^*\}    =\mathbb E\{\mathbf y (\mathbf q^H\mathbf x)^*\}    =\mathbb E\{\mathbf y\mathbf x^H\}\mathbf q    =\mathbf\Phi_{yx}\mathbf q$ 

于是代回去：
$$
J(\mathbf w)
= C -\mathbf q^H\mathbf\Phi_{xy}\mathbf w
    -\mathbf w^H \mathbf\Phi_{yx}\mathbf q
    +\mathbf w^H \mathbf\Phi_{yy}\mathbf w
$$


**步骤3：丢掉与 $\mathbf w$ 无关的常数**

我们是在 **调节 $\mathbf w$**，让 $J(\mathbf w)$ 最小。

- 第 1 项 $C$ 完全不含 $\mathbf w$，不管 $\mathbf w$ 取什么值，C 都不变；
- 所以它不会影响“最小值出现在什么地方”。

所以我们可以 **忽略第 1 项**，只保留和 $\mathbf w$ 有关的 3 项，写成
$$
\tilde J(\mathbf w)
= -\mathbf w^H \mathbf\Phi_{yx}\mathbf q
  -\mathbf q^H\mathbf\Phi_{xy}\mathbf w
  +\mathbf w^H \mathbf\Phi_{yy}\mathbf w.
$$
只要把这个 $\tilde J(\mathbf w)$ 最小化，得到的 $\mathbf w$ 和原来的 $J(\mathbf w)$ 的最优 $\mathbf w$ 是一样的。



::: info

**用“抛物线”直觉理解最小值条件**

先用一维的直觉帮你抓住要点：

- 一维二次函数：
    $$
    f(x)=ax^2-2bx
    $$
    画出来就是个“碗形”的抛物线。

- 它的最小值出现在“斜率为 0 的地方”，也就是：
    $$
    f'(x)=2ax-2b=0 \quad\Rightarrow\quad x = \frac{b}{a}.
    $$

向量情况下，其实做的是同样的事：

- $\mathbf w$ 不再是一个数，而是一串权重（向量）；
- 斜率不再是一个数，而是一个“梯度向量”；
- “最小值点”依然满足：**梯度 = 0**。

所以我们要做的就是——**对 $\tilde J(\mathbf w)$ 对 $\mathbf w$ 求“偏导/梯度”，让它等于 0。**

先把这当成一个“操作步骤/配方”，不必深究复杂向量求导的证明。

:::



**步骤4：套用“配方”求梯度**

我们现在的目标函数（省略常数）是：
$$
\tilde J(\mathbf w)
= -\mathbf w^H \mathbf\Phi_{yx}\mathbf q
  -\mathbf q^H\mathbf\Phi_{xy}\mathbf w
  +\mathbf w^H \mathbf\Phi_{yy}\mathbf w
$$
是对 $\mathbf w$ 的函数。

第 1 项和第 2 项这种的称为“线性项” = 斜坡（推动 w 往某个方向走）

它们就是“给碗加一股推力”，让最小值不在中心，而偏向某个方向。

对于线性项来说，求导配方为：
$$
\frac{\partial}{\partial \mathbf w^*}(\mathbf w^H \mathbf a)=\mathbf a
$$
翻译成生活话：

> 如果代价函数里有“斜坡项”，它的梯度就是“斜坡方向”。

因此第 1项对 $\mathbf w^*$ 求导：
$$
\frac{\partial}{\partial \mathbf w^*}(-\mathbf w^H \mathbf\Phi_{yx}\mathbf q)
= -\mathbf\Phi_{yx}\mathbf q
$$


::: info

**为什么对 $\mathbf w^*$ 求导，而不是对 $\mathbf w^H$ 求导？**

1. **变量的自然形式**：
     我们优化的是列向量 $\mathbf w$，
     $\mathbf w^*$ 也是列向量 → 梯度形式统一。
     而 $\mathbf w^H$ 是行向量，不适合作为“变量”。
2. **复数优化的标准做法**：
     在复数场景中，把 $\mathbf w$ 和 $\mathbf w^*$ 当成独立变量，
     对实值函数 J，有
     $\displaystyle \frac{\partial J}{\partial \mathbf w^*}=0$ 作为极小条件。
     所以大家都对 $\mathbf w^*$ 求导。
3. **wᴴ 只是 w\* 的转置**：
     就像 x² 只是 x 的函数一样，
     我们不会“对 x² 求导”，而是对 x 求导。

:::



第 2 项 $-\mathbf q^H\mathbf\Phi_{xy}\mathbf w$ 对 $\mathbf w^*$ 求导：

**只含 w 的项**（比如 $-\mathbf q^H\mathbf\Phi_{xy}\mathbf w$）
 👉 对 $\mathbf w^*$ 求导 = 0

**含 w\* 的项**（比如 $-\mathbf w^H \dots$，因为 $ \mathbf w^H = (\mathbf w^*)^T$）
 👉 对 $\mathbf w^*$ 求导会产生非零结果

因此该项为 0。



第 3 项 $\mathbf w^H \mathbf\Phi_{yy}\mathbf w$ 对 $\mathbf w^*$ 求导：

因为这一项是“二次型“，套用配方公式：
$$
\frac{\partial}{\partial \mathbf w^*}(\mathbf w^H\mathbf A\mathbf w)
= \mathbf A\mathbf w +\mathbf A^H\mathbf w
$$

> 如果 A 是 Hermitian（信号处理中常常是），就变成 2Aw。

而 $\mathbf\Phi_{yy}$ 就是 Hermitian，因此：
$$
\frac{\partial}{\partial \mathbf w^*}(\mathbf w^H\mathbf\Phi_{yy}\mathbf w)
= 2\mathbf\Phi_{yy}\mathbf w
$$


所以最后总梯度是：
$$
\frac{\partial \tilde J}{\partial \mathbf w^*}
= \underbrace{-\mathbf\Phi_{yx}\mathbf q}_{\text{来自第 1 项}}
  \;+\; \underbrace{0}_{\text{第 2 项}}
  \;+\; \underbrace{2\mathbf\Phi_{yy}\mathbf w}_{\text{第 3 项}}
$$
**步骤5：极小值条件即让梯度 = 0**

“找到最优的 $\mathbf w$” 等价于“找到让代价函数最小的点”，
 对二次函数来说，就是让梯度为 0：
$$
\frac{\partial \tilde J}{\partial \mathbf w^*} = 0
$$
所以有：
$$
-\mathbf\Phi_{yx}\mathbf q
+ \mathbf\Phi_{yy}\mathbf w = 0
$$
把式子整理一下：
$$
\mathbf\Phi_{yy}\mathbf w
= \mathbf\Phi_{yx}\mathbf q
$$
这就是一个**线性方程组**，未知量是 $\mathbf w$（一个 M 维列向量）。

- $\mathbf\Phi_{yy}$：$M\times M$ 矩阵
- $\mathbf w$：$M\times 1$
- $\mathbf\Phi_{yx}\mathbf q$：$M\times 1$



解这个线性方程组：得到 w 的闭式解。

和一维情况类似：

- 一维：$a x = b \Rightarrow x = a^{-1} b$（前提是 a≠0）
- 矩阵版本：$\mathbf A \mathbf w = \mathbf b \Rightarrow \mathbf w = \mathbf A^{-1} \mathbf b$（前提是 $\mathbf A$ 可逆）

这里直接套用：
$$
\mathbf\Phi_{yy}\mathbf w
= \mathbf\Phi_{yx}\mathbf q
\quad\Rightarrow\quad
\mathbf w^{\text{opt}}
= \mathbf\Phi_{yy}^{-1}\mathbf\Phi_{yx}\mathbf q
$$
这就是**在均方误差意义下的最优滤波器**（多通道 Wiener 形式）。



**步骤6：从$\mathbf\Phi_{yx}\mathbf q$ 变成 $\mathbf\Phi_{xx}\mathbf q$**

回顾公式 5：
$$
\mathbf y = \mathbf x + \mathbf r
$$
回顾定义：
$$
\mathbf\Phi_{yx}
= \mathbb E\{\mathbf y \mathbf x^H\}
$$
把 $\mathbf y = \mathbf x + \mathbf r$ 代进去：
$$
\mathbf\Phi_{yx}
= \mathbb E\{(\mathbf x+\mathbf r)\mathbf x^H\}
= \mathbb E\{\mathbf x\mathbf x^H\}
 +\mathbb E\{\mathbf r\mathbf x^H\}
$$

- 第二项：$\mathbb E\{\mathbf r\mathbf x^H\}$
     因为“目标语音”和“噪声/干扰”假设不相关 → 这一项 ≈ 0
- 第一项：$\mathbb E\{\mathbf x\mathbf x^H\}$
     就是目标语音的相干矩阵：

$$
\mathbf\Phi_{xx}
= \mathbb E\{\mathbf x\mathbf x^H\}
$$

于是：
$$
\mathbf\Phi_{yx} \approx \mathbf\Phi_{xx}
$$
代回 w 的公式：
$$
\mathbf w^{\text{opt}}
= \mathbf\Phi_{yy}^{-1}\mathbf\Phi_{yx}\mathbf q
\approx \mathbf\Phi_{yy}^{-1}\mathbf\Phi_{xx}\mathbf q
$$


这一步我们得到滤波器的最优解。

把最优的 $\mathbf w^{\text{opt}}$ 代进去：

代入：
$$
\hat x_1 
= (\mathbf w^{\text{opt}})^H\,\mathbf y
= (\mathbf\Phi_{yy}^{-1}\mathbf\Phi_{xx}\mathbf q)^H \mathbf y.
$$
注意到：

- $(AB)^H = B^H A^H$
- $\mathbf\Phi_{yy}$、$\mathbf\Phi_{xx}$ 是协方差 / 相干矩阵 → Hermitian：$\mathbf\Phi^H = \mathbf\Phi$
- $\mathbf\Phi_{yy}^{-1}$ 也是 Hermitian 的逆，所以 $(\mathbf\Phi_{yy}^{-1})^H = \mathbf\Phi_{yy}^{-1}$

于是：
$$
(\mathbf\Phi_{yy}^{-1}\mathbf\Phi_{xx}\mathbf q)^H
= \mathbf q^H \mathbf\Phi_{xx} \mathbf\Phi_{yy}^{-1}.
$$
所以：
$$
\boxed{
\hat x_1
= \mathbf q^H \mathbf\Phi_{xx}\mathbf\Phi_{yy}^{-1} \mathbf y
}
$$
这就是“最优 $\mathbf w$”代回去后的显式形式。



$\hat x_1$ 就是：
 用全部麦克风的观测 $\mathbf y$
 通过一组线性权重 $\mathbf w^{\text{opt}}$ 加权之后，
 **去尽可能逼近 “第 1 个麦克风上，只存在目标语音时的信号 $x_1$”**。

---

### 3.2 相干矩阵估计器

对应图中蓝框的 b  部分。

![](./02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.assets/image-20251203162048571.png)



- 有一套 MWF 专门估计“左边说话人”的 $\hat x_1^{(L)}$
- 另一套 MWF 专门估计“右边说话人”的 $\hat x_1^{(R)}$

它们都是用刚刚推到的那种形式：
$$
\mathbf w^{\text{opt}} = \Phi_{yy}^{-1}\Phi_{xx}\mathbf q
$$
只不过：

- 对“左 MWF”，$\Phi_{xx}$ 是“左说话人”作为目标时的协方差
- 对“右 MWF”，$\Phi_{xx}$ 是“右说话人”作为目标时的协方差

要算出这个 $\mathbf w^{\text{opt}}$，你至少得知道：

- $\Phi_{yy}(\lambda,k)$：观测的协方差（从麦克风信号 y 来）
- $\Phi_{xx}(\lambda,k)$ 或 $\Phi_{rr}(\lambda,k)$：目标和/或噪声的协方差

**这一步（两个 beamformer + 两个 VAD + whitening）干的事就是：帮每个 MWF把它那份  $\Phi_{rr}$（噪声协方差）估出来**。



::: info

在实验里 ，我们事先知道 $\Phi_{xx}$ ，也知道噪声  $\Phi_{rr}$。

 **“oracle（上帝视角）MWF”**，很多论文会用它来当 **性能上限**。
 比如：

- 直接用干净的 $\mathbf x$ 算 $\Phi_{xx}$
- 用干净的 $\mathbf r$ 算 $\Phi_{rr}$
- 然后算出“理想 MWF”



但是**算法在真实工作时是看不到这些的**，它只能看到的是：
 👉 麦克风阵列的观测 $\mathbf y = \mathbf x + \mathbf r$。

所以：**观测 y 是现实世界里唯一能用的输入**。

:::

---

**为什么要“两个 beamformer + 两个 VAD”？**

系统里有两个说话人：左 & 右，每一侧各有一个 MWF：

- 左 MWF：目标 = 左说话人，噪声 = 右说话人 + 背景
- 右 MWF：目标 = 右说话人，噪声 = 左说话人 + 背景

那么：

- 左 MWF 需要一份 “**从左的视角看** 的噪声协方差” $\Phi_{rr}^{(L)}$
- 右 MWF 需要一份 “**从右的视角看** 的噪声协方差” $\Phi_{rr}^{(R)}$

而你实际能观测的，只有多通道混合 $\mathbf y$。
 于是他们做了这样一个工程套路：

1. **两个固定波束形成器：**
    - BF-L：指向左，压制右
    - BF-R：指向右，压制左
         → 目的是：得到两个“更偏向某一边”的观测通道
2. **每个 BF 输出上挂一个 VAD：**
    - VAD-L：在 BF-L 输出上，分出
        - “有左说话人”帧
        - “只有右说话人/噪声”帧（可视为左视角的“噪声段”）
    - VAD-R 同理
3. **用这些“噪声段”的 STFT 统计 → 估计对应的 Φ_rr(λ,k)**
    - 左 MWF 用左视角的 Φ_rr^(L)
    - 右 MWF 用右视角的 Φ_rr^(R)

所以这一整步的作用可以一句话概括为：

> 用“会看左/看右的两个 beamformer + 各自的 VAD”
>  把时频点分成“属于这一侧说话人 / 不属于”
>  再用“属于噪声的一堆帧”去算协方差，
>  **从而为每个 MWF 提供它所需的噪声统计。**



因为想知道 AAD + MWF 这个框架，最多能做到什么程度。又想**尽量避免**“实际 VAD、实际 BF 估得很烂”带来的干扰，
 所以在实验中假设：

- 波束形成器是理想的
- VAD 也是理想的
     → 这样就尽可能保证 $\Phi_{rr}$ 估计得很好。

---

### 3.3. 听觉注意解码器

**AAD 在干嘛？**

原文：

> The AAD (Fig. 2c) applies a decoding procedure, employing the
>  available EEG channels, to detect which side (left/right) is of interest to
>  the hearing aid user.

翻成大白话：

- AAD = Auditory Attention Decoding：**听觉注意解码**。
- 它的输入是：**多个 EEG 通道**（脑电信号）。
- 它的输出是：**用户现在在注意哪一边（左还是右）**。

也就是：

> 用脑电信号“读心”：判断你是在听左边的人还是右边的人。



**整条链现在可以这样看：**

1. 麦克风阵列 → 两个 MWF（左/右） → 两路增强语音：
    - $\hat x^{(L)}$
    - $\hat x^{(R)}$
2. 同时，大脑对左/右说话人的注意 → 反映在 EEG 中 → AAD 解码
3. AAD 用一个固定长度的时间窗口（比如 N 秒）去**持续判断**：
    - 这 N 秒内，用户更注意左还是右？
4. AAD 的判断结果（左/右）是一个二值信号，
     → 用来控制“到底播 $\hat x^{(L)}$ 还是 $\hat x^{(R)}$”。
5. 因为要等完 N 秒的数据才能做一次决策 → 产生约 N 秒的延迟。

---

### 3.5 问题

#### Q3：噪声抑制滤波器和相干矩阵估计器的区别

🎨 核心比喻：**厨师 vs. 食材处理员**

想象一个高级餐厅的厨房，要为客人准备两道主菜（左声道和右声道）。

---

👨‍🍳 **3.1 噪声抑制滤波器 - 主厨**

*   **角色**：**两位主厨**
    *   **主厨-左**：专门烹饪左声道这道菜。
    *   **主厨-右**：专门烹饪右声道这道菜。
*   **职责**：**负责“烹饪”出最终端给客人的菜肴**。他们拿到处理好的食材，运用他们高超的厨艺（**MWF算法**），做出一道美味、干净、没有异味的菜。
*   **工作内容**：他们遵循一个固定的、最优的食谱（**公式 w^opt = Φ_yy⁻¹ Φ_xx q**）。这个食谱告诉他们如何精确地调配各种原料（麦克风信号），才能最好地突出主料（目标语音），掩盖或去除不好的味道（噪声和干扰）。
*   **关键**：他们是**最终产品的产出者**。系统最终的语音质量（PESQ）和可懂度（STOI）直接由他们的“厨艺”决定。

---

🥬 **3.2 相干矩阵估计器 - 食材处理员**

*   **角色**：**一位资深的食材处理员**
*   **职责**：**负责为主厨准备最核心的、处理好的食材**，而不是直接做菜。他的任务是：
    1.  分辨出什么是“上等主肉”（纯净的 **`Φ_xx`** - 目标语音的统计特征）。
    2.  分辨出什么是“需要剔除的筋膜和边角料”（纯净的 **`Φ_rr`** - 噪声和干扰的统计特征）。
*   **工作内容**：
    *   他使用特殊的工具（**固定波束成形器**）来对混合在一起的原始食材进行**粗分离**。
    *   他依靠经验（**语音活动检测器 VAD**）来判断什么时候拿到的是纯主肉，什么时候拿到的是纯边角料。
    *   他将这些分析好的、代表食材特征的“样品”（`Φ_xx` 和 `Φ_rr`）交给两位主厨。
*   **关键**：他是**服务和支持者**。他工作的**准确性**直接决定了主厨拿到的食谱（公式里的 `Φ_xx` 和 `Φ_rr`）是否靠谱，进而影响菜肴的最终品质。**如果他提供的食材特征有误，主厨厨艺再高也做不出好菜。**

---

💡 总结与类比

| 特性               | **3.1 噪声抑制滤波器 (主厨)**              | **3.2 相干矩阵估计器 (食材处理员)**                          |
| :----------------- | :----------------------------------------- | :----------------------------------------------------------- |
| **核心任务**       | **产出**最终增强后的语音信号。             | **估计和提供**计算所需的**统计特征**（协方差矩阵）。         |
| **在公式中的位置** | 执行公式 **`x̂ = w^H y`**，是**最终输出**。 | 计算公式 **`w^opt = Φ_yy⁻¹ Φ_xx q`** 中的 **`Φ_xx` 和 `Φ_rr`**，是**中间输入**。 |
| **依赖关系**       | 依赖于3.2提供的准确统计信息。              | 依赖于原始的麦克风信号和VAD/波束成形的性能。                 |
| **比喻**           | **烹饪**                                   | **准备食材**                                                 |

**所以，它们的根本区别是：**
*   **3.2 是“信息提供者”**，它回答“**是什么？**”（What is the target? What is the noise?）
*   **3.1 是“命令执行者”**，它回答“**怎么做？**”（How to extract the target and suppress the noise?）

在本文的实验中，作者假设 **“食材处理员”是完美的**（理想波束成形和VAD），这样就能确保如果最终“菜肴”不好吃，那问题一定不是出在食材上，而很可能是出在**决定上哪道菜的“大堂经理”（3.3 AAD）** 身上，或者“主厨”的算法本身。这就隔离了变量，让作者能专注于研究AAD的性能影响。



## 4. Methodology

本节介绍了基于 MWF 和 AAD 的降噪架构在 N=2 说话者情况下的潜在性能评估。

### 4.1 数据集规格































