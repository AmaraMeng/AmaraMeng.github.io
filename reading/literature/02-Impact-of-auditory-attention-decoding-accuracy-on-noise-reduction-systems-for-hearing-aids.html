<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.24" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.95" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"02. 听觉注意解码准确性对助听器降噪系统的影响","image":[""],"datePublished":"2025-11-27T01:44:44.000Z","dateModified":"2025-12-01T15:19:56.000Z","author":[{"@type":"Person","name":"Ran"}]}</script><meta property="og:url" content="https://pythiaroot.com/reading/literature/02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.html"><meta property="og:site_name" content="Pythia’s Root"><meta property="og:title" content="02. 听觉注意解码准确性对助听器降噪系统的影响"><meta property="og:description" content="Impact of auditory attention decoding accuracy on noise reduction systems for hearing aids (2026) 题目及作者题目及作者 摘要 Hearing aid users often struggle to focus on a specific target sp..."><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2025-12-01T15:19:56.000Z"><meta property="article:author" content="Ran"><meta property="article:published_time" content="2025-11-27T01:44:44.000Z"><meta property="article:modified_time" content="2025-12-01T15:19:56.000Z"><link rel="icon" href="/logo.jpg"><title>02. 听觉注意解码准确性对助听器降噪系统的影响 | Pythia’s Root</title><meta name="description" content="Impact of auditory attention decoding accuracy on noise reduction systems for hearing aids (2026) 题目及作者题目及作者 摘要 Hearing aid users often struggle to focus on a specific target sp...">
    <link rel="preload" href="/assets/style-fescsFu7.css" as="style"><link rel="stylesheet" href="/assets/style-fescsFu7.css">
    <link rel="modulepreload" href="/assets/app-BAzPzQ_Y.js"><link rel="modulepreload" href="/assets/02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.html-BfNEYSH7.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/assets/index.html-CLthRhCq.js" as="script"><link rel="prefetch" href="/assets/intro.html-0R6Yz4hQ.js" as="script"><link rel="prefetch" href="/assets/Cao-jing-JYM.html-DRiIKzkj.js" as="script"><link rel="prefetch" href="/assets/01-Ch1.html-CYyNXu2f.js" as="script"><link rel="prefetch" href="/assets/01-basic-math-knowledge.html-DliiXaxU.js" as="script"><link rel="prefetch" href="/assets/00-python-tips.html-BfztCNUC.js" as="script"><link rel="prefetch" href="/assets/01-variable.html-CYRSD-CM.js" as="script"><link rel="prefetch" href="/assets/02-data-type.html-CKebEtZx.js" as="script"><link rel="prefetch" href="/assets/02-test-variable-datatype.html-aTzhlUc-.js" as="script"><link rel="prefetch" href="/assets/03-numeric-type.html-gDSyGjrC.js" as="script"><link rel="prefetch" href="/assets/04-string.html-BZ4gLLZw.js" as="script"><link rel="prefetch" href="/assets/05-list.html-8IBpvjcW.js" as="script"><link rel="prefetch" href="/assets/06-tuple.html-IOPCjQZY.js" as="script"><link rel="prefetch" href="/assets/07-dict.html-NlfaHHxB.js" as="script"><link rel="prefetch" href="/assets/08-set.html-LLgYt76-.js" as="script"><link rel="prefetch" href="/assets/09-bool.html-mLxqrVHj.js" as="script"><link rel="prefetch" href="/assets/10-if.html-CcDKFXk9.js" as="script"><link rel="prefetch" href="/assets/11-while.html-bJylzI-x.js" as="script"><link rel="prefetch" href="/assets/12-for.html-ByFL21mz.js" as="script"><link rel="prefetch" href="/assets/13-functions.html-C0VYgYOi.js" as="script"><link rel="prefetch" href="/assets/14-class.html-C9Ztp1gt.js" as="script"><link rel="prefetch" href="/assets/15-environment.html--wKrN8TI.js" as="script"><link rel="prefetch" href="/assets/16-python3-errors-and-exceptions.html-B17YLhPn.js" as="script"><link rel="prefetch" href="/assets/17-TBSgame.html-BAOQeVP2.js" as="script"><link rel="prefetch" href="/assets/18-deepseek-api.html-B_y88CtF.js" as="script"><link rel="prefetch" href="/assets/19-local-LLM.html-CBVDuwL9.js" as="script"><link rel="prefetch" href="/assets/20-anaconda-install.html-5k_SLrsx.js" as="script"><link rel="prefetch" href="/assets/21-python-install.html-Lqpxs2Np.js" as="script"><link rel="prefetch" href="/assets/22-files-opt.html-n8F-2lM9.js" as="script"><link rel="prefetch" href="/assets/Markdown-formula.html-d-PTS7WT.js" as="script"><link rel="prefetch" href="/assets/Static-website-building.html-CUwjv_KO.js" as="script"><link rel="prefetch" href="/assets/article-typora.html--48uHgsV.js" as="script"><link rel="prefetch" href="/assets/01-LOVEintheTIMEofCHOLERA.html-BsAGOeyY.js" as="script"><link rel="prefetch" href="/assets/02-Tuesdays-with-Morrie.html-I7Xow00L.js" as="script"><link rel="prefetch" href="/assets/01-EEG-based-detection-of-the-locus-of-auditory-attention-with-convolutional-neural-networks.html-pfWDbFUI.js" as="script"><link rel="prefetch" href="/assets/01-human-DK10000.html-9CYYbhK6.js" as="script"><link rel="prefetch" href="/assets/404.html-ysWIeglq.js" as="script"><link rel="prefetch" href="/assets/index.html-y3v3ezWi.js" as="script"><link rel="prefetch" href="/assets/index.html-CJuNbEl3.js" as="script"><link rel="prefetch" href="/assets/index.html-BWvrnwKL.js" as="script"><link rel="prefetch" href="/assets/index.html-DCBQy6Wb.js" as="script"><link rel="prefetch" href="/assets/index.html-UdFShDu8.js" as="script"><link rel="prefetch" href="/assets/index.html-CTS1sNaE.js" as="script"><link rel="prefetch" href="/assets/index.html-Bf2_8F3l.js" as="script"><link rel="prefetch" href="/assets/index.html-BjYskzst.js" as="script"><link rel="prefetch" href="/assets/index.html--63n1D5P.js" as="script"><link rel="prefetch" href="/assets/index.html-Dw0IRd_6.js" as="script"><link rel="prefetch" href="/assets/index.html-D_J6aJW1.js" as="script"><link rel="prefetch" href="/assets/index.html-CWnTERAp.js" as="script"><link rel="prefetch" href="/assets/index.html-CXVRoqJZ.js" as="script"><link rel="prefetch" href="/assets/index.html-D18c_yBC.js" as="script"><link rel="prefetch" href="/assets/index.html-QkW8Ebja.js" as="script"><link rel="prefetch" href="/assets/index.html-BfTZCT6P.js" as="script"><link rel="prefetch" href="/assets/index.html-D0fjXtiy.js" as="script"><link rel="prefetch" href="/assets/index.html-BN5_lK0w.js" as="script"><link rel="prefetch" href="/assets/index.html-a7Qn-lMV.js" as="script"><link rel="prefetch" href="/assets/index.html-BVliGXbC.js" as="script"><link rel="prefetch" href="/assets/index.html-B6Envuug.js" as="script"><link rel="prefetch" href="/assets/index.html-Cf0Hv3av.js" as="script"><link rel="prefetch" href="/assets/index.html-C96sfKU6.js" as="script"><link rel="prefetch" href="/assets/index.html-CuiH3XCV.js" as="script"><link rel="prefetch" href="/assets/mermaid.esm.min-CreCbFg5.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-CKV1Bsxh.js" as="script"><link rel="prefetch" href="/assets/waline-meta-l0sNRNKZ.js" as="script"><link rel="prefetch" href="/assets/component-aHr90Tsv.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><a class="route-link vp-brand" href="/" aria-label="带我回家"><img class="vp-nav-logo" src="/阿尔法 logo.jpg" alt><!----><span class="vp-site-name hide-in-pad">Pythia’s Root</span></a><!--]--></div><div class="vp-navbar-center"><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/" aria-label="Pythia’s Root"><!--[--><i class="vp-icon iconfont icon-house" sizing="height"></i><!--]-->Pythia’s Root<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="编程"><!--[--><i class="vp-icon iconfont icon-biancheng-01" sizing="height"></i>编程<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/programming/static-website-blog/" aria-label="Static website building-blog"><!--[--><i class="vp-icon iconfont icon-boke" sizing="both"></i><!--]-->Static website building-blog<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/programming/python/" aria-label="Python"><!--[--><i class="vp-icon iconfont icon-python" sizing="both"></i><!--]-->Python<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/programming/ThinkDSP/" aria-label="ThinkDSP"><!--[--><i class="vp-icon iconfont icon-python" sizing="both"></i><!--]-->ThinkDSP<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/programming/math-for-ai/" aria-label="Math for AI"><!--[--><i class="vp-icon iconfont icon-python" sizing="both"></i><!--]-->Math for AI<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/#" aria-label="人工耳蜗"><!--[--><i class="vp-icon iconfont icon-rengongerwoshenqing" sizing="height"></i><!--]-->人工耳蜗<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/#" aria-label="语音学"><!--[--><i class="vp-icon iconfont icon-shengboyuyinxiaoxi" sizing="height"></i><!--]-->语音学<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="翻译"><!--[--><i class="vp-icon iconfont icon-fanyi" sizing="height"></i>翻译<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/translation/vocabulary/" aria-label="词汇"><!--[--><i class="vp-icon iconfont icon-cihuiben" sizing="both"></i><!--]-->词汇<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/translation/peki/" aria-label="Peki"><!--[--><i class="vp-icon iconfont icon-fanyi" sizing="both"></i><!--]-->Peki<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/sports/" aria-label="运动"><!--[--><i class="vp-icon iconfont icon-jianshenfang" sizing="height"></i><!--]-->运动<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="阅读"><!--[--><i class="vp-icon iconfont icon-yuedu" sizing="height"></i>阅读<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link route-link-active auto-link" href="/reading/literature/" aria-label="文献"><!--[--><i class="vp-icon iconfont icon-yuedu" sizing="both"></i><!--]-->文献<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/reading/books/" aria-label="书籍"><!--[--><i class="vp-icon iconfont icon-yuedu" sizing="both"></i><!--]-->书籍<!----></a></li></ul></button></div></div></nav><!--]--></div><div class="vp-navbar-end"><!--[--><!----><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/AmaraMeng/AmaraMeng.github.io" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><form class="search-box" role="search"><input type="search" placeholder="搜索" autocomplete="off" spellcheck="false" value><!----></form><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/" aria-label="Pythia’s Root"><!--[--><i class="vp-icon iconfont icon-house" sizing="both"></i><!--]-->Pythia’s Root<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Programming</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">Reading</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Books</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">Literature</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/reading/literature/01-EEG-based-detection-of-the-locus-of-auditory-attention-with-convolutional-neural-networks.html" aria-label="01. 基于EEG的卷积神经网络听觉注意力定位检测"><!--[--><i class="vp-icon iconfont icon-boke" sizing="both"></i><!--]-->01. 基于EEG的卷积神经网络听觉注意力定位检测<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/reading/literature/02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.html" aria-label="02. 听觉注意解码准确性对助听器降噪系统的影响"><!--[--><i class="vp-icon iconfont icon-boke" sizing="both"></i><!--]-->02. 听觉注意解码准确性对助听器降噪系统的影响<!----></a></li></ul></section></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Sports</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Translation</span><span class="vp-arrow end"></span></button><!----></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/intro.html" aria-label="介绍页"><!--[--><i class="vp-icon iconfont icon-circle-info" sizing="both"></i><!--]-->介绍页<!----></a></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><i class="vp-icon iconfont icon-boke" sizing="height"></i>02. 听觉注意解码准确性对助听器降噪系统的影响</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">Ran</span></span><span property="author" content="Ran"></span></span><span class="page-original-info">原创</span><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">2025/11/27</span><meta property="datePublished" content="2025-11-27T01:44:44.000Z"></span><span class="page-pageview-info" aria-label="访问量🔢" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon eye-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="eye icon" name="eye"><path d="M992 512.096c0-5.76-.992-10.592-1.28-11.136-.192-2.88-1.152-8.064-2.08-10.816-.256-.672-.544-1.376-.832-2.08-.48-1.568-1.024-3.104-1.6-4.32C897.664 290.112 707.104 160 512 160c-195.072 0-385.632 130.016-473.76 322.592-1.056 2.112-1.792 4.096-2.272 5.856a55.512 55.512 0 00-.64 1.6c-1.76 5.088-1.792 8.64-1.632 7.744-.832 3.744-1.568 11.168-1.568 11.168-.224 2.272-.224 4.032.032 6.304 0 0 .736 6.464 1.088 7.808.128 1.824.576 4.512 1.12 6.976h-.032c.448 2.08 1.12 4.096 1.984 6.08.48 1.536.992 2.976 1.472 4.032C126.432 733.856 316.992 864 512 864c195.136 0 385.696-130.048 473.216-321.696 1.376-2.496 2.24-4.832 2.848-6.912.256-.608.48-1.184.672-1.728 1.536-4.48 1.856-8.32 1.728-8.32l-.032.032c.608-3.104 1.568-7.744 1.568-13.28zM512 672c-88.224 0-160-71.776-160-160s71.776-160 160-160 160 71.776 160 160-71.776 160-160 160z"></path></svg><span id="ArtalkPV" class="vp-pageview waline-pageview-count" data-path="/reading/literature/02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.html" data-page-key="/reading/literature/02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.html">...</span></span><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 29 分钟</span><meta property="timeRequired" content="PT29M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item color2 clickable" role="navigation">reading</span><span class="page-category-item color8 clickable" role="navigation">literature</span><!--]--><meta property="articleSection" content="reading,literature"></span><!----></div><hr></div><!----><div class="" vp-content><!----><div id="markdown-content"><p><strong>Impact of auditory attention decoding accuracy on noise reduction systems for hearing aids (2026)</strong></p><figure><img src="/assets/image-20251127015134844-Cbd0BLmf.png" alt="题目及作者" tabindex="0" loading="lazy"><figcaption>题目及作者</figcaption></figure><h2 id="摘要" tabindex="-1"><a class="header-anchor" href="#摘要"><span>摘要</span></a></h2><p>Hearing aid users often struggle to focus on a specific target speaker in multi-talker environments. Auditory attention decoding (AAD) algorithms, which extract attentional cues from electroencephalogram (EEG) signals, offer a potential solution. This study evaluates <strong>how AAD accuracy and decision window length affect the performance of a multichannel Wiener filter noise reduction system in a speaker and story-independent scenario</strong>. Simulations in two-speaker anechoic conditions show that, for decision windows of 1 s or less, AAD accuracies approximately above 81 % are required to meet minimum conversational speech quality (PESQ = 2.0), while accuracies approximately above 64 % suffice for intelligibility (STOI = 0.62). These results define quantitative performance targets for integrating AAD-based noise reduction into hearing aids and highlight the trade-off between decision latency, decoding accuracy, and perceptual benefit under idealized beamforming/VAD and anechoic conditions with high-density EEG.</p><p>助听器使用者在多说话者环境中常常难以专注于特定的目标说话者。听觉注意解码（AAD）算法可以从脑电图（EEG）信号中提取注意线索，提供一个潜在的解决方案。本研究评估了<strong>AAD准确率和决策窗口长度如何影响多通道维纳滤波噪声抑制系统在说话者和故事独立场景中的性能</strong>。双说话者无回声条件下的仿真表明，对于1秒或更短的决策窗口，AAD准确率需要大约超过81%才能达到最低的会话语音质量（PESQ = 2.0），而大约超过64%的准确率就足以满足可懂度要求（STOI = 0.62）。这些结果为将基于AAD的噪声抑制集成到助听器中设定了量化的性能目标，并突出了在理想的波束形成/VAD和无回声条件下、高密度EEG环境中决策延迟、解码准确率与感知收益之间的权衡。</p><h2 id="_1-introduction" tabindex="-1"><a class="header-anchor" href="#_1-introduction"><span>1. Introduction</span></a></h2><h3 id="_1-1-研究背景" tabindex="-1"><a class="header-anchor" href="#_1-1-研究背景"><span>1.1 研究背景</span></a></h3><ol><li><p><strong>问题背景：</strong></p><p>听力损失用户在多说话人（“鸡尾酒会”）环境中难以聚焦于目标说话人，现有助听器在此方面存在不足。</p></li><li><p><strong>现有解决方案与局限：</strong></p><p><strong>传统方法</strong>：依赖音量、视线方向等启发式规则，在目标源不具备这些特征时效果不佳。</p><p><strong>新兴技术</strong>：基于脑电图（EEG）的<strong>听觉注意力解码（AAD）</strong> 技术，可直接从大脑信号中解码用户注意力。</p><ul><li><p><strong>两大技术路径</strong>：</p><ul><li><p><strong>神经引导的语音提取</strong>：使用EEG信号直接引导深度学习模型从混合语音中提取目标语音。但存在模型复杂、泛化能力差（如依赖特定说话人）等问题，不适用于现实助听器。</p></li><li><p><strong>分离后分类</strong>：先分离各说话人信号（提供多个备选），再用AAD选择目标。这种方法<strong>更易于在助听器上实现</strong>，是本文采用的技术路径。</p><blockquote><h3 id="为何-更易于在助听器上实现" tabindex="-1"><a class="header-anchor" href="#为何-更易于在助听器上实现"><span><strong>为何“更易于在助听器上实现”？</strong></span></a></h3><p>与第一种“端到端”方法相比，这种模块化设计有两大优势：</p><ol><li><strong>计算负载分离与降低</strong>： <ul><li><strong>语音分离模块</strong>和<strong>EEG解码模块</strong>可以独立优化。语音分离可以使用经典的、计算效率高的信号处理算法（如MWF）。</li><li>EEG解码虽然仍需神经网络，但它的任务被简化为一个相对简单的<strong>分类问题</strong>（左/右），而不是复杂的语音波形重构问题。这大大降低了模型的复杂度和计算需求。</li></ul></li><li><strong>系统更鲁棒、更易调试</strong>： <ul><li>每个模块的功能明确，可以单独测试和评估。如果效果不好，可以定位问题是出在“分离不准”还是“选择不对”。</li><li>更容易集成现有的、成熟的助听器技术（如波束成形器）。</li></ul></li></ol></blockquote></li></ul></li></ul></li><li><p><strong>核心矛盾</strong>：AAD的<strong>准确率</strong>与<strong>决策窗口长度（延迟）</strong> 之间存在权衡。短窗口（低延迟）是实用性的关键，但会导致准确率下降。先前研究使用了<strong>长达30秒的决策窗口</strong>，这在现实中<strong>完全不实用</strong>。</p></li><li><p><strong>前人研究局限：</strong></p><ul><li><code>[12-14]</code>：<strong>MWF + AAD</strong>（与本文系统架构几乎一致）。</li><li><code>[15]</code>：<strong>双耳波束成形 + 认知驱动</strong>（核心思想一致，技术实现不同）。</li><li><code>[16]</code>：<strong>AAD与自适应波束成形的联合模型</strong>（更先进的集成思路）。</li></ul><p><strong>这表明：</strong> 将神经科学与音频处理结合以增强目标语音的<strong>核心思想并非本文首创</strong>。</p><p>这些研究证明了“神经导向”在<strong>技术原理上可行</strong>，但它们为了达到足够高的解码精度（比如90%以上），普遍依赖于<strong>长达30秒的决策窗口</strong>。</p></li><li><p><strong>参考的核心文献局限</strong></p><p><strong>贡献</strong>：它提出了一种直接用EEG对听觉注意方位（左/右）进行分类的CNN方法，并且<strong>关键地</strong>，它在<strong>约1秒的决策窗口</strong>下，达到了与以往长窗口研究相似的准确率。</p><p><strong>局限：</strong></p><ul><li>只评估了AAD本身的分类性能，<strong>未集成到噪声抑制系统中</strong>评估最终语音效果。</li><li>依赖需要先验知识的<strong>伪迹去除算法</strong> （实用中无法预先知道并标记EEG中的伪迹，如眨眼、肌肉活动）。</li><li>存在<strong>数据泄露</strong>问题（未严格说话人独立），导致性能评估虚高。</li></ul></li><li><p><strong>其他局限：</strong></p><p>大多数研究只报告AAD分类准确率，但助听器的适用性最终取决于<strong>语音可懂度与质量</strong>。</p></li></ol><h3 id="_1-2-本文贡献" tabindex="-1"><a class="header-anchor" href="#_1-2-本文贡献"><span>1.2 本文贡献</span></a></h3><p><strong>🎯 研究目标</strong></p><ol><li><strong>量化影响</strong>：研究 <strong>AAD算法的分类准确率</strong> 和 <strong>决策窗口长度</strong> 这两个关键参数，如何影响噪声抑制系统的最终性能。</li><li><strong>确定最低要求</strong>：找到为了达到<strong>足够的语音可懂度（intelligibility）和质量（quality）</strong>，所需要的<strong>AAD准确率和决策窗口长度的最低门槛</strong>。</li><li><strong>提供设计起点</strong>：为未来神经导向助听器的工程设计提供<strong>量化的性能基准和起始点</strong>，而不仅仅是理论概念。</li></ol><hr><p><strong>贡献一：系统集成与在严格场景下的评估</strong></p><p><strong>做了什么</strong>：将基于多通道维纳滤波器的噪声抑制系统与基于EEG的注意力检测算法相<strong>结合</strong>，并在一个<strong>说话者和故事都独立</strong>的场景下进行评估。</p><ul><li><strong>“结合”</strong> 验证了完整系统链路的可行性。</li><li><strong>“独立”</strong> 意味着模型在训练时<strong>从未见过</strong>测试时所用的说话人和故事内容。这保证了评估结果的<strong>严谨性和泛化能力</strong>，证明了系统能应对真实世界中未知的说话人和对话，而不是在“作弊”。</li></ul><hr><p><strong>贡献二：AAD模型的个性化改进</strong></p><p><strong>做了什么</strong>：改进了文献<code>[17]</code>中的CNN模型，提出了<strong>三级个性化微调策略</strong>，探索了利用助听器验配过程中收集的用户特定EEG数据来提升性能。</p><ul><li>证明了<strong>少量用户数据</strong>（在标准验配过程中可获取）能<strong>显著提升</strong>AAD性能。</li><li>为未来产品提供了一个极具操作性的性能提升路径：<strong>“预训练通用模型 + 验配时快速微调”</strong>。</li></ul><hr><p><strong>贡献三：基于客观感知指标的系统性能分析</strong></p><p><strong>做了什么</strong>：使用<strong>PESQ</strong>和<strong>STOI</strong>这两个客观指标来分析系统输出。</p><ul><li>这代表了评估范式的转变。不再只看中间的“算法准确率”，而是关注最终的“<strong>用户体验</strong>”。</li><li><strong>PESQ</strong>评价语音听起来是否舒适、自然（<strong>质量</strong>）。</li><li><strong>STOI</strong>评价语音是否能被听懂（<strong>可懂度</strong>）。这两个才是助听器成功的终极标准。</li></ul><hr><p><strong>贡献四：建立定量的性能基准</strong></p><p><strong>做了什么</strong>：首次定量地建立了AAD准确率、决策窗口与可接受语音质量/可懂度之间的对应关系，明确了最低性能要求。</p><ul><li>这是全文的<strong>最高价值总结</strong>。它将前三点贡献的发现，凝结成可供工程界直接使用的“设计规格书”。</li><li>例如，它给出了明确答案：<em>“如果想让助听器在1秒内反应，并且语音质量达标，那么你的AAD算法准确率必须达到81%以上。”</em></li><li>这为整个领域设定了清晰、量化的研发目标，让后续研究不再是盲目追求“更高的准确率”，而是有针对性地攻关“在指定延迟下达到所需准确率”。</li></ul><h2 id="_2-acoustic-scenario-description" tabindex="-1"><a class="header-anchor" href="#_2-acoustic-scenario-description"><span>2. Acoustic scenario description</span></a></h2><h3 id="_2-1-物理场景设定" tabindex="-1"><a class="header-anchor" href="#_2-1-物理场景设定"><span>2.1 物理场景设定</span></a></h3><p>这一部分描述了一个<strong>理想化的双说话人混响场景</strong>：</p><ul><li><strong>设备配置（假设）</strong>： <ul><li>助听器佩戴在<strong>左耳</strong>。</li><li>左耳助听器上有 <strong><code>M/2</code> 个麦克风</strong>，呈线性阵列排列。</li><li>右耳有一个耳模，上面也有 <strong><code>M/2</code> 个麦克风</strong>。</li><li>左右耳的麦克风信号通过<strong>无线传输</strong>同步，共同构成一个完整的 <strong><code>M</code> 麦克风阵列系统</strong>。</li></ul></li><li><strong>麦克风捕捉到的声源与噪声</strong>： <ul><li>有 <strong><code>N</code> 个不同的说话人</strong>。</li><li>存在<strong>环境噪声</strong>，包括： <ul><li><strong>环境扩散声场</strong>（如房间混响、空调声）。</li><li><strong>电路噪声</strong>。</li></ul></li></ul></li><li><strong>关键假设（详情见2.2）：</strong><ul><li>语音源和噪声是<strong>遍历的</strong>，即语音源和噪声<strong>完全均匀混合</strong>，而且短时内是<strong>平稳的</strong>，其统计特性可以在短时窗口内估计。</li><li>语音与噪声之间是<strong>不相关的</strong>。</li></ul></li></ul><p><strong>目的</strong>：这个设定模拟了未来<strong>双耳协同</strong>的助听器，能利用头部两侧的麦克风获取空间信息，这是实现波束成形和声源定位的基础。</p><h3 id="_2-2-核心数学假设-公式推导的前提" tabindex="-1"><a class="header-anchor" href="#_2-2-核心数学假设-公式推导的前提"><span>2.2 核心数学假设（公式推导的前提）</span></a></h3><p>为了能用数学工具处理这个复杂场景，论文引入了三个关键假设，这是整个理论模型的基石：</p><ul><li><p><strong>假设一：线性混合</strong></p><blockquote><p>“The M microphones capture a <strong>linear mixture</strong> of speech signals...”</p></blockquote><ul><li><p><strong>含义</strong>：每个麦克风接收到的信号，是各个声源信号经过其传播路径（可能衰减、延迟）后，<strong>简单相加</strong>的结果。忽略回声、非线性失真等复杂效应。</p></li><li><p><strong>为什么重要</strong>：只有线性混合，才能用公式 $$y = \sum_{i=1}^N a_i s_i + n $$ 来表示，这是后续所有矩阵运算和滤波器设计（如MWF）的<strong>根本前提</strong>。</p><blockquote><p><strong>公式详解：</strong></p><p><strong>步骤1：单个麦克风收到什么？</strong><br> 对于第 <code>m</code> 个麦克风，在时频点 <code>(λ, k)</code> 上：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>y</mi><mi>m</mi></msub><mo>=</mo><msub><mi>x</mi><msub><mi>m</mi><mn>1</mn></msub></msub><mo>+</mo><msub><mi>x</mi><msub><mi>m</mi><mn>2</mn></msub></msub><mo>+</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo>+</mo><msub><mi>x</mi><msub><mi>m</mi><mi>N</mi></msub></msub><mo>+</mo><msub><mi>n</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">y_m=x_{m_1}+x_{m_2}+...+x_{m_N}+n_m </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8334em;vertical-align:-0.2501em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8334em;vertical-align:-0.2501em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord">...</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8336em;vertical-align:-0.2503em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3567em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1433em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2503em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p><ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">y_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>：麦克风 <code>m</code> 最终录到的<strong>总信号</strong>。</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><msub><mi>m</mi><mi>i</mi></msub></msub></mrow><annotation encoding="application/x-tex">x_{m_i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6807em;vertical-align:-0.2501em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span></span></span></span>：第 <code>i</code> 个说话人的声音传到麦克风 <code>m</code> 这里的部分。</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">n_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>：环境噪声和电路噪声在麦克风 <code>m</code> 处的部分。</li></ul><p><strong>步骤2：每个说话人的声音怎么来的？</strong></p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>x</mi><msub><mi>m</mi><mi>i</mi></msub></msub><mo>=</mo><msub><mi>a</mi><msub><mi>m</mi><mi>i</mi></msub></msub><mo>∗</mo><msub><mi>s</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_{m_i}=a_{m_i}∗s_i </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6807em;vertical-align:-0.2501em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7154em;vertical-align:-0.2501em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p><ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">s_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>：第 <code>i</code> 个说话人发出的<strong>原始、纯净的语音信号</strong>（声源处）。</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><msub><mi>m</mi><mi>i</mi></msub></msub></mrow><annotation encoding="application/x-tex">a_{m_i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6807em;vertical-align:-0.2501em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span></span></span></span>：<strong>声学传递函数</strong>。它描述了声音从第 <code>i</code> 个说话人的嘴巴，传播到第 <code>m</code> 个麦克风的<strong>整个过程</strong>所发生的变化。</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><msub><mi>m</mi><mi>i</mi></msub></msub></mrow><annotation encoding="application/x-tex">x_{m_i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6807em;vertical-align:-0.2501em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span></span></span></span>：最终抵达麦克风 <code>m</code> 的第 <code>i</code> 个说话人的声音。</li></ul><p><strong>步骤3：合并成向量形式</strong><br> 把所有 <code>M</code> 个麦克风的信号堆叠成向量，得到更简洁的表达：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mover accent="true"><mi>y</mi><mo>⃗</mo></mover><mo>=</mo><mover accent="true"><msub><mi>a</mi><mn>1</mn></msub><mo>⃗</mo></mover><msub><mi>s</mi><mn>1</mn></msub><mo>+</mo><mover accent="true"><msub><mi>a</mi><mn>2</mn></msub><mo>⃗</mo></mover><msub><mi>s</mi><mn>2</mn></msub><mo>+</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo>+</mo><mover accent="true"><msub><mi>a</mi><mi>N</mi></msub><mo>⃗</mo></mover><msub><mi>s</mi><mi>N</mi></msub><mo>+</mo><mover accent="true"><mi>n</mi><mo>⃗</mo></mover></mrow><annotation encoding="application/x-tex">\vec{y}=\vec{a_1}s_1+\vec{a_2}s_2+...+\vec{a_N}s_N+\vec{n} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9084em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1799em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em;" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.864em;vertical-align:-0.15em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2355em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em;" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.864em;vertical-align:-0.15em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2355em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em;" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord">...</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.864em;vertical-align:-0.15em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2355em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em;" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.714em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">n</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2355em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em;" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path></svg></span></span></span></span></span></span></span></span></span></span></span></p></blockquote></li></ul></li><li><p><strong>假设二：短时遍历性</strong></p><blockquote><p>“It is assumed that both source activity and noise statistics are <strong>ergodic and estimable over short-term windows</strong>.”</p></blockquote><ul><li><strong>含义</strong>：语音和噪声的统计特性（如均值、方差、相关性）在短时间内（例如20-40毫秒的帧内）是<strong>平稳且可估计的</strong>。虽然语音整体变化剧烈，但在极短的片段内，其特性相对稳定。</li><li><strong>为什么重要</strong>：这是所有<strong>短时傅里叶变换</strong>和<strong>在线估计算法</strong>的灵魂。它允许我们将非平稳的信号切成小段，在每一段内用统计方法处理，并相信这些估计是有效的。</li></ul></li><li><p><strong>假设三：信号不相关</strong></p><blockquote><p>“Furthermore, the speech sources and noise are assumed to be <strong>uncorrelated</strong>.”</p></blockquote><ul><li><strong>含义</strong>：任意两个不同的声源（例如目标说话人和干扰说话人）之间，以及任何声源与背景噪声之间，它们的信号是<strong>统计上不相关</strong>的。一个信号的变化无法用来预测另一个信号的变化。</li><li><strong>为什么重要</strong>：这是<strong>多通道维纳滤波器能够奏效的最关键假设</strong>。MWF的核心思想是利用信号与噪声在空间特性上的差异来分离它们。如果目标语音和干扰语音高度相关（比如是同一个人说的不同句子），MWF将极难分离它们。这个假设在现实中很难完全满足，但它是理论推导和获得清晰解的<strong>必要条件</strong>。</li></ul></li></ul><h3 id="_2-2-公式解读" tabindex="-1"><a class="header-anchor" href="#_2-2-公式解读"><span>2.2 公式解读</span></a></h3><figure><img src="/assets/image-20251127032915033-BjT4wfN0.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><strong>1. 声源与角色定义</strong></p><ul><li><strong><code>s₁(t)</code></strong>：<strong>目标语音信号</strong><ul><li>这是听者<strong>主动注意并想听清</strong>的说话人。</li><li>在本文的后续心理声学实验中，听者被要求始终跟随 <code>s₁(t)</code> 的内容。</li></ul></li><li><strong><code>s₂(t)</code></strong>：<strong>干扰语音信号</strong><ul><li>这是听者<strong>需要忽略</strong>的说话人。</li><li>在系统中，<code>s₂(t)</code> 被视为需要被抑制的“噪声”之一。</li></ul></li></ul><p><strong>重要性</strong>：这明确了系统任务的二元性——不是抑制一般的环境噪音，而是要在<strong>两个非常相似的人类语音</strong>中做出选择并抑制其中一个。这是“鸡尾酒会问题”的核心挑战。</p><hr><p><strong>2. 空间位置设定</strong></p><ul><li><strong>方位角</strong>：两个声源分别位于听者左右两侧的 <strong>±90°</strong> 方位。 <ul><li>例如，<code>s₁(t)</code> 在 <strong>+90°</strong>（听者左侧），<code>s₂(t)</code> 在 <strong>-90°</strong>（听者右侧）。</li></ul></li><li><strong>为何选择 ±90°？</strong><ol><li><strong>最大化空间分离</strong>：这是双耳听觉中<strong>空间线索最显著</strong>的位置。左右耳的时间差和强度差最大，最有利于基于空间位置的分离算法（如波束成形）。</li><li><strong>简化问题</strong>：将声源置于极端两侧，避免了正前方或后方带来的空间模糊性，使研究可以专注于评估AAD和噪声抑制本身的性能，而不受声源定位模糊的干扰。</li><li><strong>符合典型场景</strong>：模拟了常见的对话场景，例如在餐桌两旁与人交谈。</li></ol></li></ul><hr><p><strong>公式 (1): 单个麦克风接收到的信号</strong></p><figure><img src="/assets/image-20251127030012189-BMSZ4FVp.png" alt="公式1" tabindex="0" loading="lazy"><figcaption>公式1</figcaption></figure><ul><li><strong><code>yₘ(λ, k)</code></strong>：在第 <code>m</code> 个麦克风的 <strong>时频点 <code>(λ, k)</code></strong> 上接收到的总信号。（<code>λ</code> 是时间帧索引，<code>k</code> 是频率点索引）</li><li><strong><code>Σ xₘᵢ(λ, k)</code></strong>：所有 <code>N</code> 个说话人的语音信号在第 <code>m</code> 个麦克风处叠加的结果。</li><li><strong><code>nₘ(λ, k)</code></strong>：在第 <code>m</code> 个麦克风处收到的环境噪声和电路噪声。</li></ul><blockquote><p><strong>通俗理解</strong>：这个公式就是说，<strong>每个麦克风听到的声音 = 所有说话人声音的混合 + 背景噪音</strong>。对应线性混合假设。</p></blockquote><p><strong>公式 (2): 语音信号的建模</strong></p><p>公式(2) 是公式(1) 的一部分</p><figure><img src="data:image/png;base64,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" alt="公式2" tabindex="0" loading="lazy"><figcaption>公式2</figcaption></figure><ul><li><strong><code>sᵢ(λ, k)</code></strong>：第 <code>i</code> 个说话人发出的<strong>纯净语音信号</strong>。</li><li><strong><code>aₘᵢ(λ, k)</code></strong>：<strong>声学传递函数</strong>，它模拟了第 <code>i</code> 个声源发出的声音传播到第 <code>m</code> 个麦克风这个过程所发生的变化（如衰减、延迟）。</li><li><strong><code>xₘᵢ(λ, k)</code></strong>：最终，第 <code>i</code> 个说话人的声音被第 <code>m</code> 个麦克风捕捉到的版本。</li></ul><blockquote><p><strong>通俗理解</strong>：一个说话人的声音从嘴里发出，经过空气传播，再到被麦克风录下，这个过程会发生改变。<code>aₘᵢ</code> 就是描述这个“改变”的函数。所以，<strong>麦克风收到的某个说话人的声音 = 他发出的原始声音 × 传播路径的影响</strong>。</p></blockquote><p><strong>公式 (3): 所有麦克风信号的向量表示</strong></p><figure><img src="/assets/image-20251127031337699-Xn4fBnWA.png" alt="公式3" tabindex="0" loading="lazy"><figcaption>公式3</figcaption></figure><p>这只是把公式(1)和(2)结合起来，并用<strong>向量形式</strong>表示所有 <code>M</code> 个麦克风的信息，这样更简洁，也便于后续的矩阵运算。</p><ul><li><strong><code>y(λ, k)</code></strong>：一个向量，包含了所有 <code>M</code> 个麦克风在时频点 <code>(λ, k)</code> 上接收到的信号 <code>[y₁, y₂, ..., y_M]ᵀ</code>。</li><li><strong><code>aᵢ(λ, k)</code></strong>：一个向量，包含了第 <code>i</code> 个说话人到所有 <code>M</code> 个麦克风的声学传递函数 <code>[a₁ᵢ, a₂ᵢ, ..., a_Mᵢ]ᵀ</code>。它定义了该说话人的<strong>空间位置信息</strong>。</li><li><strong><code>n(λ, k)</code></strong>：一个向量，包含了所有 <code>M</code> 个麦克风处的噪声 <code>[n₁, n₂, ..., n_M]ᵀ</code>。</li></ul><p><strong>公式 (4) &amp; (5): 定义“期望信号”与“噪声+干扰”</strong></p><p>这里对总信号 <code>y(λ, k)</code> 进行拆分，将其明确分为“我们想要的”和“我们不想要的”两部分。</p><ul><li><p><strong>期望信号向量 <code>x(λ, k)</code></strong>：</p><figure><img src="/assets/image-20251127031911653-BXg24iV9.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>假设第一个说话人 <code>s₁</code> 是听者关注的目标。那么，所有麦克风收到的、来自 <code>s₁</code> 的信号就是期望信号。</p></li><li><p><strong>干扰噪声向量 <code>r(λ, k)</code></strong>：</p><figure><img src="/assets/image-20251127031932922-kQwOcsF0.png" alt="公式4" tabindex="0" loading="lazy"><figcaption>公式4</figcaption></figure><p>这个向量包含了<strong>所有干扰说话人（<code>i=2</code> 到 <code>N</code>）的声音</strong>加上<strong>环境噪声</strong>。在本文的双说话人场景中，<code>i=2</code> 就是那个干扰说话人。</p></li><li><p><strong>总信号的最终简化形式</strong>：</p><figure><img src="/assets/image-20251127031954973-C7DMl3-D.png" alt="公式5" tabindex="0" loading="lazy"><figcaption>公式5</figcaption></figure><p>这个公式至关重要，它将复杂的声学场景<strong>简化为一个清晰的加法模型</strong>：<strong>总信号 = 期望信号 + (干扰 + 噪声)</strong>。</p></li></ul><p><strong>公式(6)</strong></p><figure><img src="data:image/png;base64,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" alt="公式6" tabindex="0" loading="lazy"><figcaption>公式6</figcaption></figure><p>这个公式的意思是：<strong>系统对目标语音的最终估计值 <code>x̂</code>，等于将所有麦克风的混合信号 <code>y</code>，通过一个精心设计的多通道滤波器 <code>w</code> 进行加权组合后得到的结果。</strong></p><ul><li><strong><code>x̂(λ, k)</code></strong>: 这是在时频点 <code>(λ, k)</code> 上，对<strong>参考麦克风</strong>处<strong>目标语音</strong> <code>x₁(λ, k)</code> 的<strong>估计值</strong>。也就是我们最终想得到的、增强后的信号。它的质量（PESQ/STOI）是本文评判系统成败的唯一标准。</li><li><strong><code>y(λ, k)</code></strong>: 这是我们熟悉的公式(3)中定义的向量，包含了所有 <code>M</code> 个麦克风在此时频点上接收到的信号 <code>[y₁, y₂, ..., y_M]ᵀ</code>。它是算法的<strong>输入</strong>。</li><li><strong><code>w(λ, k)</code></strong>: 这是<strong>多通道维纳滤波器</strong>在时频点 <code>(λ, k)</code> 上的<strong>复值权重向量</strong> <code>[w₁, w₂, ..., w_M]ᵀ</code>。这个权重向量是算法的核心，它包含了如何整合所有麦克风信息以突出目标、抑制噪声和干扰的“知识”。</li><li><strong><code>(·)^H</code></strong>: 表示<strong>埃尔米特转置</strong>（即共轭转置）。因为我们在处理复值的频域信号，所以需要共轭转置。</li></ul><p>💡 直观理解：</p><p>您可以把这个公式想象成一个<strong>智能的、随时空变化的“音量调节旋钮”组合</strong>：</p><ul><li><strong>目标</strong>：从一堆混乱的麦克风信号 <code>y</code> 中，提取出目标说话人在参考麦克风处的干净声音 <code>x̂</code>。</li><li><strong>方法</strong>：滤波器 <code>w</code> 会对每一个麦克风的信号进行一项复杂的操作： <ul><li><strong>调整幅度（缩放）</strong></li><li><strong>调整相位（延迟）</strong></li></ul></li><li><strong>最终效果</strong>：所有经过这样精心调整后的麦克风信号被加在一起。在这个过程中，<strong>目标说话人的声音因为其特定的空间位置（由向量 <code>a₁</code> 定义）而被同相叠加、增强</strong>；而<strong>噪声和干扰说话人的声音则因为来自不同方向而被异相抵消、削弱</strong>。</li></ul><hr><h3 id="_2-3-问题" tabindex="-1"><a class="header-anchor" href="#_2-3-问题"><span>2.3 问题</span></a></h3><h4 id="q1-公式1的时频点-λ-k" tabindex="-1"><a class="header-anchor" href="#q1-公式1的时频点-λ-k"><span>Q1：公式1的时频点 (λ, k)</span></a></h4><p><strong>1. 什么是“时频点” <code>(λ, k)</code>？</strong></p><p>想象一下你在看一部电影的频谱图：</p><ul><li><strong>横轴 <code>λ</code></strong>：代表<strong>时间</strong>。比如 <code>λ=1</code> 代表电影开始的第10毫秒（取决于窗口长度和重叠），<code>λ=2</code> 代表第20毫秒，以此类推。它把连续的时间切成了一帧一帧的短片段。</li><li><strong>纵轴 <code>k</code></strong>：代表<strong>频率</strong>。比如 <code>k=1</code> 代表0-100Hz，<code>k=2</code> 代表100-200Hz，以此类推。它表示在这一帧时间里，声音是由哪些频率成分构成的。</li><li><strong>时频点 <code>(λ, k)</code></strong>：就是这张图上的一个<strong>像素点</strong>。它精确地表示在<strong>某个特定的短暂时间片段（λ）</strong> 内，<strong>某个特定频率段（k）</strong> 上的信号<strong>强度（或能量）</strong>。</li></ul><p><strong>所以，公式 <code>yₘ(λ, k)</code> 读作：在第 <code>m</code> 个麦克风，第 <code>λ</code> 个时间帧，第 <code>k</code> 个频率 bin 上，接收到的总信号强度。</strong></p><p><strong>2. 为什么需要时频点？（核心原因）</strong></p><p><strong>① 利用“稀疏性”假设</strong><br> 如上图所示，这是最根本的原因。在任意一个<strong>非常短的时间窗口</strong>（例如32ms）内，<strong>多个说话人极少会在完全相同的时间、发出完全相同的频率</strong>。这意味着，在大多数时频点 <code>(λ, k)</code> 上，其能量主要只由<strong>一个</strong>占主导地位的声源（目标说话人或干扰者）贡献，其他声源在该点的能量很弱甚至为零。</p><p><strong>② 简化处理，允许线性滤波</strong><br> 在时频域中，卷积混合（在时间域是复杂的）在窄带假设下可以近似为<strong>瞬时混合</strong>。这就使得公式(3)中的混合模型成立，并且可以使用像<strong>多通道维纳滤波器（MWF）</strong> 这样的<strong>线性滤波器</strong> <code>w(λ, k)</code> 来进行处理。在时间域直接进行类似的线性过滤要困难得多。</p><p><strong>③ 契合语音和非平稳信号的特性</strong><br> 语音和噪声都是<strong>非平稳信号</strong>，它们的统计特性随时间变化。在时频域中，我们可以针对<strong>每一帧（λ）</strong> 来估计和更新信号的统计信息（如协方差矩阵 <code>Φ_y(λ,k)</code>），这让算法能够自适应地跟踪声音环境的变化。</p><p><strong>3. 一个生动的比喻</strong></p><p>把整个一段语音信号想象成一幅<strong>完整的油画</strong>，画上是两个人物重叠在一起。</p><ul><li><strong>在时间域分离</strong>：就像让你不借助任何工具，直接把画上的两个人完美地剥离开，这几乎是不可能的。</li><li><strong>在时频域分离</strong>：就像用一个<strong>高倍放大镜</strong>，逐个像素 <code>(λ, k)</code> 地去观察这幅画。你会发现，在大多数像素点上，其实只显示了一个人物的颜色。你只需要在每个像素点上做一个简单的决定：“这个像素点更可能属于人物A还是人物B？”。</li><li><strong>MWF的作用</strong>：就是这个“决策过程”。它根据麦克风阵列收到的信息，在每个时频点上计算一个最优的权重，来提取目标信号并抑制干扰。</li></ul><p><strong>总结：使用“时频点” <code>(λ, k)</code> 是一种“分而治之”的策略。它将一个全局性的、高度复杂的非线性分离问题，分解成了大量局部的、相对简单的线性估计问题，从而使得实时的、高效的噪声抑制和语音增强成为可能。</strong></p><h2 id="_3-aad-based-noise-reduction-system" tabindex="-1"><a class="header-anchor" href="#_3-aad-based-noise-reduction-system"><span>3. AAD-based noise reduction system</span></a></h2><figure><img src="/assets/image-20251127033944881-C19x5Nb5.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>本文提出一种将多通道波束形成（MWF）与基于脑电图（EEG）的算法结合，用于检测听觉注意力位置的降噪系统。</p><p>两个信号分别位于左右两侧，一个为目标信号，一个为干扰信号。</p><h3 id="_3-1-噪声抑制滤波器" tabindex="-1"><a class="header-anchor" href="#_3-1-噪声抑制滤波器"><span>3.1 噪声抑制滤波器</span></a></h3><p>这个模块负责<strong>并行地生成两个备选的“干净”语音流</strong>。</p><ul><li><strong>实现方式</strong>：使用两个独立的<strong>多通道维纳滤波器</strong>。 <ul><li><strong>MWF-L</strong>: 旨在增强来自<strong>左侧</strong>的说话人，并抑制右侧说话人和噪声。</li><li><strong>MWF-R</strong>: 旨在增强来自<strong>右侧</strong>的说话人，并抑制左侧说话人和噪声。</li></ul></li><li><strong>关键点</strong>：在此阶段，系统<strong>并不知道</strong>用户正在关注哪一侧。它只是“尽职”地准备好两个可能的选择，等待最终的指令。这对应于流程图中的模块 <strong>(a)</strong>。</li></ul><p><strong>公式详解：</strong></p><p>我们的目标是估计参考麦克风（<code>m=1</code>）处目标语音信号 <code>x₁(λ,k)</code>。公式(6)给出了线性估计的方法，现在的问题就是：<strong>这个滤波器 <code>w(λ,k)</code> 应该怎么选，才是最好的？</strong></p><p><strong>理论基础：最小均方误差准则</strong></p><p>论文指出，MWF源于一个<strong>最小均方误差（MMSE）</strong> 的线性估计过程。这是一个非常经典和直观的优化准则。</p><p><strong>思想</strong>：寻找一个滤波器 <code>w(λ,k)</code>，使得滤波器输出的估计值 <code>x̂(λ,k)</code> 与<strong>我们想要的真实值</strong> <code>x₁(λ,k)</code> 之间的<strong>均方误差</strong> 最小。</p><p>用数学公式表达这个优化问题，就是<strong>公式(7)</strong>：</p><figure><img src="/assets/image-20251127035121019-KqAbZPil.png" alt="公式7" tabindex="0" loading="lazy"><figcaption>公式7</figcaption></figure><ul><li><strong><code>E[·]</code></strong>: 表示求期望值（或平均值），这里是在计算时间上的平均。</li><li><strong><code>| · |²</code></strong>: 表示取模的平方，用于衡量误差的大小。</li><li><strong><code>x₁ - w^H y</code></strong>: 就是估计误差（真实值 - 估计值）。</li></ul><p><strong>通俗地说</strong>：这个公式命令计算机去找到一组最佳的权重 <code>w</code>，让估计出来的语音 <code>x̂</code> 和真实的干净语音 <code>x₁</code> 之间差距的平均平方值达到最小。</p><p>（其他的交给deepseek简单讲解吧）😭</p><p>好的，我们把 <strong>3.1、3.2 和 3.3</strong> 节放在一起，用一个完整且统一的比喻来讲解，让您彻底理解这三个核心模块是如何协同工作的。</p><p>想象一个 <strong>“智能秘书”</strong> 在嘈杂的会议室里帮你只听清你想听的那个人说话。这个系统的工作方式如下：</p><hr><p>🎯 <strong>3.1 噪声抑制滤波器：两位专业的“速记员”</strong></p><ul><li><p><strong>【他们的职责】</strong><br> 这两位速记员，一位专门负责记录<strong>左边</strong>的发言人（MWF-L），另一位专门负责记录<strong>右边</strong>的发言人（MWF-R）。他们的任务是<strong>实时地、并行地</strong>尽可能清晰地记录下各自负责的目标的讲话，并过滤掉对方的声音和房间里的其他杂音。</p></li><li><p><strong>【他们如何工作】</strong><br> 他们使用的工具是一个复杂的“公式”（<strong>多通道维纳滤波器 MWF</strong>）。这个公式能教他们如何综合所有麦克风的信息，像调整一堆旋钮一样，<strong>放大目标方向的声音，抵消干扰方向的声音</strong>。</p><ul><li><strong>核心公式</strong>：<code>x̂ = w^H * y</code></li><li><strong>通俗解释</strong>：<code>w</code> 是这套“旋钮”的最佳设置方案。它是由 <code>Φ_xx</code>（目标语音的特征）和 <code>Φ_rr</code>（噪声的特征）计算出来的。速记员的工作就是根据这些特征，应用这个最佳方案，产出初步净化的记录稿。</li></ul></li><li><p><strong>【小结】</strong><br> 这两位速记员非常专业，但他们有个<strong>局限</strong>：他们只管记录自己负责的目标，<strong>并不知道你此刻真正想听的是左边这位还是右边这位</strong>。所以他们俩都在不停地工作，产出两份记录稿。</p></li></ul><hr><h3 id="_3-2-🔬-相干矩阵估计器-资深的-人物特征分析师" tabindex="-1"><a class="header-anchor" href="#_3-2-🔬-相干矩阵估计器-资深的-人物特征分析师"><span>3.2 🔬 <strong>相干矩阵估计器：资深的“人物特征分析师”</strong></span></a></h3><ul><li><p><strong>【他的职责】</strong><br> 这位分析师不直接参与记录，他的任务是<strong>为上面的两位速记员提供“人物档案”</strong>。他需要分析出：</p><ol><li><strong>目标人物的声学特征</strong>（<code>Φ_xx</code>）：左边的人声音有什么特点？右边的人声音有什么特点？</li><li><strong>干扰与噪声的特征</strong>（<code>Φ_rr</code>）：房间里的空调声、另一个人的声音，有什么特点？</li></ol></li><li><p><strong>【他如何工作】（三步法）</strong></p><ol><li><strong>定向收音</strong>：他使用两个<strong>定向麦克风</strong>（<strong>固定波束成形器</strong>），一个主要收左边的音，一个主要收右边的音。</li><li><strong>判断状态</strong>：他雇了两个<strong>助理</strong>（<strong>语音活动检测器 VAD</strong>），分别监听这两个定向麦克风。左边的助理会在左边的人说话时举手，右边的同理。</li><li><strong>建立档案</strong>： <ul><li>当<strong>左边助理</strong>举手时，分析师就知道：此刻左边定向麦克风里主要是<strong>目标语音（左边）</strong>，右边定向麦克风里主要是<strong>干扰噪声（右边+环境）</strong>。他立刻用此时的信号更新左边速记员（MWF-L）需要的“人物档案”。</li><li>当<strong>右边助理</strong>举手时，他就为右边速记员（MWF-R）更新档案。</li></ul></li></ol></li><li><p><strong>【小结】</strong><br> 这位分析师通过“定向监听”和“状态判断”，间接地获取了纯净的目标和干扰特征，让两位速记员手中的“旋钮方案”(<code>w</code>)始终保持最佳状态。<strong>本文假设这位分析师和他的助理是“理想的”，永不犯错</strong>，以便集中考察最关键的部分。</p></li></ul><hr><h3 id="_3-3-🧠-听觉注意力解码器-洞察你内心的-决策主管" tabindex="-1"><a class="header-anchor" href="#_3-3-🧠-听觉注意力解码器-洞察你内心的-决策主管"><span>3.3 🧠 <strong>听觉注意力解码器：洞察你内心的“决策主管”</strong></span></a></h3><ul><li><p><strong>【他的职责】</strong><br> 这位主管是最终的<strong>决策者</strong>。他的任务非常简单：<strong>看你一眼，就知道你此刻心里想听左边还是右边的人说话</strong>。然后，他命令系统将对应速记员的记录稿递给你。</p></li><li><p><strong>【他如何工作】</strong></p><ul><li>他通过一个特殊的“读心术头盔”（<strong>EEG设备</strong>）来实时感知你的大脑活动。</li><li>他不是一个冲动的人，他需要<strong>观察你一小段时间</strong>（比如<strong>1秒钟</strong>），收集足够的脑电数据，才会做出一个稳妥的决定（<strong>决策窗口</strong>）。</li><li>他使用一个训练好的“直觉模型”（<strong>CNN神经网络</strong>）来分析这些脑电数据，最终输出指令：<strong>“左”</strong> 或 <strong>“右”</strong>。</li></ul></li><li><p><strong>【核心挑战与权衡】</strong></p><ul><li>如果他观察你的时间太短（<strong>决策窗口短</strong>，如0.5秒），他很容易<strong>判断失误</strong>（准确率低），可能会把错误的记录稿递给你。</li><li>如果他观察你的时间太长（<strong>决策窗口长</strong>，如4秒），他的决策虽然很准，但<strong>反应太慢</strong>（延迟高），等你拿到记录稿时，话题可能已经过去了。</li><li><strong>因此，他的“反应速度”和“判断准确率”之间的权衡，是本文研究的绝对核心。</strong></li></ul></li></ul><hr><h3 id="_3-4-💎-整体协作流程总结" tabindex="-1"><a class="header-anchor" href="#_3-4-💎-整体协作流程总结"><span>3.4 💎 整体协作流程总结</span></a></h3><p>现在，我们把这三个角色串联起来，看看这个“智能秘书系统”是如何工作的：</p><ol><li><p><strong>并行准备</strong>：</p><ul><li><strong>人物特征分析师（3.2）</strong> 不断为<strong>两位速记员（3.1）</strong> 提供最新的“人物档案”。</li><li>两位速记员根据档案，并行地、高质量地记录着各自目标的讲话，产出两份初步净化的记录稿。</li></ul></li><li><p><strong>最终决策</strong>：</p><ul><li><strong>决策主管（3.3）</strong> 通过“读心术”判断出你当前想听谁。</li><li>他发出一个简单的切换指令。</li></ul></li><li><p><strong>交付结果</strong>：</p><ul><li>系统根据指令，选择对应速记员的记录稿，作为最终的语音输出给你听。</li></ul></li></ol><p><strong>总而言之，3.1是干活的，3.2是给干活的人提供技术支持的，3.3是做最终决定的。论文的目的，就是研究这个“做最终决定”的决策主管（3.3），他的反应速度（决策窗口）和业务能力（准确率）要达到什么水平，才能保证你最终听到的东西（语音质量和可懂度）是满意的。</strong></p><h3 id="_3-5-问题" tabindex="-1"><a class="header-anchor" href="#_3-5-问题"><span>3.5 问题</span></a></h3><h4 id="q2-噪声抑制滤波器和相干矩阵估计器的区别" tabindex="-1"><a class="header-anchor" href="#q2-噪声抑制滤波器和相干矩阵估计器的区别"><span>Q2：噪声抑制滤波器和相干矩阵估计器的区别</span></a></h4><p>🎨 核心比喻：<strong>厨师 vs. 食材处理员</strong></p><p>想象一个高级餐厅的厨房，要为客人准备两道主菜（左声道和右声道）。</p><hr><p>👨‍🍳 <strong>3.1 噪声抑制滤波器 - 主厨</strong></p><ul><li><strong>角色</strong>：<strong>两位主厨</strong><ul><li><strong>主厨-左</strong>：专门烹饪左声道这道菜。</li><li><strong>主厨-右</strong>：专门烹饪右声道这道菜。</li></ul></li><li><strong>职责</strong>：<strong>负责“烹饪”出最终端给客人的菜肴</strong>。他们拿到处理好的食材，运用他们高超的厨艺（<strong>MWF算法</strong>），做出一道美味、干净、没有异味的菜。</li><li><strong>工作内容</strong>：他们遵循一个固定的、最优的食谱（<strong>公式 w^opt = Φ_yy⁻¹ Φ_xx q</strong>）。这个食谱告诉他们如何精确地调配各种原料（麦克风信号），才能最好地突出主料（目标语音），掩盖或去除不好的味道（噪声和干扰）。</li><li><strong>关键</strong>：他们是<strong>最终产品的产出者</strong>。系统最终的语音质量（PESQ）和可懂度（STOI）直接由他们的“厨艺”决定。</li></ul><hr><p>🥬 <strong>3.2 相干矩阵估计器 - 食材处理员</strong></p><ul><li><strong>角色</strong>：<strong>一位资深的食材处理员</strong></li><li><strong>职责</strong>：<strong>负责为主厨准备最核心的、处理好的食材</strong>，而不是直接做菜。他的任务是： <ol><li>分辨出什么是“上等主肉”（纯净的 <strong><code>Φ_xx</code></strong> - 目标语音的统计特征）。</li><li>分辨出什么是“需要剔除的筋膜和边角料”（纯净的 <strong><code>Φ_rr</code></strong> - 噪声和干扰的统计特征）。</li></ol></li><li><strong>工作内容</strong>： <ul><li>他使用特殊的工具（<strong>固定波束成形器</strong>）来对混合在一起的原始食材进行<strong>粗分离</strong>。</li><li>他依靠经验（<strong>语音活动检测器 VAD</strong>）来判断什么时候拿到的是纯主肉，什么时候拿到的是纯边角料。</li><li>他将这些分析好的、代表食材特征的“样品”（<code>Φ_xx</code> 和 <code>Φ_rr</code>）交给两位主厨。</li></ul></li><li><strong>关键</strong>：他是<strong>服务和支持者</strong>。他工作的<strong>准确性</strong>直接决定了主厨拿到的食谱（公式里的 <code>Φ_xx</code> 和 <code>Φ_rr</code>）是否靠谱，进而影响菜肴的最终品质。<strong>如果他提供的食材特征有误，主厨厨艺再高也做不出好菜。</strong></li></ul><hr><p>💡 总结与类比</p><table><thead><tr><th style="text-align:left;">特性</th><th style="text-align:left;"><strong>3.1 噪声抑制滤波器 (主厨)</strong></th><th style="text-align:left;"><strong>3.2 相干矩阵估计器 (食材处理员)</strong></th></tr></thead><tbody><tr><td style="text-align:left;"><strong>核心任务</strong></td><td style="text-align:left;"><strong>产出</strong>最终增强后的语音信号。</td><td style="text-align:left;"><strong>估计和提供</strong>计算所需的<strong>统计特征</strong>（协方差矩阵）。</td></tr><tr><td style="text-align:left;"><strong>在公式中的位置</strong></td><td style="text-align:left;">执行公式 <strong><code>x̂ = w^H y</code></strong>，是<strong>最终输出</strong>。</td><td style="text-align:left;">计算公式 <strong><code>w^opt = Φ_yy⁻¹ Φ_xx q</code></strong> 中的 <strong><code>Φ_xx</code> 和 <code>Φ_rr</code></strong>，是<strong>中间输入</strong>。</td></tr><tr><td style="text-align:left;"><strong>依赖关系</strong></td><td style="text-align:left;">依赖于3.2提供的准确统计信息。</td><td style="text-align:left;">依赖于原始的麦克风信号和VAD/波束成形的性能。</td></tr><tr><td style="text-align:left;"><strong>比喻</strong></td><td style="text-align:left;"><strong>烹饪</strong></td><td style="text-align:left;"><strong>准备食材</strong></td></tr></tbody></table><p><strong>所以，它们的根本区别是：</strong></p><ul><li><strong>3.2 是“信息提供者”</strong>，它回答“<strong>是什么？</strong>”（What is the target? What is the noise?）</li><li><strong>3.1 是“命令执行者”</strong>，它回答“<strong>怎么做？</strong>”（How to extract the target and suppress the noise?）</li></ul><p>在本文的实验中，作者假设 <strong>“食材处理员”是完美的</strong>（理想波束成形和VAD），这样就能确保如果最终“菜肴”不好吃，那问题一定不是出在食材上，而很可能是出在<strong>决定上哪道菜的“大堂经理”（3.3 AAD）</strong> 身上，或者“主厨”的算法本身。这就隔离了变量，让作者能专注于研究AAD的性能影响。</p></div><!----><!--[--><h2 id="doc-changelog" tabindex="-1"><a href="#doc-changelog" class="header-anchor"><span>更新日志</span></a></h2><div class="vp-changelog-wrapper"><div class="vp-changelog-header"><div class="vp-latest-updated"><span class="vp-changelog-icon"></span><span data-allow-mismatch>2025/12/1 15:19</span></div><div><span class="vp-changelog-menu-icon"></span><span>查看所有更新日志</span></div></div><ul class="vp-changelog-list"><!--[--><li class="vp-changelog-item-commit"><span class="vp-changelog-hash" target="_blank" rel="noreferrer"><code>93638</code></span><span class="vp-changelog-divider">-</span><span class="vp-changelog-message">fix: Improve clarity and structure in the introduction and background sections of the auditory attention decoding literature review</span><span class="vp-changelog-date" data-allow-mismatch>于 <time datetime="2025-12-01T15:19:56.000Z">2025/12/1</time></span></li><li class="vp-changelog-item-commit"><span class="vp-changelog-hash" target="_blank" rel="noreferrer"><code>3f796</code></span><span class="vp-changelog-divider">-</span><span class="vp-changelog-message">fix: Enhance clarity in the abstract and introduction sections of the literature review on auditory attention decoding for hearing aids</span><span class="vp-changelog-date" data-allow-mismatch>于 <time datetime="2025-12-01T05:51:57.000Z">2025/12/1</time></span></li><li class="vp-changelog-item-commit"><span class="vp-changelog-hash" target="_blank" rel="noreferrer"><code>6ab22</code></span><span class="vp-changelog-divider">-</span><span class="vp-changelog-message">Add literature review on the impact of auditory attention decoding accuracy on noise reduction systems for hearing aids</span><span class="vp-changelog-date" data-allow-mismatch>于 <time datetime="2025-11-27T07:44:33.000Z">2025/11/27</time></span></li><!--]--></ul></div><!--]--><!----></div><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/AmaraMeng/AmaraMeng.github.io/edit/main/src/reading/literature/02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.md" aria-label="在 GitHub 上编辑此页" rel="noopener noreferrer" target="_blank"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->在 GitHub 上编辑此页<!----></a></div><div class="vp-meta-item git-info"><!----><div class="contributors"><span class="vp-meta-label">贡献者: </span><!--[--><!--[--><span class="vp-meta-info" title="email: ranmeng9558@gmail.com">AmaraMeng</span><!--]--><!--]--></div></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/reading/literature/01-EEG-based-detection-of-the-locus-of-auditory-attention-with-convolutional-neural-networks.html" aria-label="01. 基于EEG的卷积神经网络听觉注意力定位检测"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><i class="vp-icon iconfont icon-boke" sizing="height"></i>01. 基于EEG的卷积神经网络听觉注意力定位检测</div></a><!----></nav><div id="comment" class="waline-wrapper vp-comment" vp-comment darkmode="false" style="display:block;"><!----></div><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><div class="vp-footer">默认页脚</div><div class="vp-copyright">Copyright © 2025 Ran </div></footer></div><!--]--><!--[--><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script type="module" src="/assets/app-BAzPzQ_Y.js" defer></script>
  </body>
</html>
