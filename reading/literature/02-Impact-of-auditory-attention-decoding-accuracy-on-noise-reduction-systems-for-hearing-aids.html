<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.24" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.95" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"02. 听觉注意解码准确性对助听器降噪系统的影响","image":[""],"datePublished":"2025-11-27T01:44:44.000Z","dateModified":"2025-12-01T05:51:57.000Z","author":[{"@type":"Person","name":"Ran"}]}</script><meta property="og:url" content="https://pythiaroot.com/reading/literature/02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.html"><meta property="og:site_name" content="Pythia’s Root"><meta property="og:title" content="02. 听觉注意解码准确性对助听器降噪系统的影响"><meta property="og:description" content="Impact of auditory attention decoding accuracy on noise reduction systems for hearing aids (2026) 题目及作者题目及作者 摘要 Hearing aid users often struggle to focus on a specific target sp..."><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2025-12-01T05:51:57.000Z"><meta property="article:author" content="Ran"><meta property="article:published_time" content="2025-11-27T01:44:44.000Z"><meta property="article:modified_time" content="2025-12-01T05:51:57.000Z"><link rel="icon" href="/logo.jpg"><title>02. 听觉注意解码准确性对助听器降噪系统的影响 | Pythia’s Root</title><meta name="description" content="Impact of auditory attention decoding accuracy on noise reduction systems for hearing aids (2026) 题目及作者题目及作者 摘要 Hearing aid users often struggle to focus on a specific target sp...">
    <link rel="preload" href="/assets/style-fescsFu7.css" as="style"><link rel="stylesheet" href="/assets/style-fescsFu7.css">
    <link rel="modulepreload" href="/assets/app-dXkzPG9u.js"><link rel="modulepreload" href="/assets/02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.html-DTWZBGoj.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/assets/index.html-DJI9sebf.js" as="script"><link rel="prefetch" href="/assets/intro.html-BH7lutK-.js" as="script"><link rel="prefetch" href="/assets/Cao-jing-JYM.html-Y5QNQSfj.js" as="script"><link rel="prefetch" href="/assets/01-Ch1.html-C81JffnS.js" as="script"><link rel="prefetch" href="/assets/01-basic-math-knowledge.html-C3YTU9g0.js" as="script"><link rel="prefetch" href="/assets/00-python-tips.html-Bs_Zu_h5.js" as="script"><link rel="prefetch" href="/assets/01-variable.html-BlJ7bSV1.js" as="script"><link rel="prefetch" href="/assets/02-data-type.html-D-yVDeDJ.js" as="script"><link rel="prefetch" href="/assets/02-test-variable-datatype.html-DzTYcGe9.js" as="script"><link rel="prefetch" href="/assets/03-numeric-type.html-CpGf6-p9.js" as="script"><link rel="prefetch" href="/assets/04-string.html-hW0Zh6BC.js" as="script"><link rel="prefetch" href="/assets/05-list.html-JzWmQw2C.js" as="script"><link rel="prefetch" href="/assets/06-tuple.html-BixyY7ZD.js" as="script"><link rel="prefetch" href="/assets/07-dict.html-B967FaBB.js" as="script"><link rel="prefetch" href="/assets/08-set.html-C6TxVC-1.js" as="script"><link rel="prefetch" href="/assets/09-bool.html-Bs-L5wGQ.js" as="script"><link rel="prefetch" href="/assets/10-if.html-C79oPXVj.js" as="script"><link rel="prefetch" href="/assets/11-while.html-Bjk6ZPV8.js" as="script"><link rel="prefetch" href="/assets/12-for.html-DK_2JPhZ.js" as="script"><link rel="prefetch" href="/assets/13-functions.html-BGrj2vpE.js" as="script"><link rel="prefetch" href="/assets/14-class.html-CL52HTFt.js" as="script"><link rel="prefetch" href="/assets/15-environment.html-D66JlPJw.js" as="script"><link rel="prefetch" href="/assets/16-python3-errors-and-exceptions.html-BnKys5WB.js" as="script"><link rel="prefetch" href="/assets/17-TBSgame.html-DZKUJI5J.js" as="script"><link rel="prefetch" href="/assets/18-deepseek-api.html-B6vrBgkr.js" as="script"><link rel="prefetch" href="/assets/19-local-LLM.html-BgEjK7o7.js" as="script"><link rel="prefetch" href="/assets/20-anaconda-install.html-C9F6IbZC.js" as="script"><link rel="prefetch" href="/assets/21-python-install.html-BiDiYpcX.js" as="script"><link rel="prefetch" href="/assets/22-files-opt.html-mrn_ImXj.js" as="script"><link rel="prefetch" href="/assets/Markdown-formula.html-DswN8WIN.js" as="script"><link rel="prefetch" href="/assets/Static-website-building.html-DS5xddA7.js" as="script"><link rel="prefetch" href="/assets/article-typora.html-BVvfgXx3.js" as="script"><link rel="prefetch" href="/assets/01-LOVEintheTIMEofCHOLERA.html-CF65Z8XB.js" as="script"><link rel="prefetch" href="/assets/02-Tuesdays-with-Morrie.html-D0nHcR-E.js" as="script"><link rel="prefetch" href="/assets/01-EEG-based-detection-of-the-locus-of-auditory-attention-with-convolutional-neural-networks.html-DPvl1KDL.js" as="script"><link rel="prefetch" href="/assets/01-human-DK10000.html-CWA_d3B6.js" as="script"><link rel="prefetch" href="/assets/404.html-Cin9qyrZ.js" as="script"><link rel="prefetch" href="/assets/index.html-DZlvjNyO.js" as="script"><link rel="prefetch" href="/assets/index.html-CC6v-Lck.js" as="script"><link rel="prefetch" href="/assets/index.html-BG9eUxI-.js" as="script"><link rel="prefetch" href="/assets/index.html-C5NdfHtM.js" as="script"><link rel="prefetch" href="/assets/index.html-C6sy2ogQ.js" as="script"><link rel="prefetch" href="/assets/index.html-BKLAujC0.js" as="script"><link rel="prefetch" href="/assets/index.html-DRDWkFUd.js" as="script"><link rel="prefetch" href="/assets/index.html-CNG1wt-h.js" as="script"><link rel="prefetch" href="/assets/index.html-DlU8OLqP.js" as="script"><link rel="prefetch" href="/assets/index.html-9FRjPBJd.js" as="script"><link rel="prefetch" href="/assets/index.html-CeXWD_Hi.js" as="script"><link rel="prefetch" href="/assets/index.html-BGPr2dsc.js" as="script"><link rel="prefetch" href="/assets/index.html-BKxH_wNn.js" as="script"><link rel="prefetch" href="/assets/index.html-DXtMrwFF.js" as="script"><link rel="prefetch" href="/assets/index.html-CeSiIJme.js" as="script"><link rel="prefetch" href="/assets/index.html-2aPP2RfU.js" as="script"><link rel="prefetch" href="/assets/index.html-Rn4r0_Bc.js" as="script"><link rel="prefetch" href="/assets/index.html-KDTQDWae.js" as="script"><link rel="prefetch" href="/assets/index.html-Ddkqykp7.js" as="script"><link rel="prefetch" href="/assets/index.html-Bz2PFFlO.js" as="script"><link rel="prefetch" href="/assets/index.html-CLgEESh_.js" as="script"><link rel="prefetch" href="/assets/index.html-CGPtStdj.js" as="script"><link rel="prefetch" href="/assets/index.html-Db8WYSej.js" as="script"><link rel="prefetch" href="/assets/index.html-DyaTKANP.js" as="script"><link rel="prefetch" href="/assets/mermaid.esm.min-B66MqglB.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-CKV1Bsxh.js" as="script"><link rel="prefetch" href="/assets/waline-meta-l0sNRNKZ.js" as="script"><link rel="prefetch" href="/assets/component-D1qKURgw.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><a class="route-link vp-brand" href="/" aria-label="带我回家"><img class="vp-nav-logo" src="/阿尔法 logo.jpg" alt><!----><span class="vp-site-name hide-in-pad">Pythia’s Root</span></a><!--]--></div><div class="vp-navbar-center"><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/" aria-label="Pythia’s Root"><!--[--><i class="vp-icon iconfont icon-house" sizing="height"></i><!--]-->Pythia’s Root<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="编程"><!--[--><i class="vp-icon iconfont icon-biancheng-01" sizing="height"></i>编程<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/programming/static-website-blog/" aria-label="Static website building-blog"><!--[--><i class="vp-icon iconfont icon-boke" sizing="both"></i><!--]-->Static website building-blog<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/programming/python/" aria-label="Python"><!--[--><i class="vp-icon iconfont icon-python" sizing="both"></i><!--]-->Python<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/programming/ThinkDSP/" aria-label="ThinkDSP"><!--[--><i class="vp-icon iconfont icon-python" sizing="both"></i><!--]-->ThinkDSP<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/programming/math-for-ai/" aria-label="Math for AI"><!--[--><i class="vp-icon iconfont icon-python" sizing="both"></i><!--]-->Math for AI<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/#" aria-label="人工耳蜗"><!--[--><i class="vp-icon iconfont icon-rengongerwoshenqing" sizing="height"></i><!--]-->人工耳蜗<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/#" aria-label="语音学"><!--[--><i class="vp-icon iconfont icon-shengboyuyinxiaoxi" sizing="height"></i><!--]-->语音学<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="翻译"><!--[--><i class="vp-icon iconfont icon-fanyi" sizing="height"></i>翻译<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/translation/vocabulary/" aria-label="词汇"><!--[--><i class="vp-icon iconfont icon-cihuiben" sizing="both"></i><!--]-->词汇<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/translation/peki/" aria-label="Peki"><!--[--><i class="vp-icon iconfont icon-fanyi" sizing="both"></i><!--]-->Peki<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/sports/" aria-label="运动"><!--[--><i class="vp-icon iconfont icon-jianshenfang" sizing="height"></i><!--]-->运动<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="阅读"><!--[--><i class="vp-icon iconfont icon-yuedu" sizing="height"></i>阅读<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link route-link-active auto-link" href="/reading/literature/" aria-label="文献"><!--[--><i class="vp-icon iconfont icon-yuedu" sizing="both"></i><!--]-->文献<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/reading/books/" aria-label="书籍"><!--[--><i class="vp-icon iconfont icon-yuedu" sizing="both"></i><!--]-->书籍<!----></a></li></ul></button></div></div></nav><!--]--></div><div class="vp-navbar-end"><!--[--><!----><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/AmaraMeng/AmaraMeng.github.io" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><form class="search-box" role="search"><input type="search" placeholder="搜索" autocomplete="off" spellcheck="false" value><!----></form><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/" aria-label="Pythia’s Root"><!--[--><i class="vp-icon iconfont icon-house" sizing="both"></i><!--]-->Pythia’s Root<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Programming</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">Reading</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Books</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">Literature</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/reading/literature/01-EEG-based-detection-of-the-locus-of-auditory-attention-with-convolutional-neural-networks.html" aria-label="01. 基于EEG的卷积神经网络听觉注意力定位检测"><!--[--><i class="vp-icon iconfont icon-boke" sizing="both"></i><!--]-->01. 基于EEG的卷积神经网络听觉注意力定位检测<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/reading/literature/02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.html" aria-label="02. 听觉注意解码准确性对助听器降噪系统的影响"><!--[--><i class="vp-icon iconfont icon-boke" sizing="both"></i><!--]-->02. 听觉注意解码准确性对助听器降噪系统的影响<!----></a></li></ul></section></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Sports</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Translation</span><span class="vp-arrow end"></span></button><!----></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/intro.html" aria-label="介绍页"><!--[--><i class="vp-icon iconfont icon-circle-info" sizing="both"></i><!--]-->介绍页<!----></a></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><i class="vp-icon iconfont icon-boke" sizing="height"></i>02. 听觉注意解码准确性对助听器降噪系统的影响</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">Ran</span></span><span property="author" content="Ran"></span></span><span class="page-original-info">原创</span><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">2025/11/27</span><meta property="datePublished" content="2025-11-27T01:44:44.000Z"></span><span class="page-pageview-info" aria-label="访问量🔢" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon eye-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="eye icon" name="eye"><path d="M992 512.096c0-5.76-.992-10.592-1.28-11.136-.192-2.88-1.152-8.064-2.08-10.816-.256-.672-.544-1.376-.832-2.08-.48-1.568-1.024-3.104-1.6-4.32C897.664 290.112 707.104 160 512 160c-195.072 0-385.632 130.016-473.76 322.592-1.056 2.112-1.792 4.096-2.272 5.856a55.512 55.512 0 00-.64 1.6c-1.76 5.088-1.792 8.64-1.632 7.744-.832 3.744-1.568 11.168-1.568 11.168-.224 2.272-.224 4.032.032 6.304 0 0 .736 6.464 1.088 7.808.128 1.824.576 4.512 1.12 6.976h-.032c.448 2.08 1.12 4.096 1.984 6.08.48 1.536.992 2.976 1.472 4.032C126.432 733.856 316.992 864 512 864c195.136 0 385.696-130.048 473.216-321.696 1.376-2.496 2.24-4.832 2.848-6.912.256-.608.48-1.184.672-1.728 1.536-4.48 1.856-8.32 1.728-8.32l-.032.032c.608-3.104 1.568-7.744 1.568-13.28zM512 672c-88.224 0-160-71.776-160-160s71.776-160 160-160 160 71.776 160 160-71.776 160-160 160z"></path></svg><span id="ArtalkPV" class="vp-pageview waline-pageview-count" data-path="/reading/literature/02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.html" data-page-key="/reading/literature/02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.html">...</span></span><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 22 分钟</span><meta property="timeRequired" content="PT22M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item color2 clickable" role="navigation">reading</span><span class="page-category-item color8 clickable" role="navigation">literature</span><!--]--><meta property="articleSection" content="reading,literature"></span><!----></div><hr></div><!----><div class="" vp-content><!----><div id="markdown-content"><p><strong>Impact of auditory attention decoding accuracy on noise reduction systems for hearing aids (2026)</strong></p><figure><img src="/assets/image-20251127015134844-Cbd0BLmf.png" alt="题目及作者" tabindex="0" loading="lazy"><figcaption>题目及作者</figcaption></figure><h2 id="摘要" tabindex="-1"><a class="header-anchor" href="#摘要"><span>摘要</span></a></h2><p>Hearing aid users often struggle to focus on a specific target speaker in multi-talker environments. Auditory attention decoding (AAD) algorithms, which extract attentional cues from electroencephalogram (EEG) signals, offer a potential solution. This study evaluates <strong>how AAD accuracy and decision window length affect the performance of a multichannel Wiener filter noise reduction system in a speaker and story-independent scenario</strong>. Simulations in two-speaker anechoic conditions show that, for decision windows of 1 s or less, AAD accuracies approximately above 81 % are required to meet minimum conversational speech quality (PESQ = 2.0), while accuracies approximately above 64 % suffice for intelligibility (STOI = 0.62). These results define quantitative performance targets for integrating AAD-based noise reduction into hearing aids and highlight the trade-off between decision latency, decoding accuracy, and perceptual benefit under idealized beamforming/VAD and anechoic conditions with high-density EEG.</p><p>助听器使用者在多说话者环境中常常难以专注于特定的目标说话者。听觉注意解码（AAD）算法可以从脑电图（EEG）信号中提取注意线索，提供一个潜在的解决方案。本研究评估了<strong>AAD准确率和决策窗口长度如何影响多通道维纳滤波噪声抑制系统在说话者和故事独立场景中的性能</strong>。双说话者无回声条件下的仿真表明，对于1秒或更短的决策窗口，AAD准确率需要大约超过81%才能达到最低的会话语音质量（PESQ = 2.0），而大约超过64%的准确率就足以满足可懂度要求（STOI = 0.62）。这些结果为将基于AAD的噪声抑制集成到助听器中设定了量化的性能目标，并突出了在理想的波束形成/VAD和无回声条件下、高密度EEG环境中决策延迟、解码准确率与感知收益之间的权衡。</p><h2 id="_1-introduction" tabindex="-1"><a class="header-anchor" href="#_1-introduction"><span>1. Introduction</span></a></h2><h3 id="_1-1-研究背景" tabindex="-1"><a class="header-anchor" href="#_1-1-研究背景"><span>1.1 研究背景</span></a></h3><ol><li><p><strong>问题背景：</strong></p><p>听力损失用户在多说话人（“鸡尾酒会”）环境中难以聚焦于目标说话人，现有助听器在此方面存在不足。</p></li><li><p><strong>现有解决方案与局限：</strong></p><p><strong>传统方法</strong>：依赖音量、视线方向等启发式规则，在目标源不具备这些特征时效果不佳。</p><p><strong>新兴技术</strong>：基于脑电图（EEG）的<strong>听觉注意力解码（AAD）</strong> 技术，可直接从大脑信号中解码用户注意力。</p><ul><li><p><strong>两大技术路径</strong>：</p><ul><li><p><strong>神经引导的语音提取</strong>：使用EEG信号直接引导深度学习模型从混合语音中提取目标语音。但存在模型复杂、泛化能力差（如依赖特定说话人）等问题，不适用于现实助听器。</p></li><li><p><strong>分离后分类</strong>：先分离各说话人信号（提供多个备选），再用AAD选择目标。这种方法<strong>更易于在助听器上实现</strong>，是本文采用的技术路径。</p><blockquote><h3 id="为何-更易于在助听器上实现" tabindex="-1"><a class="header-anchor" href="#为何-更易于在助听器上实现"><span><strong>为何“更易于在助听器上实现”？</strong></span></a></h3><p>与第一种“端到端”方法相比，这种模块化设计有两大优势：</p><ol><li><strong>计算负载分离与降低</strong>： <ul><li><strong>语音分离模块</strong>和<strong>EEG解码模块</strong>可以独立优化。语音分离可以使用经典的、计算效率高的信号处理算法（如MWF）。</li><li>EEG解码虽然仍需神经网络，但它的任务被简化为一个相对简单的<strong>分类问题</strong>（左/右），而不是复杂的语音波形重构问题。这大大降低了模型的复杂度和计算需求。</li></ul></li><li><strong>系统更鲁棒、更易调试</strong>： <ul><li>每个模块的功能明确，可以单独测试和评估。如果效果不好，可以定位问题是出在“分离不准”还是“选择不对”。</li><li>更容易集成现有的、成熟的助听器技术（如波束成形器）。</li></ul></li></ol></blockquote></li></ul></li></ul></li><li><p><strong>核心矛盾</strong>：AAD的<strong>准确率</strong>与<strong>决策窗口长度（延迟）</strong> 之间存在权衡。短窗口（低延迟）是实用性的关键，但会导致准确率下降。先前研究使用了<strong>长达30秒的决策窗口</strong>，这在现实中<strong>完全不实用</strong>。</p></li><li><p><strong>参考的核心文献局限</strong></p></li></ol><ul><li>只评估了AAD本身的分类性能，<strong>未集成到噪声抑制系统中</strong>评估最终语音效果。</li><li>依赖需要先验知识的<strong>伪迹去除算法</strong>。</li><li>存在<strong>数据泄露</strong>问题，导致性能评估虚高。</li></ul><ol start="5"><li><p><strong>其他局限：</strong></p><p>大多数研究只报告AAD分类准确率，但助听器的适用性最终取决于<strong>语音可懂度与质量</strong>。</p></li></ol><h3 id="_1-2-本文贡献" tabindex="-1"><a class="header-anchor" href="#_1-2-本文贡献"><span>1.2 本文贡献</span></a></h3><ul><li><strong>核心目标</strong>：在<strong>说话者和故事独立</strong>的实用场景下，量化研究<strong>AAD准确率</strong>和<strong>决策窗口长度</strong>如何影响噪声抑制系统的<strong>客观语音质量（PESQ）</strong> 和<strong>可懂度（STOI）</strong>。</li><li><strong>最终目的</strong>：为将AAD集成到助听器中，确定其<strong>准确率和延迟的最低性能要求</strong>，为实际设计提供定量基准。</li></ul><h2 id="_2-acoustic-scenario-description" tabindex="-1"><a class="header-anchor" href="#_2-acoustic-scenario-description"><span>2. Acoustic scenario description</span></a></h2><h3 id="_2-1-核心内容概括" tabindex="-1"><a class="header-anchor" href="#_2-1-核心内容概括"><span>2.1 核心内容概括</span></a></h3><p>这一部分描述了一个<strong>理想化的双说话人混响场景</strong>：</p><ul><li><p><strong>位置</strong>：一位听者，其左右两侧（方位角±90°）各有一个说话人。</p></li><li><p><strong>设备</strong>：助听器共有 <code>M</code> 个麦克风，线性分布在双耳（左耳 <code>M/2</code> 个，右耳 <code>M/2</code> 个，信号通过无线传输同步）。</p></li><li><p><strong>接收信号</strong>：这些麦克风会捕捉到：</p><ul><li><p><code>N</code> 个不同说话人的语音信号。</p></li><li><p>环境中的环境噪声（扩散声场）和电路噪声。</p></li></ul></li><li><p><strong>关键假设</strong>：</p><ul><li>语音源和噪声是<strong>遍历的</strong>，其统计特性可以在短时窗口内估计。</li><li>语音与噪声之间是<strong>不相关的</strong>。</li></ul></li></ul><h3 id="_2-2-公式解读" tabindex="-1"><a class="header-anchor" href="#_2-2-公式解读"><span>2.2 公式解读</span></a></h3><figure><img src="/assets/image-20251127032915033-BjT4wfN0.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><strong>公式 (1): 单个麦克风接收到的信号</strong></p><figure><img src="/assets/image-20251127030012189-BMSZ4FVp.png" alt="公式1" tabindex="0" loading="lazy"><figcaption>公式1</figcaption></figure><ul><li><strong><code>yₘ(λ, k)</code></strong>：在第 <code>m</code> 个麦克风的 <strong>时频点 <code>(λ, k)</code></strong> 上接收到的总信号。（<code>λ</code> 是时间帧索引，<code>k</code> 是频率点索引）</li><li><strong><code>Σ xₘᵢ(λ, k)</code></strong>：所有 <code>N</code> 个说话人的语音信号在第 <code>m</code> 个麦克风处叠加的结果。</li><li><strong><code>nₘ(λ, k)</code></strong>：在第 <code>m</code> 个麦克风处收到的环境噪声和电路噪声。</li></ul><blockquote><p><strong>通俗理解</strong>：这个公式就是说，<strong>每个麦克风听到的声音 = 所有说话人声音的混合 + 背景噪音</strong>。</p></blockquote><p><strong>公式 (2): 语音信号的建模</strong></p><p>公式(2) 是公式(1) 的一部分</p><figure><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAa0AAAAwCAIAAAAtu7JJAAAAAXNSR0IArs4c6QAAD6FJREFUeJztnWtQU0cbxzeBUAhFlKuIFq3YqG0tFrwwKEIBqxUdQbFcCohaTMuM1SLghdJWxFIKIyq2YwWrkqJgAzhiQbkLIgVCkFHkogI28RLFNMQASUzO+2FnzptJSDgQL5Hs7xNn98mzz+7J+Wf37AUShmEAgUAg9Bjy6w4AgUAgXjNIBxEIhL6DdBCBQOg7SAcRCIS+g3QQgUDoO0gHEQiEvoN0EIFA6DtIBxEIhL6DdBCBQOg7SAcRCIS+g3QQgUDoO0gHEQiEvqNbOigSiX788UftnVy7du3XX3+NiopqbW1VNdi3b9/g4KCWpbw89KQRUlNTeTyelk56enoKCgoSEhL279+vmltZWXnp0iUti0DoBZjOIJVKV69e3dbWpppVVVXF4/EI+omLi1u4cKGBgQEA4M6dO6oGbW1tAQEBMplM65BfPHrSCPHx8adOnVJNf/jwYXV1NUEnra2tXl5e9vb2AIDQ0NBhbeh0elVVlXbBIsY/OqSDMTExp0+fVk2HP/Xu7u7EXT179oxMJk+cOFGdwalTpxISEsYa6UtEHxqhqKho8+bNqumPHz+eMmUKAKC8vJy4t9jYWABAenr6sLmDg4Pu7u7Efz8Q+omujIvb29srKipCQ0OV0sVisUgk4vF4d+/effbsGUFvbDZbLpc7OzurMwgNDS0sLLx9+7Z2Ub9g9KERxGJxTEzMsMPYwsLCv//+OzU1tbi4mLhDFosFAFBXTWNj461bt+7evVuLkBHjH13RwR9++IFOp6umc7ncXbt2WVtbL1mypK+vj6A3zc8GAIBEIkVFRQ37NL5G9KER/vjjj48//njy5MmqWc7Ozh999JGvr++TJ0+IO2xubiaTyU5OTuoMNmzYUFZWdvfu3bGGjBj/ENVBHo936tSpuro6xcQrV65kZGQ8ffpUyyCePn168eLF4OBg1ax33313woQJAABTU1MTExOCDqEEuLi4wMv+/v7ff/+9pKRE0cbPz+/cuXMCgUDL4Inw6NGjnJycjIwMNputzkbXGkEkEhUWFh48eJDJZA4ODtbX12s/rQEAyMrK2rhx47BZ8+fPH20d7969y+fzZ8+e/fbbb8OU2trao0ePPn78GLcxNDT09fXNysrSPnjEuIXI4Dk5OZlCoQAAjIyM8Ff4+Fhj69atWg7O//zzTxcXF802AQEBAwMDBB3OnTsXnx+4d+/erFmzYKhdXV2KZrNnz2YymVoETojffvtt5syZwcHBZDKZRCLV1NQMa6ZTjXD8+HEbG5t33nlny5YtNBrN2toa9rwIFq0ODodDJpMFAoEGm5s3b8bGxhJ0mJeXpzhJcuDAAVjHkJAQRbOzZ89++OGHWgSOGOcQnScRi8U7d+4EAERERGAYdvjwYVNT071795qZmZ04cULLIOh0+ldffaXBoKurS8P7fiUU5we4XK6jo6OHh4e3t/fq1aslEomiZURExPbt27WLfQSqq6tJJFJZWRn85Zg8eXJ7e/uwlrrTCD/99BMAYPPmzVBzq6qqAAA2NjYEi9bA2bNn58yZo9lm69atiYmJBB3GxcXhkyQpKSnGxsYxMTG2trbFxcWKZr29vSQSic/naxE7YjxjSLDbaGRktHv37qNHj/71118xMTFxcXFMJnPlypV79uyhUqla9kl7e3s9PT3V5Uql0qCgIOLeWlpa4PwAj8fz8vJaunTpsWPHDAwMyGTllwBTpkzRMFDFMGzVqlV8Pn/EEm1sbM6fPz9sVklJCZy1BAAkJSXhHRZVdKQRWCzW3r17Fy9eDO0BAEKhEADg5uZGvHR19Pb2zpgxQ4NBfn7+sWPH0tPTCTrE34EePnw4NTW1oqLC1dU1OTlZqZp2dnbwh2TBggXa1QAxPiGqgwAACwuL9evXZ2dn+/r6hoeHr1y5EgAwBhGUyWRJSUlr1qzB320/evRo4sSJ6uz37Nlz69YtGo1G0H9zczMAYPr06d7e3vb29idOnNBQIw6Hoy6XRCLl5uZKJJIRS3zrrbfUZb333nsAADqdXllZiY9MdbkREhIS5HJ5fHw8FEEoqQCAxYsXEyxakezsbBMTk/Xr18NLzXX8999/t2zZMmPGDPxl34iw2WwymdzQ0BAdHV1TU+Pq6goAUNV6CoViZmbG4XCQDiKGZXTzxYGBgQAADofz3XffjblIsVick5PT1NSEpzx+/NjMzGxY48uXL6elpSUnJ1tZWRH0D/sIDAajra2toaFBJBKps5w0aZKGXACAmZmZJQE0PLchISHu7u5cLnfRokUVFRV4um42gkAgKC0tNTY29vHxwQ1gb3HhwoUEi1akuLi4qKgIv9RQR7lc/sUXX0yYMGHbtm3qbJTo6enp6+sjkUh79uyBu0c0GI94rxH6zOh0EHYNZDKZhh7QiFCp1Pb29i1btvw/CDJ52G4Xj8cLDw9funRpVFSUWCwm6B9KQFZWVnBwsFAoPHPmjDpLsVhsbm4+pkoQhUKhFBcX+/n58fn8zz77DJ9w181G6OjokEqlM2fONDIywg3gTYeTuaMlJyfn5MmT+KW6OgIA9u/ff+XKlczMTIlEQlAHYR3nz59fU1NDJpMzMzNlMpk641dwrxFvLqMYF/f19aWnp3/wwQc3btw4f/78pk2bYDqPxzt06BCLxYqKirp+/Xp5eXlsbOzMmTOTk5M5HA6cLcWdlJSUMJlMDoejuFbW0tJSdekGhmEbN27s7+8/ceKEWCw2NCQU6uDg4K1btywsLEJCQubNm8dgMFJTUyMiIvBRniL//fefjY2NOlcYhm3evBm+HdOMhYXFsWPH1OVSqVQmkxkWFsZgMOLj4ysqKnS2EeByE1NTUzxXIBB0d3c7ODhAEcnPz79w4cLQ0ND27dt/+eUXY2PjrKyskydP5uXleXl5wX4Z5NatW8ePH2ez2ZmZmfgXwNLSsqenRzWGurq6ffv2RUZGent7l5WVjUoHQ0NDFyxY4Ofnx2Qyz549GxISMqyx5nuN0HdGnEmRSqUDAwNyuXzt2rW+vr4FBQUAgEWLFuEGMpmspqYGALBixYqSkpKFCxdOmzYtNja2vLycQqGkpKQoehOJRHQ6fdmyZYqJ69ev3717t1K5Bw8exKcCeTyeh4cHhmFNTU1DQ0PQ4N69e1KpVOlTsMPl4+MDL1etWgUAyMjIGLZq3377bXh4uIa6d3R0tBBAaSUKRCwW+/v7e3t7w2nKmzdvAgCWLFmiy43wzz//AACsrKzwfce5ubkAgOXLl8NLoVC4Zs0aOzu7xMTE48ePw5vOZDIjIiKoVKqiW4lEcvr0aQqFIhaL8cSMjAxXV1elAPh8voODw7Rp0+B6mq+//hruCK6rq4MGQ0NDXC5XNfLly5cDAK5evYphWGNjIwDAwcHh2bNnqpb9/f0AgO7ubsVEpUuEPjOCDg4NDTk6Ojo7OwcGBlpaWnK5XIlEAne2w+Uy8GuXm5trZmYGv8dBQUFr167FMEwul1Op1NzcXCWfK1euVFqokZKS8umnnyqmsNlsIyMjNzc3+EByuVwrK6uenp4dO3ZAg+rqagCAv7+/kvMjR44AAHBBuXbtGuyRwd37SivXli1bpk4dtAdOPlhYWECdYjAYAIDMzEyYq5uNIJVK4c3dsWNHU1NTQkICfPXp4uLC5/NbWlowDJszZw7cldzR0QFHzXCFqeqCmJ9//tnJyUkxpaGhgUqlPn/+XDExICAAn1jHMOzLL79MTExkMpkXL16EKZ6engYGBmw2W8m/lZWVgYEBvqByxYoVAIB169YNDQ319/fL5XLcsrKy0traWjEFnuhz+PBhlfuG0EdG0EGhUAgn+Ozt7VtbW2FiYWEhHGE5OjqWlpbC0wFgVwXDMBqNlpaWhmFYe3s7XPGv5HPy5MlKZ42wWCxLS0v8UiQS0Wg0ExOTzs5OmPL8+XNbW1symYw/G21tbVOnTlVdeAz3KiguDI6OjoY9XxqNlpeXh6fLZDIzMzN1q/leCHFxcYaGhk5OThs2bLCzs1PUXJ1thPLycgsLC2js4+PT2NgIlwSYmppu2rRJKBSSyWTYXztz5oy5uTkUl8DAwLCwMKUwAgMD4WpTHKlUOmnSJPyLhGFYZmYmXKuIp2RkZAAAXF1dcdmKioqaPXv2oUOHFF3B8bXi6ujOzk47OzsAwIQJE1asWKHYTU5JSQkKClL8OIPBsLe3j4yMxBAIIuuoHz16dPXqVaVtDHfu3GlpacGHPJ6ennAPgEAgwLdMMBgMxQcb8uDBAwDA9evXldLnzZtXWVmpIQwul6v4/EAIHpdy8+bNlpYWpW5IaWmp6hjthfPkyZO6urrGxkZ8JKv7jSAUCuvr6/HTujgcTn19/eDgIOyBkslkoVAIB9ReXl7QxtHR8ciRI0p+aDSaknhhGLZt27bvv/9ec6g1NTVKw1uBQAB/XDUjFApra2tVT5dxc3O7dOmSqr1unjmEePW8gHO35HK5ubn5uXPnMAyrqKgwMDCAX+JvvvnG29sb2vT09MCeY3FxsaGhodKWBgzDTp48+fnnn4+26BGfKA2sWbPmFWyqG5Y3txHS0tLef/99+Le7u/uuXbvgCz4SiVRbW4th2MDAwJkzZ2B/lkwmq8p6Z2fn9OnTleR4ROrq6vCB82hpbm52cnJSPWlRLBYfOHBgbD4R44wXcN5MV1eXQCCA68saGxvnzp0LJxz7+vpYLFZsbCyfz798+TJ+ksrz588jIyPhC3icsLCw+/fvd3Z2Ei+3o6PDwcFhbDG3tbWJRCJ/f/+xfVx73tBGaGpqgjdaLpc3NzfDZclwlnnfvn0FBQV37tyJjo5ms9kSiYRCoSQlJSUlJSl6mDVrVkBAQHZ29qhCLSoq8vb2HtVHcFJSUtLT01UXV2dnZ69bt25sPhHjjZcnsWKx+Pbt2/jvcH5+Pvyjt7d32MMCOjo6PDw8FMePGpDJZNHR0aPtVkAGBgY++eST3t7eMXz2RTHOGuH+/ft9fX3w797eXhaLBSe48USloj08PPD3niNy4cKFYUe1RMjOzo6Li1NN7+7uJjLQRugJr+48atWJY1Wqqqp27txJ0OGYz5TfsWNHfX392D77CnjTG6GgoEB1yK8El8sNDg4WiUREHI65jjdu3KDT6cN+XDf/KwPidUHCMOwV9Drh+q+pU6eOaHn//n14OPvL48GDB3BiUWd5cxtBLpezWCwi23iFQiGJRCK+lXgMPHz40NbWlkQivbwiEOODV6SDCAQCobPoyrn8CAQC8bpAOohAIPQdpIMIBELfQTqIQCD0HaSDCARC30E6iEAg9B2kgwgEQt9BOohAIPQdpIMIBELfQTqIQCD0HaSDCARC30E6iEAg9J3/AaUu2i5jxH0uAAAAAElFTkSuQmCC" alt="公式2" tabindex="0" loading="lazy"><figcaption>公式2</figcaption></figure><ul><li><strong><code>sᵢ(λ, k)</code></strong>：第 <code>i</code> 个说话人发出的<strong>纯净语音信号</strong>。</li><li><strong><code>aₘᵢ(λ, k)</code></strong>：<strong>声学传递函数</strong>，它模拟了第 <code>i</code> 个声源发出的声音传播到第 <code>m</code> 个麦克风这个过程所发生的变化（如衰减、延迟）。</li><li><strong><code>xₘᵢ(λ, k)</code></strong>：最终，第 <code>i</code> 个说话人的声音被第 <code>m</code> 个麦克风捕捉到的版本。</li></ul><blockquote><p><strong>通俗理解</strong>：一个说话人的声音从嘴里发出，经过空气传播，再到被麦克风录下，这个过程会发生改变。<code>aₘᵢ</code> 就是描述这个“改变”的函数。所以，<strong>麦克风收到的某个说话人的声音 = 他发出的原始声音 × 传播路径的影响</strong>。</p></blockquote><p><strong>公式 (3): 所有麦克风信号的向量表示</strong></p><figure><img src="/assets/image-20251127031337699-Xn4fBnWA.png" alt="公式3" tabindex="0" loading="lazy"><figcaption>公式3</figcaption></figure><p>这只是把公式(1)和(2)结合起来，并用<strong>向量形式</strong>表示所有 <code>M</code> 个麦克风的信息，这样更简洁，也便于后续的矩阵运算。</p><ul><li><strong><code>y(λ, k)</code></strong>：一个向量，包含了所有 <code>M</code> 个麦克风在时频点 <code>(λ, k)</code> 上接收到的信号 <code>[y₁, y₂, ..., y_M]ᵀ</code>。</li><li><strong><code>aᵢ(λ, k)</code></strong>：一个向量，包含了第 <code>i</code> 个说话人到所有 <code>M</code> 个麦克风的声学传递函数 <code>[a₁ᵢ, a₂ᵢ, ..., a_Mᵢ]ᵀ</code>。它定义了该说话人的<strong>空间位置信息</strong>。</li><li><strong><code>n(λ, k)</code></strong>：一个向量，包含了所有 <code>M</code> 个麦克风处的噪声 <code>[n₁, n₂, ..., n_M]ᵀ</code>。</li></ul><p><strong>公式 (4) &amp; (5): 定义“期望信号”与“噪声+干扰”</strong></p><p>这里对总信号 <code>y(λ, k)</code> 进行拆分，将其明确分为“我们想要的”和“我们不想要的”两部分。</p><ul><li><p><strong>期望信号向量 <code>x(λ, k)</code></strong>：</p><figure><img src="/assets/image-20251127031911653-BXg24iV9.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>假设第一个说话人 <code>s₁</code> 是听者关注的目标。那么，所有麦克风收到的、来自 <code>s₁</code> 的信号就是期望信号。</p></li><li><p><strong>干扰噪声向量 <code>r(λ, k)</code></strong>：</p><figure><img src="/assets/image-20251127031932922-kQwOcsF0.png" alt="公式4" tabindex="0" loading="lazy"><figcaption>公式4</figcaption></figure><p>这个向量包含了<strong>所有干扰说话人（<code>i=2</code> 到 <code>N</code>）的声音</strong>加上<strong>环境噪声</strong>。在本文的双说话人场景中，<code>i=2</code> 就是那个干扰说话人。</p></li><li><p><strong>总信号的最终简化形式</strong>：</p><figure><img src="/assets/image-20251127031954973-C7DMl3-D.png" alt="公式5" tabindex="0" loading="lazy"><figcaption>公式5</figcaption></figure><p>这个公式至关重要，它将复杂的声学场景<strong>简化为一个清晰的加法模型</strong>：<strong>总信号 = 期望信号 + (干扰 + 噪声)</strong>。</p></li></ul><p><strong>公式(6)</strong></p><figure><img src="data:image/png;base64,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" alt="公式6" tabindex="0" loading="lazy"><figcaption>公式6</figcaption></figure><ul><li><strong><code>x̂(λ, k)</code></strong>: 这是在时频点 <code>(λ, k)</code> 上，对<strong>参考麦克风</strong>处<strong>目标语音</strong> <code>x₁(λ, k)</code> 的<strong>估计值</strong>。也就是我们最终想得到的、增强后的信号。</li><li><strong><code>y(λ, k)</code></strong>: 这是我们熟悉的公式(3)中定义的向量，包含了所有 <code>M</code> 个麦克风在此时频点上接收到的信号 <code>[y₁, y₂, ..., y_M]ᵀ</code>。它是算法的<strong>输入</strong>。</li><li><strong><code>w(λ, k)</code></strong>: 这是<strong>多通道维纳滤波器</strong>在时频点 <code>(λ, k)</code> 上的<strong>复值权重向量</strong> <code>[w₁, w₂, ..., w_M]ᵀ</code>。这个权重向量是算法的核心，它包含了如何整合所有麦克风信息以突出目标、抑制噪声和干扰的“知识”。</li><li><strong><code>(·)^H</code></strong>: 表示<strong>埃尔米特转置</strong>（即共轭转置）。因为我们在处理复值的频域信号，所以需要共轭转置。</li></ul><p>💡 直观理解：</p><p>您可以把这个公式想象成一个<strong>智能的、随时空变化的“音量调节旋钮”组合</strong>：</p><ul><li><strong>目标</strong>：从一堆混乱的麦克风信号 <code>y</code> 中，提取出目标说话人在参考麦克风处的干净声音 <code>x̂</code>。</li><li><strong>方法</strong>：滤波器 <code>w</code> 会对每一个麦克风的信号进行一项复杂的操作： <ul><li><strong>调整幅度（缩放）</strong></li><li><strong>调整相位（延迟）</strong></li></ul></li><li><strong>最终效果</strong>：所有经过这样精心调整后的麦克风信号被加在一起。在这个过程中，<strong>目标说话人的声音因为其特定的空间位置（由向量 <code>a₁</code> 定义）而被同相叠加、增强</strong>；而<strong>噪声和干扰说话人的声音则因为来自不同方向而被异相抵消、削弱</strong>。</li></ul><hr><h3 id="_2-3-问题" tabindex="-1"><a class="header-anchor" href="#_2-3-问题"><span>2.3 问题</span></a></h3><h4 id="q1-公式1的时频点-λ-k" tabindex="-1"><a class="header-anchor" href="#q1-公式1的时频点-λ-k"><span>Q1：公式1的时频点 (λ, k)</span></a></h4><p><strong>1. 什么是“时频点” <code>(λ, k)</code>？</strong></p><p>想象一下你在看一部电影的频谱图：</p><ul><li><strong>横轴 <code>λ</code></strong>：代表<strong>时间</strong>。比如 <code>λ=1</code> 代表电影开始的第10毫秒（取决于窗口长度和重叠），<code>λ=2</code> 代表第20毫秒，以此类推。它把连续的时间切成了一帧一帧的短片段。</li><li><strong>纵轴 <code>k</code></strong>：代表<strong>频率</strong>。比如 <code>k=1</code> 代表0-100Hz，<code>k=2</code> 代表100-200Hz，以此类推。它表示在这一帧时间里，声音是由哪些频率成分构成的。</li><li><strong>时频点 <code>(λ, k)</code></strong>：就是这张图上的一个<strong>像素点</strong>。它精确地表示在<strong>某个特定的短暂时间片段（λ）</strong> 内，<strong>某个特定频率段（k）</strong> 上的信号<strong>强度（或能量）</strong>。</li></ul><p><strong>所以，公式 <code>yₘ(λ, k)</code> 读作：在第 <code>m</code> 个麦克风，第 <code>λ</code> 个时间帧，第 <code>k</code> 个频率 bin 上，接收到的总信号强度。</strong></p><p><strong>2. 为什么需要时频点？（核心原因）</strong></p><p><strong>① 利用“稀疏性”假设</strong><br> 如上图所示，这是最根本的原因。在任意一个<strong>非常短的时间窗口</strong>（例如32ms）内，<strong>多个说话人极少会在完全相同的时间、发出完全相同的频率</strong>。这意味着，在大多数时频点 <code>(λ, k)</code> 上，其能量主要只由<strong>一个</strong>占主导地位的声源（目标说话人或干扰者）贡献，其他声源在该点的能量很弱甚至为零。</p><p><strong>② 简化处理，允许线性滤波</strong><br> 在时频域中，卷积混合（在时间域是复杂的）在窄带假设下可以近似为<strong>瞬时混合</strong>。这就使得公式(3)中的混合模型成立，并且可以使用像<strong>多通道维纳滤波器（MWF）</strong> 这样的<strong>线性滤波器</strong> <code>w(λ, k)</code> 来进行处理。在时间域直接进行类似的线性过滤要困难得多。</p><p><strong>③ 契合语音和非平稳信号的特性</strong><br> 语音和噪声都是<strong>非平稳信号</strong>，它们的统计特性随时间变化。在时频域中，我们可以针对<strong>每一帧（λ）</strong> 来估计和更新信号的统计信息（如协方差矩阵 <code>Φ_y(λ,k)</code>），这让算法能够自适应地跟踪声音环境的变化。</p><p><strong>3. 一个生动的比喻</strong></p><p>把整个一段语音信号想象成一幅<strong>完整的油画</strong>，画上是两个人物重叠在一起。</p><ul><li><strong>在时间域分离</strong>：就像让你不借助任何工具，直接把画上的两个人完美地剥离开，这几乎是不可能的。</li><li><strong>在时频域分离</strong>：就像用一个<strong>高倍放大镜</strong>，逐个像素 <code>(λ, k)</code> 地去观察这幅画。你会发现，在大多数像素点上，其实只显示了一个人物的颜色。你只需要在每个像素点上做一个简单的决定：“这个像素点更可能属于人物A还是人物B？”。</li><li><strong>MWF的作用</strong>：就是这个“决策过程”。它根据麦克风阵列收到的信息，在每个时频点上计算一个最优的权重，来提取目标信号并抑制干扰。</li></ul><p><strong>总结：使用“时频点” <code>(λ, k)</code> 是一种“分而治之”的策略。它将一个全局性的、高度复杂的非线性分离问题，分解成了大量局部的、相对简单的线性估计问题，从而使得实时的、高效的噪声抑制和语音增强成为可能。</strong></p><h2 id="_3-aad-based-noise-reduction-system" tabindex="-1"><a class="header-anchor" href="#_3-aad-based-noise-reduction-system"><span>3. AAD-based noise reduction system</span></a></h2><figure><img src="/assets/image-20251127033944881-C19x5Nb5.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>本文提出一种将多通道波束形成（MWF）与基于脑电图（EEG）的算法结合，用于检测听觉注意力位置的降噪系统。</p><p>两个信号分别位于左右两侧，一个为目标信号，一个为干扰信号。</p><h3 id="_3-1-噪声抑制滤波器" tabindex="-1"><a class="header-anchor" href="#_3-1-噪声抑制滤波器"><span>3.1 噪声抑制滤波器</span></a></h3><p>这个模块负责<strong>并行地生成两个备选的“干净”语音流</strong>。</p><ul><li><strong>实现方式</strong>：使用两个独立的<strong>多通道维纳滤波器</strong>。 <ul><li><strong>MWF-L</strong>: 旨在增强来自<strong>左侧</strong>的说话人，并抑制右侧说话人和噪声。</li><li><strong>MWF-R</strong>: 旨在增强来自<strong>右侧</strong>的说话人，并抑制左侧说话人和噪声。</li></ul></li><li><strong>关键点</strong>：在此阶段，系统<strong>并不知道</strong>用户正在关注哪一侧。它只是“尽职”地准备好两个可能的选择，等待最终的指令。这对应于流程图中的模块 <strong>(a)</strong>。</li></ul><p><strong>公式详解：</strong></p><p>我们的目标是估计参考麦克风（<code>m=1</code>）处目标语音信号 <code>x₁(λ,k)</code>。公式(6)给出了线性估计的方法，现在的问题就是：<strong>这个滤波器 <code>w(λ,k)</code> 应该怎么选，才是最好的？</strong></p><p><strong>理论基础：最小均方误差准则</strong></p><p>论文指出，MWF源于一个<strong>最小均方误差（MMSE）</strong> 的线性估计过程。这是一个非常经典和直观的优化准则。</p><p><strong>思想</strong>：寻找一个滤波器 <code>w(λ,k)</code>，使得滤波器输出的估计值 <code>x̂(λ,k)</code> 与<strong>我们想要的真实值</strong> <code>x₁(λ,k)</code> 之间的<strong>均方误差</strong> 最小。</p><p>用数学公式表达这个优化问题，就是<strong>公式(7)</strong>：</p><figure><img src="/assets/image-20251127035121019-KqAbZPil.png" alt="公式7" tabindex="0" loading="lazy"><figcaption>公式7</figcaption></figure><ul><li><strong><code>E[·]</code></strong>: 表示求期望值（或平均值），这里是在计算时间上的平均。</li><li><strong><code>| · |²</code></strong>: 表示取模的平方，用于衡量误差的大小。</li><li><strong><code>x₁ - w^H y</code></strong>: 就是估计误差（真实值 - 估计值）。</li></ul><p><strong>通俗地说</strong>：这个公式命令计算机去找到一组最佳的权重 <code>w</code>，让估计出来的语音 <code>x̂</code> 和真实的干净语音 <code>x₁</code> 之间差距的平均平方值达到最小。</p><p>（其他的交给deepseek简单讲解吧）😭</p><p>好的，我们把 <strong>3.1、3.2 和 3.3</strong> 节放在一起，用一个完整且统一的比喻来讲解，让您彻底理解这三个核心模块是如何协同工作的。</p><p>想象一个 <strong>“智能秘书”</strong> 在嘈杂的会议室里帮你只听清你想听的那个人说话。这个系统的工作方式如下：</p><hr><p>🎯 <strong>3.1 噪声抑制滤波器：两位专业的“速记员”</strong></p><ul><li><p><strong>【他们的职责】</strong><br> 这两位速记员，一位专门负责记录<strong>左边</strong>的发言人（MWF-L），另一位专门负责记录<strong>右边</strong>的发言人（MWF-R）。他们的任务是<strong>实时地、并行地</strong>尽可能清晰地记录下各自负责的目标的讲话，并过滤掉对方的声音和房间里的其他杂音。</p></li><li><p><strong>【他们如何工作】</strong><br> 他们使用的工具是一个复杂的“公式”（<strong>多通道维纳滤波器 MWF</strong>）。这个公式能教他们如何综合所有麦克风的信息，像调整一堆旋钮一样，<strong>放大目标方向的声音，抵消干扰方向的声音</strong>。</p><ul><li><strong>核心公式</strong>：<code>x̂ = w^H * y</code></li><li><strong>通俗解释</strong>：<code>w</code> 是这套“旋钮”的最佳设置方案。它是由 <code>Φ_xx</code>（目标语音的特征）和 <code>Φ_rr</code>（噪声的特征）计算出来的。速记员的工作就是根据这些特征，应用这个最佳方案，产出初步净化的记录稿。</li></ul></li><li><p><strong>【小结】</strong><br> 这两位速记员非常专业，但他们有个<strong>局限</strong>：他们只管记录自己负责的目标，<strong>并不知道你此刻真正想听的是左边这位还是右边这位</strong>。所以他们俩都在不停地工作，产出两份记录稿。</p></li></ul><hr><h3 id="_3-2-🔬-相干矩阵估计器-资深的-人物特征分析师" tabindex="-1"><a class="header-anchor" href="#_3-2-🔬-相干矩阵估计器-资深的-人物特征分析师"><span>3.2 🔬 <strong>相干矩阵估计器：资深的“人物特征分析师”</strong></span></a></h3><ul><li><p><strong>【他的职责】</strong><br> 这位分析师不直接参与记录，他的任务是<strong>为上面的两位速记员提供“人物档案”</strong>。他需要分析出：</p><ol><li><strong>目标人物的声学特征</strong>（<code>Φ_xx</code>）：左边的人声音有什么特点？右边的人声音有什么特点？</li><li><strong>干扰与噪声的特征</strong>（<code>Φ_rr</code>）：房间里的空调声、另一个人的声音，有什么特点？</li></ol></li><li><p><strong>【他如何工作】（三步法）</strong></p><ol><li><strong>定向收音</strong>：他使用两个<strong>定向麦克风</strong>（<strong>固定波束成形器</strong>），一个主要收左边的音，一个主要收右边的音。</li><li><strong>判断状态</strong>：他雇了两个<strong>助理</strong>（<strong>语音活动检测器 VAD</strong>），分别监听这两个定向麦克风。左边的助理会在左边的人说话时举手，右边的同理。</li><li><strong>建立档案</strong>： <ul><li>当<strong>左边助理</strong>举手时，分析师就知道：此刻左边定向麦克风里主要是<strong>目标语音（左边）</strong>，右边定向麦克风里主要是<strong>干扰噪声（右边+环境）</strong>。他立刻用此时的信号更新左边速记员（MWF-L）需要的“人物档案”。</li><li>当<strong>右边助理</strong>举手时，他就为右边速记员（MWF-R）更新档案。</li></ul></li></ol></li><li><p><strong>【小结】</strong><br> 这位分析师通过“定向监听”和“状态判断”，间接地获取了纯净的目标和干扰特征，让两位速记员手中的“旋钮方案”(<code>w</code>)始终保持最佳状态。<strong>本文假设这位分析师和他的助理是“理想的”，永不犯错</strong>，以便集中考察最关键的部分。</p></li></ul><hr><h3 id="_3-3-🧠-听觉注意力解码器-洞察你内心的-决策主管" tabindex="-1"><a class="header-anchor" href="#_3-3-🧠-听觉注意力解码器-洞察你内心的-决策主管"><span>3.3 🧠 <strong>听觉注意力解码器：洞察你内心的“决策主管”</strong></span></a></h3><ul><li><p><strong>【他的职责】</strong><br> 这位主管是最终的<strong>决策者</strong>。他的任务非常简单：<strong>看你一眼，就知道你此刻心里想听左边还是右边的人说话</strong>。然后，他命令系统将对应速记员的记录稿递给你。</p></li><li><p><strong>【他如何工作】</strong></p><ul><li>他通过一个特殊的“读心术头盔”（<strong>EEG设备</strong>）来实时感知你的大脑活动。</li><li>他不是一个冲动的人，他需要<strong>观察你一小段时间</strong>（比如<strong>1秒钟</strong>），收集足够的脑电数据，才会做出一个稳妥的决定（<strong>决策窗口</strong>）。</li><li>他使用一个训练好的“直觉模型”（<strong>CNN神经网络</strong>）来分析这些脑电数据，最终输出指令：<strong>“左”</strong> 或 <strong>“右”</strong>。</li></ul></li><li><p><strong>【核心挑战与权衡】</strong></p><ul><li>如果他观察你的时间太短（<strong>决策窗口短</strong>，如0.5秒），他很容易<strong>判断失误</strong>（准确率低），可能会把错误的记录稿递给你。</li><li>如果他观察你的时间太长（<strong>决策窗口长</strong>，如4秒），他的决策虽然很准，但<strong>反应太慢</strong>（延迟高），等你拿到记录稿时，话题可能已经过去了。</li><li><strong>因此，他的“反应速度”和“判断准确率”之间的权衡，是本文研究的绝对核心。</strong></li></ul></li></ul><hr><h3 id="_3-4-💎-整体协作流程总结" tabindex="-1"><a class="header-anchor" href="#_3-4-💎-整体协作流程总结"><span>3.4 💎 整体协作流程总结</span></a></h3><p>现在，我们把这三个角色串联起来，看看这个“智能秘书系统”是如何工作的：</p><ol><li><p><strong>并行准备</strong>：</p><ul><li><strong>人物特征分析师（3.2）</strong> 不断为<strong>两位速记员（3.1）</strong> 提供最新的“人物档案”。</li><li>两位速记员根据档案，并行地、高质量地记录着各自目标的讲话，产出两份初步净化的记录稿。</li></ul></li><li><p><strong>最终决策</strong>：</p><ul><li><strong>决策主管（3.3）</strong> 通过“读心术”判断出你当前想听谁。</li><li>他发出一个简单的切换指令。</li></ul></li><li><p><strong>交付结果</strong>：</p><ul><li>系统根据指令，选择对应速记员的记录稿，作为最终的语音输出给你听。</li></ul></li></ol><p><strong>总而言之，3.1是干活的，3.2是给干活的人提供技术支持的，3.3是做最终决定的。论文的目的，就是研究这个“做最终决定”的决策主管（3.3），他的反应速度（决策窗口）和业务能力（准确率）要达到什么水平，才能保证你最终听到的东西（语音质量和可懂度）是满意的。</strong></p><h3 id="_3-5-问题" tabindex="-1"><a class="header-anchor" href="#_3-5-问题"><span>3.5 问题</span></a></h3><h4 id="q2-噪声抑制滤波器和相干矩阵估计器的区别" tabindex="-1"><a class="header-anchor" href="#q2-噪声抑制滤波器和相干矩阵估计器的区别"><span>Q2：噪声抑制滤波器和相干矩阵估计器的区别</span></a></h4><p>🎨 核心比喻：<strong>厨师 vs. 食材处理员</strong></p><p>想象一个高级餐厅的厨房，要为客人准备两道主菜（左声道和右声道）。</p><hr><p>👨‍🍳 <strong>3.1 噪声抑制滤波器 - 主厨</strong></p><ul><li><strong>角色</strong>：<strong>两位主厨</strong><ul><li><strong>主厨-左</strong>：专门烹饪左声道这道菜。</li><li><strong>主厨-右</strong>：专门烹饪右声道这道菜。</li></ul></li><li><strong>职责</strong>：<strong>负责“烹饪”出最终端给客人的菜肴</strong>。他们拿到处理好的食材，运用他们高超的厨艺（<strong>MWF算法</strong>），做出一道美味、干净、没有异味的菜。</li><li><strong>工作内容</strong>：他们遵循一个固定的、最优的食谱（<strong>公式 w^opt = Φ_yy⁻¹ Φ_xx q</strong>）。这个食谱告诉他们如何精确地调配各种原料（麦克风信号），才能最好地突出主料（目标语音），掩盖或去除不好的味道（噪声和干扰）。</li><li><strong>关键</strong>：他们是<strong>最终产品的产出者</strong>。系统最终的语音质量（PESQ）和可懂度（STOI）直接由他们的“厨艺”决定。</li></ul><hr><p>🥬 <strong>3.2 相干矩阵估计器 - 食材处理员</strong></p><ul><li><strong>角色</strong>：<strong>一位资深的食材处理员</strong></li><li><strong>职责</strong>：<strong>负责为主厨准备最核心的、处理好的食材</strong>，而不是直接做菜。他的任务是： <ol><li>分辨出什么是“上等主肉”（纯净的 <strong><code>Φ_xx</code></strong> - 目标语音的统计特征）。</li><li>分辨出什么是“需要剔除的筋膜和边角料”（纯净的 <strong><code>Φ_rr</code></strong> - 噪声和干扰的统计特征）。</li></ol></li><li><strong>工作内容</strong>： <ul><li>他使用特殊的工具（<strong>固定波束成形器</strong>）来对混合在一起的原始食材进行<strong>粗分离</strong>。</li><li>他依靠经验（<strong>语音活动检测器 VAD</strong>）来判断什么时候拿到的是纯主肉，什么时候拿到的是纯边角料。</li><li>他将这些分析好的、代表食材特征的“样品”（<code>Φ_xx</code> 和 <code>Φ_rr</code>）交给两位主厨。</li></ul></li><li><strong>关键</strong>：他是<strong>服务和支持者</strong>。他工作的<strong>准确性</strong>直接决定了主厨拿到的食谱（公式里的 <code>Φ_xx</code> 和 <code>Φ_rr</code>）是否靠谱，进而影响菜肴的最终品质。<strong>如果他提供的食材特征有误，主厨厨艺再高也做不出好菜。</strong></li></ul><hr><p>💡 总结与类比</p><table><thead><tr><th style="text-align:left;">特性</th><th style="text-align:left;"><strong>3.1 噪声抑制滤波器 (主厨)</strong></th><th style="text-align:left;"><strong>3.2 相干矩阵估计器 (食材处理员)</strong></th></tr></thead><tbody><tr><td style="text-align:left;"><strong>核心任务</strong></td><td style="text-align:left;"><strong>产出</strong>最终增强后的语音信号。</td><td style="text-align:left;"><strong>估计和提供</strong>计算所需的<strong>统计特征</strong>（协方差矩阵）。</td></tr><tr><td style="text-align:left;"><strong>在公式中的位置</strong></td><td style="text-align:left;">执行公式 <strong><code>x̂ = w^H y</code></strong>，是<strong>最终输出</strong>。</td><td style="text-align:left;">计算公式 <strong><code>w^opt = Φ_yy⁻¹ Φ_xx q</code></strong> 中的 <strong><code>Φ_xx</code> 和 <code>Φ_rr</code></strong>，是<strong>中间输入</strong>。</td></tr><tr><td style="text-align:left;"><strong>依赖关系</strong></td><td style="text-align:left;">依赖于3.2提供的准确统计信息。</td><td style="text-align:left;">依赖于原始的麦克风信号和VAD/波束成形的性能。</td></tr><tr><td style="text-align:left;"><strong>比喻</strong></td><td style="text-align:left;"><strong>烹饪</strong></td><td style="text-align:left;"><strong>准备食材</strong></td></tr></tbody></table><p><strong>所以，它们的根本区别是：</strong></p><ul><li><strong>3.2 是“信息提供者”</strong>，它回答“<strong>是什么？</strong>”（What is the target? What is the noise?）</li><li><strong>3.1 是“命令执行者”</strong>，它回答“<strong>怎么做？</strong>”（How to extract the target and suppress the noise?）</li></ul><p>在本文的实验中，作者假设 <strong>“食材处理员”是完美的</strong>（理想波束成形和VAD），这样就能确保如果最终“菜肴”不好吃，那问题一定不是出在食材上，而很可能是出在<strong>决定上哪道菜的“大堂经理”（3.3 AAD）</strong> 身上，或者“主厨”的算法本身。这就隔离了变量，让作者能专注于研究AAD的性能影响。</p></div><!----><!--[--><h2 id="doc-changelog" tabindex="-1"><a href="#doc-changelog" class="header-anchor"><span>更新日志</span></a></h2><div class="vp-changelog-wrapper"><div class="vp-changelog-header"><div class="vp-latest-updated"><span class="vp-changelog-icon"></span><span data-allow-mismatch>2025/12/1 05:51</span></div><div><span class="vp-changelog-menu-icon"></span><span>查看所有更新日志</span></div></div><ul class="vp-changelog-list"><!--[--><li class="vp-changelog-item-commit"><span class="vp-changelog-hash" target="_blank" rel="noreferrer"><code>3f796</code></span><span class="vp-changelog-divider">-</span><span class="vp-changelog-message">fix: Enhance clarity in the abstract and introduction sections of the literature review on auditory attention decoding for hearing aids</span><span class="vp-changelog-date" data-allow-mismatch>于 <time datetime="2025-12-01T05:51:57.000Z">2025/12/1</time></span></li><li class="vp-changelog-item-commit"><span class="vp-changelog-hash" target="_blank" rel="noreferrer"><code>6ab22</code></span><span class="vp-changelog-divider">-</span><span class="vp-changelog-message">Add literature review on the impact of auditory attention decoding accuracy on noise reduction systems for hearing aids</span><span class="vp-changelog-date" data-allow-mismatch>于 <time datetime="2025-11-27T07:44:33.000Z">2025/11/27</time></span></li><!--]--></ul></div><!--]--><!----></div><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/AmaraMeng/AmaraMeng.github.io/edit/main/src/reading/literature/02-Impact-of-auditory-attention-decoding-accuracy-on-noise-reduction-systems-for-hearing-aids.md" aria-label="在 GitHub 上编辑此页" rel="noopener noreferrer" target="_blank"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->在 GitHub 上编辑此页<!----></a></div><div class="vp-meta-item git-info"><!----><div class="contributors"><span class="vp-meta-label">贡献者: </span><!--[--><!--[--><span class="vp-meta-info" title="email: ranmeng9558@gmail.com">AmaraMeng</span><!--]--><!--]--></div></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/reading/literature/01-EEG-based-detection-of-the-locus-of-auditory-attention-with-convolutional-neural-networks.html" aria-label="01. 基于EEG的卷积神经网络听觉注意力定位检测"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><i class="vp-icon iconfont icon-boke" sizing="height"></i>01. 基于EEG的卷积神经网络听觉注意力定位检测</div></a><!----></nav><div id="comment" class="waline-wrapper vp-comment" vp-comment darkmode="false" style="display:block;"><!----></div><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><div class="vp-footer">默认页脚</div><div class="vp-copyright">Copyright © 2025 Ran </div></footer></div><!--]--><!--[--><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script type="module" src="/assets/app-dXkzPG9u.js" defer></script>
  </body>
</html>
