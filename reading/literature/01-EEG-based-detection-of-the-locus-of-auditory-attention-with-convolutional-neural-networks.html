<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.24" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.95" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"01. åŸºäºEEGçš„å·ç§¯ç¥ç»ç½‘ç»œå¬è§‰æ³¨æ„åŠ›å®šä½æ£€æµ‹","image":[""],"datePublished":"2025-11-23T11:39:12.000Z","dateModified":"2025-11-23T09:30:36.000Z","author":[{"@type":"Person","name":"Ran"}]}</script><meta property="og:url" content="https://pythiaroot.com/reading/literature/01-EEG-based-detection-of-the-locus-of-auditory-attention-with-convolutional-neural-networks.html"><meta property="og:site_name" content="Pythiaâ€™s Root"><meta property="og:title" content="01. åŸºäºEEGçš„å·ç§¯ç¥ç»ç½‘ç»œå¬è§‰æ³¨æ„åŠ›å®šä½æ£€æµ‹"><meta property="og:description" content="EEG-based detection of the locus of auditory attention with convolutional neural networks é¢˜ç›®åŠä½œè€…é¢˜ç›®åŠä½œè€… æ‘˜è¦ In a multi-speaker scenario, the human auditory system is able to attend ..."><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2025-11-23T09:30:36.000Z"><meta property="article:author" content="Ran"><meta property="article:published_time" content="2025-11-23T11:39:12.000Z"><meta property="article:modified_time" content="2025-11-23T09:30:36.000Z"><link rel="icon" href="/logo.jpg"><title>01. åŸºäºEEGçš„å·ç§¯ç¥ç»ç½‘ç»œå¬è§‰æ³¨æ„åŠ›å®šä½æ£€æµ‹ | Pythiaâ€™s Root</title><meta name="description" content="EEG-based detection of the locus of auditory attention with convolutional neural networks é¢˜ç›®åŠä½œè€…é¢˜ç›®åŠä½œè€… æ‘˜è¦ In a multi-speaker scenario, the human auditory system is able to attend ...">
    <link rel="preload" href="/assets/style-fescsFu7.css" as="style"><link rel="stylesheet" href="/assets/style-fescsFu7.css">
    <link rel="modulepreload" href="/assets/app-C6BM0Klo.js"><link rel="modulepreload" href="/assets/01-EEG-based-detection-of-the-locus-of-auditory-attention-with-convolutional-neural-networks.html-BvTtIyps.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/assets/index.html-BbMWfEXj.js" as="script"><link rel="prefetch" href="/assets/intro.html-CPaVoYAZ.js" as="script"><link rel="prefetch" href="/assets/Cao-jing-JYM.html-C4gf5TO_.js" as="script"><link rel="prefetch" href="/assets/01-Ch1.html-Chx3eF_b.js" as="script"><link rel="prefetch" href="/assets/01-basic-math-knowledge.html-Dzn0TxO6.js" as="script"><link rel="prefetch" href="/assets/00-python-tips.html-Br-BUlZj.js" as="script"><link rel="prefetch" href="/assets/01-variable.html-CqSXeZFO.js" as="script"><link rel="prefetch" href="/assets/02-data-type.html-CXZjv1K6.js" as="script"><link rel="prefetch" href="/assets/02-test-variable-datatype.html-eFD-V2HD.js" as="script"><link rel="prefetch" href="/assets/03-numeric-type.html-DfGFntd4.js" as="script"><link rel="prefetch" href="/assets/04-string.html-C6Dq_IPj.js" as="script"><link rel="prefetch" href="/assets/05-list.html-B_EbItoU.js" as="script"><link rel="prefetch" href="/assets/06-tuple.html-0HcO5ZEG.js" as="script"><link rel="prefetch" href="/assets/07-dict.html-DGj-R70l.js" as="script"><link rel="prefetch" href="/assets/08-set.html-BZz07ZU_.js" as="script"><link rel="prefetch" href="/assets/09-bool.html-DieJAdlq.js" as="script"><link rel="prefetch" href="/assets/10-if.html-6ahlbVlv.js" as="script"><link rel="prefetch" href="/assets/11-while.html-QW52uccy.js" as="script"><link rel="prefetch" href="/assets/12-for.html-X4q0MVKy.js" as="script"><link rel="prefetch" href="/assets/13-functions.html-D9430UE-.js" as="script"><link rel="prefetch" href="/assets/14-class.html-zEAbgyn1.js" as="script"><link rel="prefetch" href="/assets/15-environment.html-CO4pW-_v.js" as="script"><link rel="prefetch" href="/assets/16-python3-errors-and-exceptions.html-aILq814x.js" as="script"><link rel="prefetch" href="/assets/17-TBSgame.html-Byf7fLIT.js" as="script"><link rel="prefetch" href="/assets/18-local-LLM.html-BQTh6JP2.js" as="script"><link rel="prefetch" href="/assets/19-python-install.html-DljZPU_U.js" as="script"><link rel="prefetch" href="/assets/20-anaconda-install.html-Dn7-iZ_k.js" as="script"><link rel="prefetch" href="/assets/Markdown-formula.html-Dqy1jQM5.js" as="script"><link rel="prefetch" href="/assets/Static-website-building.html-BFtSsAWg.js" as="script"><link rel="prefetch" href="/assets/article-typora.html-B4z2TGXV.js" as="script"><link rel="prefetch" href="/assets/01-LOVEintheTIMEofCHOLERA.html-CTf50Ptp.js" as="script"><link rel="prefetch" href="/assets/02-Tuesdays-with-Morrie.html-Cqt-jjf0.js" as="script"><link rel="prefetch" href="/assets/01-human-DK10000.html-CEnLlizt.js" as="script"><link rel="prefetch" href="/assets/404.html-C5OqlwMW.js" as="script"><link rel="prefetch" href="/assets/index.html-SROe-SDS.js" as="script"><link rel="prefetch" href="/assets/index.html-Bs8EQ_hh.js" as="script"><link rel="prefetch" href="/assets/index.html-B9TXQvMJ.js" as="script"><link rel="prefetch" href="/assets/index.html-D1a4h-d5.js" as="script"><link rel="prefetch" href="/assets/index.html-Chd17YUV.js" as="script"><link rel="prefetch" href="/assets/index.html-DGo7ZB54.js" as="script"><link rel="prefetch" href="/assets/index.html-CrYryf29.js" as="script"><link rel="prefetch" href="/assets/index.html-DT5emqIc.js" as="script"><link rel="prefetch" href="/assets/index.html-DBpjdgUL.js" as="script"><link rel="prefetch" href="/assets/index.html-yFxYhk1-.js" as="script"><link rel="prefetch" href="/assets/index.html-DOZzc64x.js" as="script"><link rel="prefetch" href="/assets/index.html-CaDlKxRW.js" as="script"><link rel="prefetch" href="/assets/index.html-Ci3WRrLA.js" as="script"><link rel="prefetch" href="/assets/index.html-Clmvs3TE.js" as="script"><link rel="prefetch" href="/assets/index.html-yKjfu9co.js" as="script"><link rel="prefetch" href="/assets/index.html-mAoafZke.js" as="script"><link rel="prefetch" href="/assets/index.html-CoPBQSr0.js" as="script"><link rel="prefetch" href="/assets/index.html-B4ey8AZ5.js" as="script"><link rel="prefetch" href="/assets/index.html-DSFCAej6.js" as="script"><link rel="prefetch" href="/assets/index.html-COMwr7ki.js" as="script"><link rel="prefetch" href="/assets/index.html-DHsLuA2E.js" as="script"><link rel="prefetch" href="/assets/index.html-TMf2XsXz.js" as="script"><link rel="prefetch" href="/assets/index.html-ua591ROT.js" as="script"><link rel="prefetch" href="/assets/index.html-ClEGG8yx.js" as="script"><link rel="prefetch" href="/assets/mermaid.esm.min-Dte05QPn.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-CKV1Bsxh.js" as="script"><link rel="prefetch" href="/assets/waline-meta-l0sNRNKZ.js" as="script"><link rel="prefetch" href="/assets/component-tOvfgh5e.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">è·³è‡³ä¸»è¦å…§å®¹</a><!--]--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><a class="route-link vp-brand" href="/" aria-label="å¸¦æˆ‘å›å®¶"><img class="vp-nav-logo" src="/é˜¿å°”æ³• logo.jpg" alt><!----><span class="vp-site-name hide-in-pad">Pythiaâ€™s Root</span></a><!--]--></div><div class="vp-navbar-center"><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/" aria-label="Pythiaâ€™s Root"><!--[--><i class="vp-icon iconfont icon-house" sizing="height"></i><!--]-->Pythiaâ€™s Root<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="ç¼–ç¨‹"><!--[--><i class="vp-icon iconfont icon-biancheng-01" sizing="height"></i>ç¼–ç¨‹<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/programming/static-website-blog/" aria-label="Static website building-blog"><!--[--><i class="vp-icon iconfont icon-boke" sizing="both"></i><!--]-->Static website building-blog<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/programming/python/" aria-label="Python"><!--[--><i class="vp-icon iconfont icon-python" sizing="both"></i><!--]-->Python<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/programming/ThinkDSP/" aria-label="ThinkDSP"><!--[--><i class="vp-icon iconfont icon-python" sizing="both"></i><!--]-->ThinkDSP<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/programming/math-for-ai/" aria-label="Math for AI"><!--[--><i class="vp-icon iconfont icon-python" sizing="both"></i><!--]-->Math for AI<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/#" aria-label="äººå·¥è€³èœ—"><!--[--><i class="vp-icon iconfont icon-rengongerwoshenqing" sizing="height"></i><!--]-->äººå·¥è€³èœ—<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/#" aria-label="è¯­éŸ³å­¦"><!--[--><i class="vp-icon iconfont icon-shengboyuyinxiaoxi" sizing="height"></i><!--]-->è¯­éŸ³å­¦<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="ç¿»è¯‘"><!--[--><i class="vp-icon iconfont icon-fanyi" sizing="height"></i>ç¿»è¯‘<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/translation/vocabulary/" aria-label="è¯æ±‡"><!--[--><i class="vp-icon iconfont icon-cihuiben" sizing="both"></i><!--]-->è¯æ±‡<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/translation/peki/" aria-label="Peki"><!--[--><i class="vp-icon iconfont icon-fanyi" sizing="both"></i><!--]-->Peki<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/sports/" aria-label="è¿åŠ¨"><!--[--><i class="vp-icon iconfont icon-jianshenfang" sizing="height"></i><!--]-->è¿åŠ¨<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="é˜…è¯»"><!--[--><i class="vp-icon iconfont icon-yuedu" sizing="height"></i>é˜…è¯»<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link route-link-active auto-link" href="/reading/literature/" aria-label="æ–‡çŒ®"><!--[--><i class="vp-icon iconfont icon-yuedu" sizing="both"></i><!--]-->æ–‡çŒ®<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/reading/books/" aria-label="ä¹¦ç±"><!--[--><i class="vp-icon iconfont icon-yuedu" sizing="both"></i><!--]-->ä¹¦ç±<!----></a></li></ul></button></div></div></nav><!--]--></div><div class="vp-navbar-end"><!--[--><!----><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/AmaraMeng/AmaraMeng.github.io" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><form class="search-box" role="search"><input type="search" placeholder="æœç´¢" autocomplete="off" spellcheck="false" value><!----></form><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/" aria-label="Pythiaâ€™s Root"><!--[--><i class="vp-icon iconfont icon-house" sizing="both"></i><!--]-->Pythiaâ€™s Root<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Programming</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">Reading</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Books</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">Literature</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/reading/literature/01-EEG-based-detection-of-the-locus-of-auditory-attention-with-convolutional-neural-networks.html" aria-label="01. åŸºäºEEGçš„å·ç§¯ç¥ç»ç½‘ç»œå¬è§‰æ³¨æ„åŠ›å®šä½æ£€æµ‹"><!--[--><i class="vp-icon iconfont icon-boke" sizing="both"></i><!--]-->01. åŸºäºEEGçš„å·ç§¯ç¥ç»ç½‘ç»œå¬è§‰æ³¨æ„åŠ›å®šä½æ£€æµ‹<!----></a></li></ul></section></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Sports</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Translation</span><span class="vp-arrow end"></span></button><!----></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/intro.html" aria-label="ä»‹ç»é¡µ"><!--[--><i class="vp-icon iconfont icon-circle-info" sizing="both"></i><!--]-->ä»‹ç»é¡µ<!----></a></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><i class="vp-icon iconfont icon-boke" sizing="height"></i>01. åŸºäºEEGçš„å·ç§¯ç¥ç»ç½‘ç»œå¬è§‰æ³¨æ„åŠ›å®šä½æ£€æµ‹</h1><div class="page-info"><span class="page-author-info" aria-label="ä½œè€…ğŸ–Š" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">Ran</span></span><span property="author" content="Ran"></span></span><span class="page-original-info">åŸåˆ›</span><span class="page-date-info" aria-label="å†™ä½œæ—¥æœŸğŸ“…" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">2025/11/23</span><meta property="datePublished" content="2025-11-23T11:39:12.000Z"></span><span class="page-pageview-info" aria-label="è®¿é—®é‡ğŸ”¢" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon eye-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="eye icon" name="eye"><path d="M992 512.096c0-5.76-.992-10.592-1.28-11.136-.192-2.88-1.152-8.064-2.08-10.816-.256-.672-.544-1.376-.832-2.08-.48-1.568-1.024-3.104-1.6-4.32C897.664 290.112 707.104 160 512 160c-195.072 0-385.632 130.016-473.76 322.592-1.056 2.112-1.792 4.096-2.272 5.856a55.512 55.512 0 00-.64 1.6c-1.76 5.088-1.792 8.64-1.632 7.744-.832 3.744-1.568 11.168-1.568 11.168-.224 2.272-.224 4.032.032 6.304 0 0 .736 6.464 1.088 7.808.128 1.824.576 4.512 1.12 6.976h-.032c.448 2.08 1.12 4.096 1.984 6.08.48 1.536.992 2.976 1.472 4.032C126.432 733.856 316.992 864 512 864c195.136 0 385.696-130.048 473.216-321.696 1.376-2.496 2.24-4.832 2.848-6.912.256-.608.48-1.184.672-1.728 1.536-4.48 1.856-8.32 1.728-8.32l-.032.032c.608-3.104 1.568-7.744 1.568-13.28zM512 672c-88.224 0-160-71.776-160-160s71.776-160 160-160 160 71.776 160 160-71.776 160-160 160z"></path></svg><span id="ArtalkPV" class="vp-pageview waline-pageview-count" data-path="/reading/literature/01-EEG-based-detection-of-the-locus-of-auditory-attention-with-convolutional-neural-networks.html" data-page-key="/reading/literature/01-EEG-based-detection-of-the-locus-of-auditory-attention-with-convolutional-neural-networks.html">...</span></span><span class="page-reading-time-info" aria-label="é˜…è¯»æ—¶é—´âŒ›" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>å¤§çº¦ 5 åˆ†é’Ÿ</span><meta property="timeRequired" content="PT5M"></span><span class="page-category-info" aria-label="åˆ†ç±»ğŸŒˆ" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item color2 clickable" role="navigation">reading</span><span class="page-category-item color8 clickable" role="navigation">literature</span><!--]--><meta property="articleSection" content="reading,literature"></span><!----></div><hr></div><!----><div class="" vp-content><!----><div id="markdown-content"><p><strong>EEG-based detection of the locus of auditory attention with convolutional neural networks</strong></p><figure><img src="/assets/image-20251123114219611-D89kLo7f.png" alt="é¢˜ç›®åŠä½œè€…" tabindex="0" loading="lazy"><figcaption>é¢˜ç›®åŠä½œè€…</figcaption></figure><h2 id="æ‘˜è¦" tabindex="-1"><a class="header-anchor" href="#æ‘˜è¦"><span>æ‘˜è¦</span></a></h2><p>In a multi-speaker scenario, the human auditory system is able to attend to one particular speaker of interest and ignore the others. It has been demonstrated that it is possible to use electroencephalography (EEG) signals to infer to which speaker someone is attending by relating the neural activity to the speech signals. However, classifying auditory attention within a short time interval remains the main challenge. We present a convolutional neural network-based approach to extract the locus of auditory attention (left/right) without knowledge of the speech envelopes. Our results show that it is possible to decode the locus of attention within 1â€“2 s, with a median accuracy of around 81%. These results are promising for neuro-steered noise suppression in hearing aids, in particular in scenarios where per-speaker envelopes are unavailable.</p><p>åœ¨å¤šè¯´è¯è€…åœºæ™¯ä¸­ï¼Œäººç±»çš„å¬è§‰ç³»ç»Ÿèƒ½å¤Ÿä¸“æ³¨äºæŸä¸ªæ„Ÿå…´è¶£çš„ç‰¹å®šè¯´è¯è€…å¹¶å¿½ç•¥å…¶ä»–äººã€‚ç ”ç©¶è¡¨æ˜ï¼Œé€šè¿‡å°†ç¥ç»æ´»åŠ¨ä¸è¯­éŸ³ä¿¡å·å…³è”ï¼Œå¯ä»¥åˆ©ç”¨è„‘ç”µï¼ˆEEGï¼‰ä¿¡å·æ¨æ–­å¬è€…æ­£åœ¨å…³æ³¨å“ªä½è¯´è¯è€…ã€‚ç„¶è€Œï¼Œåœ¨çŸ­æ—¶é—´éš”å†…å¯¹å¬è§‰æ³¨æ„è¿›è¡Œåˆ†ç±»ä»ç„¶æ˜¯ä¸»è¦æŒ‘æˆ˜ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºå·ç§¯ç¥ç»ç½‘ç»œçš„æ–¹æ³•ï¼Œç”¨æ¥æå–å¬è§‰æ³¨æ„çš„ä½ç½®ï¼ˆå·¦/å³ï¼‰ï¼Œä¸”æ— éœ€è¯­éŸ³åŒ…ç»œã€‚ç»“æœæ˜¾ç¤ºï¼Œåœ¨1â€“2ç§’å†…è§£ç æ³¨æ„ä½ç½®æ˜¯å¯è¡Œçš„ï¼Œå‡†ç¡®ç‡çº¦ä¸º81%ã€‚è¿™äº›ç»“æœåœ¨åŠ©å¬è®¾å¤‡ä¸­ç¥ç»å¼•å¯¼å™ªå£°æŠ‘åˆ¶æ–¹é¢å…·æœ‰å‰æ™¯ï¼Œå°¤å…¶æ˜¯åœ¨æ— æ³•è·å–æ¯ä½è¯´è¯è€…è¯­éŸ³åŒ…ç»œçš„æƒ…å†µä¸‹ã€‚</p><h2 id="_1-introduction" tabindex="-1"><a class="header-anchor" href="#_1-introduction"><span>1. Introduction</span></a></h2><ul><li><p><strong>ç°è±¡ï¼š</strong></p><p>cocktail party problem é¸¡å°¾é…’ä¼šé—®é¢˜ ï¼ˆCherry EC. 1953. Some experiments on the recognition of speech, with one and with two ears. The Journal of the Acoustical Society of America 25:975â€“979. DOI: <a href="https://doi.org/10.1121/1.1907229%EF%BC%89" target="_blank" rel="noopener noreferrer">https://doi.org/10.1121/1.1907229ï¼‰</a></p></li><li><p><strong>æ¶‰åŠäººç¾¤ï¼š</strong></p><p>å¬åŠ›æŸå¤±äººç¾¤å’Œè€å¹´äººæ›´éš¾åˆ†è¾¨ã€‚</p></li><li><p><strong>é—®é¢˜ï¼š</strong></p><p>åŠ©å¬è®¾å¤‡ç°æœ‰çš„ç­–ç•¥æ˜¯æ ¹æ®è¯´è¯äººéŸ³é‡æˆ–è€…å¬è€…é¢å¯¹çš„æ–¹å‘ï¼Œåº”ç”¨æ•ˆæœä¸ä½³ã€‚</p></li><li><p><strong>è§£å†³æ–¹æ³•ï¼š</strong></p><p>auditory attention decoding (AAD) å¬è§‰æ³¨æ„åŠ›è§£ç ï¼šç¥ç»æ´»åŠ¨ â†’è§£ç  å¬è§‰æ³¨æ„</p></li></ul><h3 id="_1-1-çº¿æ€§è§£ç -vs-éçº¿æ€§è§£ç é—®é¢˜" tabindex="-1"><a class="header-anchor" href="#_1-1-çº¿æ€§è§£ç -vs-éçº¿æ€§è§£ç é—®é¢˜"><span>1.1 çº¿æ€§è§£ç  VS éçº¿æ€§è§£ç é—®é¢˜</span></a></h3><p><strong>çº¿æ€§è§£ç </strong></p><ul><li><p><strong>å¸¸è§æ–¹æ³•ï¼š</strong></p><p>step 1: åˆºæ¿€é‡å»ºï¼ˆç”¨å¤§è„‘æ´»åŠ¨è§£ç å¹¶é‡å»ºåˆºæ¿€è¯­éŸ³çš„åŒ…ç»œï¼‰;</p><p>step 2ï¼šç›¸å…³æ€§åˆ†æï¼ˆå°†é‡å»ºçš„åŒ…ç»œä¸åŸå§‹åˆºæ¿€åŒ…ç»œè¿›è¡Œç›¸å…³åˆ†æï¼Œç›¸å…³æ€§æœ€é«˜çš„é‚£ä¸ªåŒ…ç»œå±äºæ‰€å…³æ³¨çš„è¯´è¯è€…ã€‚ï¼‰</p><p>(Oâ€™Sullivan JA, Power AJ, Mesgarani N, Rajaram S, Foxe JJ, Shinn-Cunningham BG, Slaney M, Shamma SA, Lalor EC. 2015. Attentional selection in a cocktail party environment can be decoded from Single-Trial EEG. Cerebral Cortex 25:1697â€“1706. DOI: <a href="https://doi.org/10.1093/cercor/bht355" target="_blank" rel="noopener noreferrer">https://doi.org/10.1093/cercor/bht355</a>, PMID: 24429136)</p><p>( Pasley BN, David SV, Mesgarani N, Flinker A, Shamma SA, Crone NE, Knight RT, Chang EF. 2012. Reconstructing speech from human auditory cortex. PLOS Biology 10:e1001251. DOI: <a href="https://doi.org/10.1371/" target="_blank" rel="noopener noreferrer">https://doi.org/10.1371/</a> journal.pbio.1001251, PMID: 22303281)</p></li><li><p><strong>å…¶ä»–æ–¹æ³•ï¼š</strong></p><p>forward modeling approach;</p><p>predicting EEG from the auditory stimulus;</p><p>( Akram S, Presacco A, Simon JZ, Shamma SA, Babadi B. 2016. Robust decoding of selective auditory attention from MEG in a competing-speaker environment via state-space modeling. NeuroImage 124:906â€“917. DOI: <a href="https://doi.org/10.1016/j.neuroimage.2015.09.048" target="_blank" rel="noopener noreferrer">https://doi.org/10.1016/j.neuroimage.2015.09.048</a>, PMID: 26436490)</p><p>(Alickovic E, Lunner T, Gustafsson F. 2016. A system identification approach to determining listening attention from EEG signals. 24th European Signal Processing Conference (EUSIPCO) 31â€“35.)</p><p>canonical correlation analysis (CCA)-based methods;</p><p>( de CheveigneÂ´ A, Wong DDE, Di Liberto GM, HjortkjÃ¦r J, Slaney M, Lalor E. 2018. Decoding the auditory brain with canonical component analysis. NeuroImage 172:206â€“216. DOI: <a href="https://doi.org/10.1016/j.neuroimage" target="_blank" rel="noopener noreferrer">https://doi.org/10.1016/j.neuroimage</a>. 2018.01.033, PMID: 29378317)</p><p>Bayesian state-space modeling.</p><p>( Miran S, Akram S, Sheikhattar A, Simon JZ, Zhang T, Babadi B. 2018. Real-Time tracking of selective auditory attention from M/EEG: a bayesian filtering approach. Frontiers in Neuroscience 12:262. DOI: <a href="https://doi.org/" target="_blank" rel="noopener noreferrer">https://doi.org/</a> 10.3389/fnins.2018.00262, PMID: 29765298)</p></li></ul><p><strong>éçº¿æ€§è§£ç </strong></p><p>äººç±»å¬è§‰ç³»ç»Ÿ<strong>éçº¿æ€§</strong>ç‰¹ç‚¹ï¼ˆ Faure P, Korn H. 2001. Is there Chaos in the brain? I. concepts of nonlinear dynamics and methods of investigation. Comptes Rendus De lâ€™AcadeÂ´mie Des Sciences- Series III- Sciences De La Vie 324:773â€“793. DOI: <a href="https://doi.org/10.1016/S0764-4469(01)01377-4%EF%BC%89" target="_blank" rel="noopener noreferrer">https://doi.org/10.1016/S0764-4469(01)01377-4ï¼‰</a></p><p>å› æ­¤é‡‡ç”¨éçº¿æ€§æ¨¡å‹ã€‚</p><ul><li><p>feedforward neural network</p><p>( Taillez T, Kollmeier B, Meyer BT. 2017. Machine learning for decoding listenersâ€™ attention from electroencephalography evoked by continuous speech. European Journal of Neuroscience 51:1234â€“1241. DOI: <a href="https://doi.org/10.1111/ejn.13790" target="_blank" rel="noopener noreferrer">https://doi.org/10.1111/ejn.13790</a>)</p></li><li><p>convolutional neural networks (CNNs) æ–¹æ³•</p><p>ä¼˜ç‚¹ï¼šåŒè¯´è¯äººåˆ†ç¦»æ•ˆæœä¼˜äºçº¿æ€§æ–¹æ³•ï¼›</p><p>ç¼ºç‚¹ï¼šé•¿åº¦10s æ—¶æ•ˆæœå¥½ï¼Œå‡†ç¡®ç‡ 75â€“85%ï¼Œä½†æ—¶é•¿ç¼©çŸ­ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚</p></li></ul><h3 id="_1-2-å†³å®šçª—æ—¶é•¿é—®é¢˜" tabindex="-1"><a class="header-anchor" href="#_1-2-å†³å®šçª—æ—¶é•¿é—®é¢˜"><span>1.2 å†³å®šçª—æ—¶é•¿é—®é¢˜</span></a></h3><p>ç”±äºæ—¶é•¿ç¼©çŸ­ä¼šå¯¼è‡´å‡†ç¡®ç‡ä¸‹é™ï¼Œé‚£ä¹ˆè¯¥å¦‚ä½•å¹³è¡¡decision window æ—¶é•¿å’Œå‡†ç¡®ç‡ï¼Ÿ</p><p>Geirnaert et al., 2020 æå‡ºäº†ä¸€ç§å°†ä¸¤ç§å±æ€§ç»“åˆæˆå•ä¸€æŒ‡æ ‡çš„æ–¹æ³•ï¼Œé€šè¿‡åœ¨å…·æœ‰ç¨³å¥æ€§çº¦æŸçš„åŸºäºAADçš„éŸ³é‡æ§åˆ¶ç³»ç»Ÿä¸­å¯»æ‰¾æœ€ä½³æƒè¡¡ç‚¹ï¼Œä»¥æœ€å°åŒ–é¢„æœŸåˆ‡æ¢æŒç»­æ—¶é—´ã€‚é€šè¿‡å¯¹æ¯æ¬¡æ–°çš„AADå†³ç­–ä½¿ç”¨è¾ƒå°çš„ç›¸å¯¹éŸ³é‡å˜åŒ–ï¼Œå¯ä»¥æé«˜å¯¹AADé”™è¯¯çš„é²æ£’æ€§ã€‚</p><p>é€‚åˆçŸ­æ—¶ä½†å‡†ç¡®ç‡ä¸­ç­‰çš„éœ€æ±‚ã€‚</p><h3 id="_1-3-ä½ç½®é—®é¢˜" tabindex="-1"><a class="header-anchor" href="#_1-3-ä½ç½®é—®é¢˜"><span>1.3 ä½ç½®é—®é¢˜</span></a></h3><p><strong>ä»»åŠ¡è½¬å‘ï¼š</strong></p><p>é‡æ„çš„è¯­éŸ³åŒ…ç»œå¯¹åº”å“ªä¸ªè¯­éŸ³åˆºæ¿€ â†’è½¬å‘ è¯­éŸ³åˆºæ¿€çš„ç©ºé—´ä½ç½®ã€‚</p><p><strong>å¥½å¤„ï¼š</strong> æ— éœ€å¹²å‡€è¯­éŸ³ã€‚</p><p><strong>åŸºç¡€ï¼š</strong></p><p>æœ€è¿‘çš„ç ”ç©¶ï¼ˆ Wolbers et al., 2011; Bednar and Lalor, 2018; Patel et al., 2018; Oâ€™Sullivan et al., 2019; Bednar and Lalor, 2020ï¼‰è¡¨æ˜ï¼Œå¬è§‰æ³¨æ„çš„æ–¹å‘åœ¨ç¥ç»ä¸Šæ˜¯ç¼–ç çš„ï¼Œè¿™è¡¨æ˜å¯èƒ½ä» EEG ä¸­è§£ç å‡ºè¢«æ³¨æ„å£°éŸ³çš„ä½ç½®æˆ–è½¨è¿¹ã€‚</p><p>ä¸€äº›ä½¿ç”¨è„‘ç£å›¾ï¼ˆMEGï¼‰çš„ç ”ç©¶è¡¨æ˜ï¼Œå°¤å…¶æ˜¯Î±æ³¢æ®µçš„åŠŸç‡å¯ä»¥è¢«ç”¨æ¥è¿½è¸ªå¬è§‰æ³¨æ„åŠ›çš„ä½ç½® (Frey et al., 2014; WoÂ¨stmann et al., 2016)ã€‚å¦æœ‰ä¸€é¡¹ä½¿ç”¨å¤´çš®è„‘ç”µå›¾ï¼ˆEEGï¼‰çš„ç ”ç©¶å‘ç°Î²æ³¢æ®µçš„åŠŸç‡ä¸é€‰æ‹©æ€§æ³¨æ„åŠ›ç›¸å…³(Gao et al., 2017)ã€‚</p><p><strong>ç›®çš„ï¼š</strong></p><p>é€šè¿‡ EEG å’Œ CNN è§£ç ä½ç½®ä¿¡æ¯ï¼Œå†åœ¨åˆ†ç¦»å‡ºæ¥çš„ç›®çš„æ–¹å‘ä¸Šåº”ç”¨ beamformerã€‚</p><h2 id="_2-materials-and-methods" tabindex="-1"><a class="header-anchor" href="#_2-materials-and-methods"><span>2. Materials and methods</span></a></h2><p>è‹±æ–‡è¡¨è¾¾å­¦ä¹ ï¼š</p><p>The desired result is increased speech intelligibility for the listener.</p></div><!----><!--[--><h2 id="doc-changelog" tabindex="-1"><a href="#doc-changelog" class="header-anchor"><span>æ›´æ–°æ—¥å¿—</span></a></h2><div class="vp-changelog-wrapper"><div class="vp-changelog-header"><div class="vp-latest-updated"><span class="vp-changelog-icon"></span><span data-allow-mismatch>2025/11/23 09:30</span></div><div><span class="vp-changelog-menu-icon"></span><span>æŸ¥çœ‹æ‰€æœ‰æ›´æ–°æ—¥å¿—</span></div></div><ul class="vp-changelog-list"><!--[--><li class="vp-changelog-item-commit"><span class="vp-changelog-hash" target="_blank" rel="noreferrer"><code>05705</code></span><span class="vp-changelog-divider">-</span><span class="vp-changelog-message">feat: Update literature review on auditory attention decoding with linear and nonlinear methods</span><span class="vp-changelog-date" data-allow-mismatch>äº <time datetime="2025-11-23T09:30:36.000Z">2025/11/23</time></span></li><li class="vp-changelog-item-commit"><span class="vp-changelog-hash" target="_blank" rel="noreferrer"><code>c0b9d</code></span><span class="vp-changelog-divider">-</span><span class="vp-changelog-message">Add literature review on EEG-based detection of auditory attention using CNNs</span><span class="vp-changelog-date" data-allow-mismatch>äº <time datetime="2025-11-23T06:13:54.000Z">2025/11/23</time></span></li><!--]--></ul></div><!--]--><!----></div><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/AmaraMeng/AmaraMeng.github.io/edit/main/src/reading/literature/01-EEG-based-detection-of-the-locus-of-auditory-attention-with-convolutional-neural-networks.md" aria-label="åœ¨ GitHub ä¸Šç¼–è¾‘æ­¤é¡µ" rel="noopener noreferrer" target="_blank"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->åœ¨ GitHub ä¸Šç¼–è¾‘æ­¤é¡µ<!----></a></div><div class="vp-meta-item git-info"><!----><div class="contributors"><span class="vp-meta-label">è´¡çŒ®è€…: </span><!--[--><!--[--><span class="vp-meta-info" title="email: ranmeng9558@gmail.com">AmaraMeng</span><!--]--><!--]--></div></div></footer><!----><div id="comment" class="waline-wrapper vp-comment" vp-comment darkmode="false" style="display:block;"><!----></div><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><div class="vp-footer">é»˜è®¤é¡µè„š</div><div class="vp-copyright">Copyright Â© 2025 Ran </div></footer></div><!--]--><!--[--><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script type="module" src="/assets/app-C6BM0Klo.js" defer></script>
  </body>
</html>
